[
  {
    "objectID": "analyses.html",
    "href": "analyses.html",
    "title": "Analyses",
    "section": "",
    "text": "library(brms)\nlibrary(ggplot2)\nlibrary(kableExtra)\nlibrary(lme4)\nlibrary(lmerTest)\nlibrary(rmarkdown)\nlibrary(performance)\nlibrary(see)\nlibrary(sjmisc)\nlibrary(tidyverse)\n\noptions(\n  digits = 3\n)\nset.seed(170819)\n\n\n\n\n\n# function to silence brms output\nhush &lt;- \n  function(\n    code\n    ){\n    sink(\"/dev/null\")\n    tmp = code\n    sink()\n    return(tmp)\n    }\n\n\n\n\n\nd &lt;- read_csv(\"data/data.csv\")\n\n# same as above; but original file name:\n# d &lt;- read_csv(\"data/DataAggregated_T1T2_costsbenefits.csv\")\n\n# load image for work in IDE\n# load(\"data/image.RData\")\n\nd &lt;- d |&gt; \n  rename(\n    group = roles,\n    op_expr = n_OE,\n    gender = DE01_T1,\n    age = DE02_01_T1,\n    pol_stance = DE06_01_T1\n  ) |&gt; \n  mutate(\n    female = as.logical(2 - gender),\n    gender = factor(gender, labels = c(\"female\", \"male\"))\n  )\n\n# recode to make as sum coding\nd$anonymity_dev &lt;- factor(d$anonymity)\ncontrasts(d$anonymity_dev) &lt;- contr.sum(2)\nd$persistence_dev &lt;- factor(d$persistence)\ncontrasts(d$persistence_dev) &lt;- contr.sum(2)"
  },
  {
    "objectID": "analyses.html#packages",
    "href": "analyses.html#packages",
    "title": "Analyses",
    "section": "",
    "text": "library(brms)\nlibrary(ggplot2)\nlibrary(kableExtra)\nlibrary(lme4)\nlibrary(lmerTest)\nlibrary(rmarkdown)\nlibrary(performance)\nlibrary(see)\nlibrary(sjmisc)\nlibrary(tidyverse)\n\noptions(\n  digits = 3\n)\nset.seed(170819)"
  },
  {
    "objectID": "analyses.html#custom-functions",
    "href": "analyses.html#custom-functions",
    "title": "Analyses",
    "section": "",
    "text": "# function to silence brms output\nhush &lt;- \n  function(\n    code\n    ){\n    sink(\"/dev/null\")\n    tmp = code\n    sink()\n    return(tmp)\n    }"
  },
  {
    "objectID": "analyses.html#data",
    "href": "analyses.html#data",
    "title": "Analyses",
    "section": "",
    "text": "d &lt;- read_csv(\"data/data.csv\")\n\n# same as above; but original file name:\n# d &lt;- read_csv(\"data/DataAggregated_T1T2_costsbenefits.csv\")\n\n# load image for work in IDE\n# load(\"data/image.RData\")\n\nd &lt;- d |&gt; \n  rename(\n    group = roles,\n    op_expr = n_OE,\n    gender = DE01_T1,\n    age = DE02_01_T1,\n    pol_stance = DE06_01_T1\n  ) |&gt; \n  mutate(\n    female = as.logical(2 - gender),\n    gender = factor(gender, labels = c(\"female\", \"male\"))\n  )\n\n# recode to make as sum coding\nd$anonymity_dev &lt;- factor(d$anonymity)\ncontrasts(d$anonymity_dev) &lt;- contr.sum(2)\nd$persistence_dev &lt;- factor(d$persistence)\ncontrasts(d$persistence_dev) &lt;- contr.sum(2)"
  },
  {
    "objectID": "analyses.html#fixed-effects",
    "href": "analyses.html#fixed-effects",
    "title": "Analyses",
    "section": "Fixed effects",
    "text": "Fixed effects\nWe preregistered to analyze fixed effects.\n\nfit_fe_1 &lt;- \n  hush(\n    brm(\n      op_expr ~ \n        1 + persistence_dev * anonymity_dev + age + female + pol_stance +\n        (1 | topic/group)\n      , data = d\n      , chains = 4\n      , cores = 4\n      , iter = 6000\n      , warmup = 2000\n      , family = zero_inflated_poisson()\n      , control = list(\n        adapt_delta = .95\n        , max_treedepth = 12\n        )\n      , save_pars = save_pars(all = TRUE)\n      , silent = 2\n      )\n  )\n\nWarning: There were 330 divergent transitions after warmup. See\nhttps://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup\nto find out why this is a problem and how to eliminate them.\n\n\nWarning: Examine the pairs() plot to diagnose sampling problems\n\n\nShows some convergence warnings. Let’s inspect model.\n\nplot(fit_fe_1, ask = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTrace-plots look alright.\nLet’s look at results.\n\nsummary(fit_fe_1)\n\nWarning: There were 330 divergent transitions after warmup. Increasing\nadapt_delta above 0.95 may help. See\nhttp://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup\n\n\n Family: zero_inflated_poisson \n  Links: mu = log; zi = identity \nFormula: op_expr ~ 1 + persistence_dev * anonymity_dev + age + female + pol_stance + (1 | topic/group) \n   Data: d (Number of observations: 960) \n  Draws: 4 chains, each with iter = 6000; warmup = 2000; thin = 1;\n         total post-warmup draws = 16000\n\nMultilevel Hyperparameters:\n~topic (Number of levels: 3) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.27      0.32     0.01     1.21 1.00     1879     1967\n\n~topic:group (Number of levels: 48) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.40      0.05     0.32     0.50 1.00     2529     4636\n\nRegression Coefficients:\n                                Estimate Est.Error l-95% CI u-95% CI Rhat\nIntercept                           1.99      0.22     1.49     2.47 1.00\npersistence_dev1                   -0.01      0.06    -0.12     0.11 1.01\nanonymity_dev1                     -0.01      0.06    -0.13     0.11 1.00\nage                                 0.01      0.00     0.01     0.01 1.00\nfemaleTRUE                         -0.00      0.02    -0.05     0.04 1.00\npol_stance                         -0.02      0.01    -0.03    -0.01 1.00\npersistence_dev1:anonymity_dev1     0.02      0.06    -0.09     0.14 1.00\n                                Bulk_ESS Tail_ESS\nIntercept                           2441     1383\npersistence_dev1                    2894     4760\nanonymity_dev1                      2785     4618\nage                                13034     8835\nfemaleTRUE                          6554     5051\npol_stance                         13079    10695\npersistence_dev1:anonymity_dev1     3066     3327\n\nFurther Distributional Parameters:\n   Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nzi     0.21      0.01     0.19     0.24 1.00    11038     9513\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nNo significant effect emerged.\nLet’s inspect ICC\n\nvar_ratio_fe &lt;- performance::variance_decomposition(\n  fit_fe_1\n  , by_group = TRUE)\nvar_ratio_fe\n\n# Random Effect Variances and ICC\n\nConditioned on: all random effects\n\n## Variance Ratio (comparable to ICC)\nRatio: 0.42  CI 95%: [-0.33 0.74]\n\n## Variances of Posterior Predicted Distribution\nConditioned on fixed effects: 31.87  CI 95%: [14.10 73.13]\nConditioned on rand. effects: 55.05  CI 95%: [49.82 60.88]\n\n## Difference in Variances\nDifference: 23.13  CI 95%: [-18.27 41.30]\n\n\n42.145 percent of variance in opinion expressions explained by both topics and groups.\nLet’s visualize results to see what they exactly mean.\n\np &lt;- plot(\n  conditional_effects(\n    fit_fe_1\n    ), \n  ask = FALSE,\n  plot = FALSE\n  )\n\np_anon &lt;- \n  p[[\"anonymity_dev\"]] +\n  xlab(\"Anonymity\") +\n  ylab(\"Opinion expression\") +\n  scale_x_discrete(\n    limits = rev\n     ) +\n  scale_y_continuous(\n    limits = c(5, 14)\n    , breaks = c(6, 8, 10, 12, 14)\n    )\n\np_pers &lt;- \n  p[[\"persistence_dev\"]] +\n  xlab(\"Persistence\") +\n  ylab(\"Opinion expression\") +\n  scale_x_discrete(\n    limits = rev\n   ) +\n  scale_y_continuous(\n    limits = c(5, 14)\n    , breaks = c(6, 8, 10, 12, 14)\n    ) +\n  theme(\n    axis.title.y = element_blank()\n    )\n\np_int &lt;- \n  p[[\"persistence_dev:anonymity_dev\"]] +\n  xlab(\"Persistence\") +\n  scale_x_discrete(\n    limits = rev\n     ) +\n  scale_color_discrete(\n    labels = c(\"low\", \"high\")\n    ) +\n  guides(\n    fill = \"none\",\n    color = guide_legend(\n      title = \"Anonymity\"\n      )\n    ) +\n  theme(\n    axis.title.y = element_blank()\n    ) +\n  scale_y_continuous(\n    limits = c(5, 14)\n    , breaks = c(6, 8, 10, 12, 14)\n    )\n\nplot &lt;- cowplot::plot_grid(\n  p_anon, p_pers, p_int, \n  labels = c('A', 'B', \"C\"), \n  nrow = 1,\n  rel_widths = c(2, 2, 3)\n  )\n\nplot\n\n\n\n\n\n\n\nggsave(\"figures/results.png\", plot, width = 8, height = 4)\n\nShows that there are no main effects. There seems to be a (nonsignificant) interaction effect. In low persistence environment, anonymity is conducive to communication; in high it’s the opposite.\nLet’s look at posteriors\n\np_1 &lt;- \n  pp_check(fit_fe_1) + \n  labs(title = \"Zero-inflated poisson\")\n\nUsing 10 posterior draws for ppc type 'dens_overlay' by default.\n\np_1\n\n\n\n\n\n\n\n\nThe actual distribution cannot be precisely reproduced, but it’s also not too far off."
  },
  {
    "objectID": "analyses.html#random-effects",
    "href": "analyses.html#random-effects",
    "title": "Analyses",
    "section": "Random effects",
    "text": "Random effects\nWe preregistered to explore and compare models with random effects. So let’s model how the experimental conditions affect the outcomes differently depending on topic.\n\nfit_re_1 &lt;- \n  hush(\n    brm(\n      op_expr ~ \n        1 + persistence_dev * anonymity_dev + age + female + pol_stance +\n        (1 + persistence_dev * anonymity_dev | topic) + \n        (1 | topic:group)\n      , data = d\n      , chains = 4\n      , cores = 4\n      , iter = 6000\n      , warmup = 2000\n      , family = zero_inflated_poisson()\n      , control = list(\n        adapt_delta = .95\n        , max_treedepth = 15\n        )\n      , save_pars = save_pars(all = TRUE)\n    )\n  )\n\nWarning: There were 510 divergent transitions after warmup. See\nhttps://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup\nto find out why this is a problem and how to eliminate them.\n\n\nWarning: Examine the pairs() plot to diagnose sampling problems\n\n\nShows some convergence warnings.\nLet’s inspect model.\n\nplot(fit_re_1, ask = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTraceplots look alright.\nLet’s look at results.\n\nsummary(fit_re_1)\n\nWarning: There were 1281 divergent transitions after warmup. Increasing\nadapt_delta above 0.95 may help. See\nhttp://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup\n\n\n Family: zero_inflated_poisson \n  Links: mu = log; zi = identity \nFormula: op_expr ~ 1 + persistence_dev * anonymity_dev + (1 + persistence_dev * anonymity_dev | topic) + (1 | topic:group) \n   Data: d (Number of observations: 960) \n  Draws: 4 chains, each with iter = 8000; warmup = 2000; thin = 1;\n         total post-warmup draws = 24000\n\nMultilevel Hyperparameters:\n~topic (Number of levels: 3) \n                                                      Estimate Est.Error\nsd(Intercept)                                             0.36      0.46\nsd(persistence_dev1)                                      0.25      0.35\nsd(anonymity_dev1)                                        0.24      0.34\nsd(persistence_dev1:anonymity_dev1)                       0.41      0.46\ncor(Intercept,persistence_dev1)                          -0.00      0.46\ncor(Intercept,anonymity_dev1)                             0.01      0.46\ncor(persistence_dev1,anonymity_dev1)                     -0.01      0.47\ncor(Intercept,persistence_dev1:anonymity_dev1)            0.08      0.46\ncor(persistence_dev1,persistence_dev1:anonymity_dev1)     0.02      0.46\ncor(anonymity_dev1,persistence_dev1:anonymity_dev1)      -0.01      0.46\n                                                      l-95% CI u-95% CI Rhat\nsd(Intercept)                                             0.01     1.60 1.00\nsd(persistence_dev1)                                      0.01     1.21 1.00\nsd(anonymity_dev1)                                        0.00     1.20 1.00\nsd(persistence_dev1:anonymity_dev1)                       0.02     1.69 1.00\ncor(Intercept,persistence_dev1)                          -0.83     0.83 1.00\ncor(Intercept,anonymity_dev1)                            -0.83     0.83 1.00\ncor(persistence_dev1,anonymity_dev1)                     -0.83     0.83 1.00\ncor(Intercept,persistence_dev1:anonymity_dev1)           -0.78     0.86 1.00\ncor(persistence_dev1,persistence_dev1:anonymity_dev1)    -0.83     0.84 1.00\ncor(anonymity_dev1,persistence_dev1:anonymity_dev1)      -0.83     0.83 1.00\n                                                      Bulk_ESS Tail_ESS\nsd(Intercept)                                             6620    11752\nsd(persistence_dev1)                                      7764    10211\nsd(anonymity_dev1)                                        7280     9370\nsd(persistence_dev1:anonymity_dev1)                       6024     5585\ncor(Intercept,persistence_dev1)                          21881    16269\ncor(Intercept,anonymity_dev1)                            22853    15065\ncor(persistence_dev1,anonymity_dev1)                     19146    13364\ncor(Intercept,persistence_dev1:anonymity_dev1)           22045    15452\ncor(persistence_dev1,persistence_dev1:anonymity_dev1)    19117    15472\ncor(anonymity_dev1,persistence_dev1:anonymity_dev1)      15719    17072\n\n~topic:group (Number of levels: 48) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.40      0.05     0.32     0.51 1.00     7776    12613\n\nRegression Coefficients:\n                                Estimate Est.Error l-95% CI u-95% CI Rhat\nIntercept                           2.38      0.27     1.79     2.95 1.00\npersistence_dev1                   -0.00      0.21    -0.41     0.44 1.00\nanonymity_dev1                      0.00      0.22    -0.44     0.44 1.00\npersistence_dev1:anonymity_dev1     0.02      0.33    -0.67     0.71 1.00\n                                Bulk_ESS Tail_ESS\nIntercept                          10960     9291\npersistence_dev1                   10694     8366\nanonymity_dev1                      9075     6054\npersistence_dev1:anonymity_dev1     8583     5583\n\nFurther Distributional Parameters:\n   Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nzi     0.21      0.01     0.19     0.24 1.00    32167    15762\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nAgain, no main or interaction effects.\nLet’s see if the random effects model fits better\n\nfit_fe_1 &lt;- add_criterion(\n  fit_fe_1\n  , \"kfold\" \n  , K = 10\n  , cores = 4\n  )\n\nFitting model 1 out of 10\n\n\nStart sampling\n\n\nFitting model 2 out of 10\n\n\nStart sampling\n\n\nFitting model 3 out of 10\n\n\nStart sampling\n\n\nFitting model 4 out of 10\n\n\nStart sampling\n\n\nFitting model 5 out of 10\n\n\nStart sampling\n\n\nFitting model 6 out of 10\n\n\nStart sampling\n\n\nFitting model 7 out of 10\n\n\nStart sampling\n\n\nFitting model 8 out of 10\n\n\nStart sampling\n\n\nFitting model 9 out of 10\n\n\nStart sampling\n\n\nFitting model 10 out of 10\n\n\nStart sampling\n\nfit_re_1 &lt;- add_criterion(\n  fit_re_1\n  , \"kfold\"\n  , K = 10\n  , cores = 4\n  )\n\nFitting model 1 out of 10\nStart sampling\n\n\nFitting model 2 out of 10\n\n\nStart sampling\n\n\nFitting model 3 out of 10\n\n\nStart sampling\n\n\nFitting model 4 out of 10\n\n\nStart sampling\n\n\nFitting model 5 out of 10\n\n\nStart sampling\n\n\nFitting model 6 out of 10\n\n\nStart sampling\n\n\nFitting model 7 out of 10\n\n\nStart sampling\n\n\nFitting model 8 out of 10\n\n\nStart sampling\n\n\nFitting model 9 out of 10\n\n\nStart sampling\n\n\nFitting model 10 out of 10\n\n\nStart sampling\n\ncomp_1 &lt;- loo_compare(fit_fe_1, fit_re_1, criterion = \"kfold\")\ncomp_1\n\n         elpd_diff se_diff\nfit_re_1   0.0       0.0  \nfit_fe_1 -16.5      29.9  \n\n\nAlthough model comparisons showed that the model with random effects fitted better, the difference was not significant (Δ ELPD = -16.46, 95% CI [-75.054, 42.139]. Hence, for reasons of parsimony the model with fixed effects is preferred."
  },
  {
    "objectID": "analyses.html#hurdle",
    "href": "analyses.html#hurdle",
    "title": "Analyses",
    "section": "Hurdle",
    "text": "Hurdle\nLet’s now estimate a fixed effects model with hurdles.\n\nfit_hrdl_1 &lt;- \n  hush(\n    brm(\n      bf(\n        op_expr ~ \n          1 + persistence_dev * anonymity_dev + age + female + pol_stance +\n          (1 | topic) + \n          (1 | topic:group),\n        zi ~ \n          1 + persistence_dev * anonymity_dev + age + female + pol_stance +\n          (1 | topic) + \n          (1 | topic:group)\n      )\n    , data = d\n    , chains = 4\n    , cores = 4\n    , iter = 6000\n    , warmup = 2000\n    , family = zero_inflated_poisson()\n    , control = list(\n      adapt_delta = .95\n      , max_treedepth = 15\n      )\n    )\n  )\n\nWarning: There were 4188 divergent transitions after warmup. See\nhttps://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup\nto find out why this is a problem and how to eliminate them.\n\n\nWarning: Examine the pairs() plot to diagnose sampling problems\n\n\nWarning: The largest R-hat is 1.57, indicating chains have not mixed.\nRunning the chains for more iterations may help. See\nhttps://mc-stan.org/misc/warnings.html#r-hat\n\n\nWarning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable.\nRunning the chains for more iterations may help. See\nhttps://mc-stan.org/misc/warnings.html#bulk-ess\n\n\nWarning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable.\nRunning the chains for more iterations may help. See\nhttps://mc-stan.org/misc/warnings.html#tail-ess\n\n\nAgian, some warnings.\nLet’s inspect model.\n\nplot(fit_hrdl_1, ask = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTrace-plots look alright.\n\nsummary(fit_hrdl_1)\n\nWarning: There were 601 divergent transitions after warmup. Increasing\nadapt_delta above 0.95 may help. See\nhttp://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup\n\n\n Family: zero_inflated_poisson \n  Links: mu = log; zi = logit \nFormula: op_expr ~ 1 + persistence_dev * anonymity_dev + (1 | topic) + (1 | topic:group) \n         zi ~ 1 + persistence_dev * anonymity_dev + (1 | topic) + (1 | topic:group)\n   Data: d (Number of observations: 960) \n  Draws: 4 chains, each with iter = 8000; warmup = 2000; thin = 1;\n         total post-warmup draws = 24000\n\nMultilevel Hyperparameters:\n~topic (Number of levels: 3) \n                 Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)        0.27      0.32     0.01     1.17 1.00     2245     1183\nsd(zi_Intercept)     0.28      0.44     0.01     1.50 1.00     6240     5389\n\n~topic:group (Number of levels: 48) \n                 Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)        0.40      0.05     0.32     0.50 1.00     5272    10476\nsd(zi_Intercept)     0.24      0.14     0.01     0.53 1.00     5361     8349\n\nRegression Coefficients:\n                                   Estimate Est.Error l-95% CI u-95% CI Rhat\nIntercept                              2.39      0.20     1.96     2.83 1.00\nzi_Intercept                          -1.30      0.28    -1.74    -0.67 1.00\npersistence_dev1                      -0.01      0.06    -0.12     0.11 1.00\nanonymity_dev1                         0.00      0.06    -0.12     0.12 1.00\npersistence_dev1:anonymity_dev1        0.03      0.06    -0.09     0.15 1.00\nzi_persistence_dev1                    0.03      0.09    -0.15     0.20 1.00\nzi_anonymity_dev1                      0.01      0.09    -0.17     0.18 1.00\nzi_persistence_dev1:anonymity_dev1     0.01      0.09    -0.16     0.18 1.00\n                                   Bulk_ESS Tail_ESS\nIntercept                              2994     1307\nzi_Intercept                           7245     4630\npersistence_dev1                       4984     9340\nanonymity_dev1                         5664     9023\npersistence_dev1:anonymity_dev1        5982     9817\nzi_persistence_dev1                   19443     9630\nzi_anonymity_dev1                     22174    16988\nzi_persistence_dev1:anonymity_dev1    10375     7268\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nSame results, no main effects, slightly larger but still nonsignificant interaction effect."
  },
  {
    "objectID": "analyses.html#frequentist",
    "href": "analyses.html#frequentist",
    "title": "Analyses",
    "section": "Frequentist",
    "text": "Frequentist\nLook at results from a frequentist perspective.\n\nFixed effects\nEstimate nested model.\n\nfit_fe_1_frq &lt;- \n  lmer(\n    op_expr ~ \n      1 + \n      (1 | topic/group) + \n      persistence_dev * anonymity_dev + age + female + pol_stance\n    , data = d\n    )\n\nsummary(fit_fe_1_frq)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: op_expr ~ 1 + (1 | topic/group) + persistence_dev * anonymity_dev +  \n    age + female + pol_stance\n   Data: d\n\nREML criterion at convergence: 7604\n\nScaled residuals: \n   Min     1Q Median     3Q    Max \n-1.484 -0.555 -0.196  0.264 13.549 \n\nRandom effects:\n Groups      Name        Variance Std.Dev.\n group:topic (Intercept) 1.08e+01 3.28e+00\n topic       (Intercept) 8.92e-08 2.99e-04\n Residual                1.55e+02 1.25e+01\nNumber of obs: 960, groups:  group:topic, 48; topic, 3\n\nFixed effects:\n                                Estimate Std. Error t value\n(Intercept)                       6.0450     2.1478    2.81\npersistence_dev1                 -0.0197     0.6214   -0.03\nanonymity_dev1                   -0.3437     0.6242   -0.55\nage                               0.0860     0.0357    2.41\nfemaleTRUE                       -0.2434     0.8783   -0.28\npol_stance                       -0.0319     0.2058   -0.16\npersistence_dev1:anonymity_dev1   0.1953     0.6226    0.31\n\nCorrelation of Fixed Effects:\n            (Intr) prss_1 anny_1 age    fmTRUE pl_stn\nprsstnc_dv1  0.015                                   \nannymty_dv1  0.053  0.000                            \nage         -0.750 -0.010 -0.049                     \nfemaleTRUE  -0.463 -0.014  0.041  0.252              \npol_stance  -0.538 -0.009 -0.057 -0.003  0.062       \nprsstn_1:_1  0.019  0.000 -0.002 -0.045 -0.034  0.038\noptimizer (nloptwrap) convergence code: 0 (OK)\nboundary (singular) fit: see help('isSingular')\n\n\nQuite weird that topic doesn’t get any variance at all. Perhaps due to small cluster size? With Bayesian estimation, it worked alright. Also, again no significant effects.\nEstimate without nesting.\n\nfit_fe_2_frq &lt;- \n  lmer(\n    op_expr ~ \n      1 + \n      (1 | group) +\n      persistence_dev * anonymity_dev + age + female + pol_stance + topic\n    , data = d\n    )\n\nsummary(fit_fe_2_frq)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: op_expr ~ 1 + (1 | group) + persistence_dev * anonymity_dev +  \n    age + female + pol_stance + topic\n   Data: d\n\nREML criterion at convergence: 7598\n\nScaled residuals: \n   Min     1Q Median     3Q    Max \n-1.513 -0.548 -0.188  0.265 13.577 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n group    (Intercept)  11       3.32   \n Residual             155      12.46   \nNumber of obs: 960, groups:  group, 48\n\nFixed effects:\n                                Estimate Std. Error       df t value Pr(&gt;|t|)\n(Intercept)                       6.3760     2.3261 511.8117    2.74   0.0063\npersistence_dev1                 -0.0195     0.6257  41.8742   -0.03   0.9753\nanonymity_dev1                   -0.3439     0.6284  42.6053   -0.55   0.5871\nage                               0.0854     0.0357 942.0312    2.39   0.0169\nfemaleTRUE                       -0.2641     0.8788 938.1103   -0.30   0.7638\npol_stance                       -0.0324     0.2058 941.3972   -0.16   0.8751\ntopicgender                       0.4373     1.5334  41.9702    0.29   0.7769\ntopicmigration                   -1.3078     1.5329  41.9180   -0.85   0.3984\npersistence_dev1:anonymity_dev1   0.1960     0.6268  42.1850    0.31   0.7561\n                                  \n(Intercept)                     **\npersistence_dev1                  \nanonymity_dev1                    \nage                             * \nfemaleTRUE                        \npol_stance                        \ntopicgender                       \ntopicmigration                    \npersistence_dev1:anonymity_dev1   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) prss_1 anny_1 age    fmTRUE pl_stn tpcgnd tpcmgr\nprsstnc_dv1  0.014                                                 \nannymty_dv1  0.049  0.000                                          \nage         -0.701 -0.010 -0.049                                   \nfemaleTRUE  -0.423 -0.014  0.041  0.252                            \npol_stance  -0.489 -0.009 -0.057 -0.004  0.063                     \ntopicgender -0.325  0.000 -0.001  0.017 -0.024 -0.020              \ntopicmigrtn -0.337  0.000 -0.001  0.024  0.000 -0.016  0.500       \nprsstn_1:_1  0.018  0.000 -0.001 -0.045 -0.033  0.038 -0.001 -0.002\n\n\nAlso shows no significant effects.\nFor curiosity, estimate also without hierarchical structure.\n\nfit_fe_3_frq &lt;- \n  lm(\n    op_expr ~ \n      1 + \n      persistence_dev * anonymity_dev + topic + age + female + pol_stance\n    , data = d\n    )\n\nsummary(fit_fe_3_frq)\n\n\nCall:\nlm(formula = op_expr ~ 1 + persistence_dev * anonymity_dev + \n    topic + age + female + pol_stance, data = d)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-12.95  -7.46  -2.92   3.00 177.59 \n\nCoefficients:\n                                Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)                       5.7503     2.2095    2.60   0.0094 **\npersistence_dev1                 -0.0223     0.4148   -0.05   0.9571   \nanonymity_dev1                   -0.3598     0.4191   -0.86   0.3908   \ntopicgender                       0.4291     1.0174    0.42   0.6733   \ntopicmigration                   -1.3114     1.0166   -1.29   0.1974   \nage                               0.0901     0.0362    2.49   0.0129 * \nfemaleTRUE                       -0.2010     0.8932   -0.23   0.8220   \npol_stance                        0.0398     0.2087    0.19   0.8489   \npersistence_dev1:anonymity_dev1   0.2004     0.4166    0.48   0.6306   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.8 on 951 degrees of freedom\nMultiple R-squared:  0.0115,    Adjusted R-squared:  0.00315 \nF-statistic: 1.38 on 8 and 951 DF,  p-value: 0.202\n\n\nAlso here, no significant effects."
  },
  {
    "objectID": "analyses.html#gender",
    "href": "analyses.html#gender",
    "title": "Analyses",
    "section": "Gender",
    "text": "Gender\nAs preregistered, let’s see if effects differ across genders.\n\nfit_fe_gen &lt;- \n  hush(\n    brm(\n      op_expr ~ \n        1 + persistence_dev * anonymity_dev * gender + age + pol_stance +\n        (1 | topic/group)\n      , data = d\n      , chains = 4\n      , cores = 4\n      , iter = 8000\n      , warmup = 2000\n      , family = zero_inflated_poisson()\n      , control = list(\n        adapt_delta = .95\n        , max_treedepth = 12\n        )\n      )\n  )\n\nWarning: There were 3844 divergent transitions after warmup. See\nhttps://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup\nto find out why this is a problem and how to eliminate them.\n\n\nWarning: Examine the pairs() plot to diagnose sampling problems\n\n\nWarning: The largest R-hat is 1.32, indicating chains have not mixed.\nRunning the chains for more iterations may help. See\nhttps://mc-stan.org/misc/warnings.html#r-hat\n\n\nWarning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable.\nRunning the chains for more iterations may help. See\nhttps://mc-stan.org/misc/warnings.html#bulk-ess\n\n\nWarning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable.\nRunning the chains for more iterations may help. See\nhttps://mc-stan.org/misc/warnings.html#tail-ess\n\n\nAgain, some warnings.\nLet’s inspect model.\n\nplot(fit_fe_gen, ask = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTraceplots look alright.\nLet’s look at results.\n\nsummary(fit_fe_gen)\n\nWarning: There were 319 divergent transitions after warmup. Increasing\nadapt_delta above 0.95 may help. See\nhttp://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup\n\n\n Family: zero_inflated_poisson \n  Links: mu = log; zi = identity \nFormula: op_expr ~ 1 + persistence_dev * anonymity_dev * gender + age + pol_stance + (1 | topic/group) \n   Data: d (Number of observations: 960) \n  Draws: 4 chains, each with iter = 6000; warmup = 2000; thin = 1;\n         total post-warmup draws = 16000\n\nMultilevel Hyperparameters:\n~topic (Number of levels: 3) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.24      0.28     0.01     1.08 1.00     1881     1668\n\n~topic:group (Number of levels: 48) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.40      0.05     0.32     0.50 1.00     2824     4724\n\nRegression Coefficients:\n                                           Estimate Est.Error l-95% CI u-95% CI\nIntercept                                      2.00      0.18     1.61     2.40\npersistence_dev1                               0.02      0.06    -0.09     0.14\nanonymity_dev1                                -0.04      0.06    -0.15     0.08\ngendermale                                    -0.00      0.02    -0.05     0.04\nage                                            0.01      0.00     0.01     0.01\npol_stance                                    -0.02      0.01    -0.03    -0.01\npersistence_dev1:anonymity_dev1                0.01      0.06    -0.11     0.12\npersistence_dev1:gendermale                   -0.08      0.02    -0.12    -0.03\nanonymity_dev1:gendermale                      0.07      0.02     0.03     0.12\npersistence_dev1:anonymity_dev1:gendermale     0.05      0.02     0.01     0.09\n                                           Rhat Bulk_ESS Tail_ESS\nIntercept                                  1.00     2586     1884\npersistence_dev1                           1.00     2815     4790\nanonymity_dev1                             1.00     2742     4434\ngendermale                                 1.00    10194    10160\nage                                        1.00    21298    12326\npol_stance                                 1.00    11116     9270\npersistence_dev1:anonymity_dev1            1.00     2857     4325\npersistence_dev1:gendermale                1.00    10315     8940\nanonymity_dev1:gendermale                  1.00     9975     9554\npersistence_dev1:anonymity_dev1:gendermale 1.00    10847    10513\n\nFurther Distributional Parameters:\n   Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nzi     0.21      0.01     0.19     0.24 1.00    11016     9500\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nIndeed, several gender effects.\n\nFor females, the effect of persistence is larger, that is more positive.\nFor females, the effect of anonymity is smaller, that is more negative.\nFor females, the interaction effect is also a bit smaller, that is more negative.\n\nLet’s visualize results.\n\np_gen &lt;- plot(\n  conditional_effects(\n    fit_fe_gen\n    ), \n  ask = FALSE,\n  plot = FALSE\n  )\n\np_gen_pers &lt;- \n  p_gen[[\"persistence_dev:gender\"]] +\n  xlab(\"Persistence\") +\n  ylab(\"Opinion expression\") +\n  scale_y_continuous(\n    limits = c(4, 15),\n    breaks = c(5, 7.5, 10, 12.5, 15)\n  ) +\n  scale_x_discrete(\n    limits = rev\n  ) +\n  guides(\n    fill = \"none\"\n    , color = \"none\"\n    )\n\np_gen_anon &lt;- \n  p_gen[[\"anonymity_dev:gender\"]] +\n  xlab(\"Anonymity\") +\n  ylab(\"Opinion expression\") +\n  scale_y_continuous(\n    limits = c(3.5, 15),\n    breaks = c(5, 7.5, 10, 12.5, 15)\n  ) +\n  theme(\n    axis.title.y = element_blank()\n    ) +\n  guides(\n    fill = \"none\"\n    ) + \n  scale_x_discrete(\n    limits = rev\n  ) +\n  scale_color_discrete(\n    name = \"Gender\"\n    )\n\nplot_gen &lt;- cowplot::plot_grid(\n  p_gen_pers, p_gen_anon, \n  labels = c('A', 'B'), \n  nrow = 1,\n  rel_widths = c(4, 5)\n  )\n\nplot_gen\n\n\n\n\n\n\n\nggsave(\"figures/results_gen.png\", plot_gen, width = 8, height = 4)"
  },
  {
    "objectID": "analyses.html#benefits",
    "href": "analyses.html#benefits",
    "title": "Analyses",
    "section": "Benefits",
    "text": "Benefits\nLet’s see if benefits differ across experimental groups.\nWe first look at the experimental group’s descriptives\n\nd |&gt; \n  group_by(persistence) |&gt; \n  summarize(benefits_m = mean(benefits, na.rm = TRUE)) |&gt; \n  as.data.frame() |&gt; \n  kable()\n\n\n\n\npersistence\nbenefits_m\n\n\n\n\nhigh\n3.12\n\n\nlow\n3.23\n\n\n\n\n\nLooking at persistence, we see people with lower persistence reporting slightly higher benefits.\n\nd |&gt; \n  group_by(anonymity) |&gt; \n  summarize(benefits_m = mean(benefits, na.rm = TRUE)) |&gt; \n  as.data.frame() |&gt; \n  kable()\n\n\n\n\nanonymity\nbenefits_m\n\n\n\n\nhigh\n3.15\n\n\nlow\n3.20\n\n\n\n\n\nLooking at anonymity, we see people with low anonymity reporting marginally higher benefits.\n\nd |&gt; \n  group_by(persistence, anonymity) |&gt; \n  summarize(benefits_m = mean(benefits, na.rm = T)) |&gt; \n  as.data.frame() |&gt; \n  kable()\n\n`summarise()` has grouped output by 'persistence'. You can override using the\n`.groups` argument.\n\n\n\n\n\npersistence\nanonymity\nbenefits_m\n\n\n\n\nhigh\nhigh\n3.07\n\n\nhigh\nlow\n3.18\n\n\nlow\nhigh\n3.22\n\n\nlow\nlow\n3.23\n\n\n\n\n\nLooking at both groups combined, we see that low anonymity and low persistence yielded highest benefits.\nLet’s look if effects are significant.\n\nfit_fe_ben_1 &lt;- \n  hush(\n    brm(\n      benefits ~ \n        1 + persistence_dev * anonymity_dev  + age + female + pol_stance +\n        (1 | topic/group)\n      , data = d\n      , chains = 4\n      , cores = 4\n      , iter = 6000\n      , warmup = 2000\n      , control = list(\n        adapt_delta = .95\n        , max_treedepth = 12\n        )\n      )\n  )\n\nWarning: Rows containing NAs were excluded from the model.\n\n\nWarning: There were 118 divergent transitions after warmup. See\nhttps://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup\nto find out why this is a problem and how to eliminate them.\n\n\nWarning: Examine the pairs() plot to diagnose sampling problems\n\n\nLet’s inspect model.\n\nplot(fit_fe_ben_1, ask = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTraceplots look alright.\nLet’s look at results.\n\nsummary(fit_fe_ben_1)\n\nWarning: There were 247 divergent transitions after warmup. Increasing\nadapt_delta above 0.95 may help. See\nhttp://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup\n\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: benefits ~ 1 + persistence_dev * anonymity_dev + age + female + pol_stance + (1 | topic/group) \n   Data: d (Number of observations: 705) \n  Draws: 4 chains, each with iter = 6000; warmup = 2000; thin = 1;\n         total post-warmup draws = 16000\n\nMultilevel Hyperparameters:\n~topic (Number of levels: 3) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.13      0.19     0.00     0.73 1.00     1100      369\n\n~topic:group (Number of levels: 48) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.07      0.05     0.00     0.17 1.00     3788     5227\n\nRegression Coefficients:\n                                Estimate Est.Error l-95% CI u-95% CI Rhat\nIntercept                           3.22      0.18     2.89     3.60 1.01\npersistence_dev1                   -0.05      0.03    -0.11     0.01 1.00\nanonymity_dev1                     -0.03      0.03    -0.09     0.03 1.00\nage                                -0.00      0.00    -0.01     0.00 1.00\nfemaleTRUE                         -0.07      0.06    -0.19     0.04 1.00\npol_stance                          0.02      0.01    -0.01     0.04 1.00\npersistence_dev1:anonymity_dev1    -0.02      0.03    -0.08     0.04 1.00\n                                Bulk_ESS Tail_ESS\nIntercept                            856      306\npersistence_dev1                   14485    11192\nanonymity_dev1                      7778     8443\nage                                 8196     6231\nfemaleTRUE                         18094    11134\npol_stance                         17172     9460\npersistence_dev1:anonymity_dev1     7262     5633\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     0.74      0.02     0.70     0.78 1.00    13329     8099\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nNo significant effects. But note that effect of persistence on perceived benefits only marginally not significant."
  },
  {
    "objectID": "analyses.html#costs",
    "href": "analyses.html#costs",
    "title": "Analyses",
    "section": "Costs",
    "text": "Costs\nLet’s see if perceived differed across experimental groups.\nWe first look at the experimental group’s descriptives\n\nd |&gt; \n  group_by(persistence) |&gt; \n  summarize(costs = mean(costs, na.rm = TRUE)) |&gt; \n  as.data.frame() |&gt; \n  kable()\n\n\n\n\npersistence\ncosts\n\n\n\n\nhigh\n1.99\n\n\nlow\n1.99\n\n\n\n\n\nLooking at persistence, we see both groups report equal costs.\n\nd |&gt; \n  group_by(anonymity) |&gt; \n  summarize(costs = mean(costs, na.rm = TRUE)) |&gt; \n  as.data.frame() |&gt; \n  kable()\n\n\n\n\nanonymity\ncosts\n\n\n\n\nhigh\n1.89\n\n\nlow\n2.09\n\n\n\n\n\nLooking at anonymity, we see people with low anonymity report slightly higher costs.\n\nd |&gt; \n  group_by(persistence, anonymity) |&gt; \n  summarize(costs = mean(costs, na.rm = TRUE)) |&gt; \n  as.data.frame() |&gt; \n  kable()\n\n`summarise()` has grouped output by 'persistence'. You can override using the\n`.groups` argument.\n\n\n\n\n\npersistence\nanonymity\ncosts\n\n\n\n\nhigh\nhigh\n1.90\n\n\nhigh\nlow\n2.07\n\n\nlow\nhigh\n1.87\n\n\nlow\nlow\n2.11\n\n\n\n\n\nLooking at both groups combined, we see that highest costs were reported by group with low anonymity and low persistence.\nLet’s look if effects are significant.\n\nfit_fe_costs_1 &lt;- \n  hush(\n    brm(\n      costs ~ \n        1 + persistence_dev * anonymity_dev + age + female + pol_stance +\n        (1 | topic/group)\n      , data = d\n      , chains = 4\n      , cores = 4\n      , iter = 8000\n      , warmup = 2000\n      , control = list(\n        adapt_delta = .95\n        , max_treedepth = 12\n        )\n      )\n  )\n\nWarning: Rows containing NAs were excluded from the model.\n\n\nWarning: There were 232 divergent transitions after warmup. See\nhttps://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup\nto find out why this is a problem and how to eliminate them.\n\n\nWarning: Examine the pairs() plot to diagnose sampling problems\n\n\nLet’s inspect model.\n\nplot(fit_fe_costs_1, ask = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTraceplots look alright.\nLet’s look at results.\n\nsummary(fit_fe_costs_1)\n\nWarning: There were 90 divergent transitions after warmup. Increasing\nadapt_delta above 0.95 may help. See\nhttp://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup\n\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: costs ~ 1 + persistence_dev * anonymity_dev + age + female + pol_stance + (1 | topic/group) \n   Data: d (Number of observations: 705) \n  Draws: 4 chains, each with iter = 6000; warmup = 2000; thin = 1;\n         total post-warmup draws = 16000\n\nMultilevel Hyperparameters:\n~topic (Number of levels: 3) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.13      0.18     0.00     0.66 1.00     3243     2917\n\n~topic:group (Number of levels: 48) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.07      0.05     0.00     0.17 1.00     4567     6211\n\nRegression Coefficients:\n                                Estimate Est.Error l-95% CI u-95% CI Rhat\nIntercept                           2.48      0.19     2.11     2.85 1.00\npersistence_dev1                    0.00      0.03    -0.07     0.07 1.00\nanonymity_dev1                     -0.08      0.03    -0.15    -0.02 1.00\nage                                -0.01      0.00    -0.02    -0.01 1.00\nfemaleTRUE                          0.01      0.07    -0.12     0.14 1.00\npol_stance                         -0.00      0.02    -0.04     0.03 1.00\npersistence_dev1:anonymity_dev1     0.02      0.03    -0.05     0.09 1.00\n                                Bulk_ESS Tail_ESS\nIntercept                           7441     5033\npersistence_dev1                   16973    10458\nanonymity_dev1                     15824    12001\nage                                23160    12259\nfemaleTRUE                         17259    11422\npol_stance                         19931    10211\npersistence_dev1:anonymity_dev1    13347     6847\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     0.84      0.02     0.80     0.89 1.00    17064     8181\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nWe find that anonymity does reduce costs."
  },
  {
    "objectID": "analyses.html#mediation",
    "href": "analyses.html#mediation",
    "title": "Analyses",
    "section": "Mediation",
    "text": "Mediation\nLet’s see if perceived benefits and costs were associated with increased opinion expressions.\n\nfit_fe_med &lt;- \n  hush(\n    brm(\n      op_expr ~ \n        1 + persistence_dev * anonymity_dev + benefits + costs  + age + female + pol_stance + \n        (1 | topic/group)\n      , data = d\n      , chains = 4\n      , cores = 4\n      , iter = 6000\n      , warmup = 2000\n      , family = zero_inflated_poisson()\n      , control = list(\n        adapt_delta = .95\n        , max_treedepth = 12\n        )\n      )\n  )\n\nWarning: Rows containing NAs were excluded from the model.\n\n\nWarning: There were 1389 divergent transitions after warmup. See\nhttps://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup\nto find out why this is a problem and how to eliminate them.\n\n\nWarning: Examine the pairs() plot to diagnose sampling problems\n\n\nWarning: The largest R-hat is 1.1, indicating chains have not mixed.\nRunning the chains for more iterations may help. See\nhttps://mc-stan.org/misc/warnings.html#r-hat\n\n\nWarning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable.\nRunning the chains for more iterations may help. See\nhttps://mc-stan.org/misc/warnings.html#bulk-ess\n\n\nWarning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable.\nRunning the chains for more iterations may help. See\nhttps://mc-stan.org/misc/warnings.html#tail-ess\n\n\nLet’s look at results.\n\nsummary(fit_fe_med)\n\nWarning: There were 237 divergent transitions after warmup. Increasing\nadapt_delta above 0.95 may help. See\nhttp://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup\n\n\n Family: zero_inflated_poisson \n  Links: mu = log; zi = identity \nFormula: op_expr ~ 1 + persistence_dev * anonymity_dev + benefits + costs + age + female + pol_stance + (1 | topic/group) \n   Data: d (Number of observations: 705) \n  Draws: 4 chains, each with iter = 6000; warmup = 2000; thin = 1;\n         total post-warmup draws = 16000\n\nMultilevel Hyperparameters:\n~topic (Number of levels: 3) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.21      0.25     0.01     0.94 1.00     2495     4490\n\n~topic:group (Number of levels: 48) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.41      0.05     0.33     0.51 1.00     2840     5243\n\nRegression Coefficients:\n                                Estimate Est.Error l-95% CI u-95% CI Rhat\nIntercept                           1.96      0.17     1.61     2.33 1.00\npersistence_dev1                   -0.02      0.06    -0.14     0.09 1.00\nanonymity_dev1                      0.00      0.06    -0.12     0.12 1.00\nbenefits                            0.11      0.02     0.08     0.14 1.00\ncosts                              -0.09      0.01    -0.12    -0.07 1.00\nage                                 0.01      0.00     0.01     0.01 1.00\nfemaleTRUE                          0.00      0.02    -0.05     0.05 1.00\npol_stance                         -0.02      0.01    -0.03    -0.00 1.00\npersistence_dev1:anonymity_dev1     0.02      0.06    -0.10     0.14 1.00\n                                Bulk_ESS Tail_ESS\nIntercept                           5127     4650\npersistence_dev1                    3572     5591\nanonymity_dev1                      3374     4915\nbenefits                           11632     9554\ncosts                              12027     9628\nage                                20747    13026\nfemaleTRUE                         12495    10627\npol_stance                         12865    10854\npersistence_dev1:anonymity_dev1     3396     5453\n\nFurther Distributional Parameters:\n   Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nzi     0.08      0.01     0.06     0.10 1.00    12787     9891\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nWe find that increased perceived costs are associated with decreased opinion expressions. Increased benefits are associated with increased opinion expressions. Let’s check if overall effect is significant.\n\nanon_costs_a_b &lt;- fixef(fit_fe_costs_1)[\"anonymity_dev1\", \"Estimate\"]\nanon_costs_a_se &lt;- fixef(fit_fe_costs_1)[\"anonymity_dev1\", \"Est.Error\"]\nanon_costs_a_dis &lt;- rnorm(10000, anon_costs_a_b, anon_costs_a_se)\n\nanon_costs_b_b &lt;- fixef(fit_fe_med)[\"benefits\", \"Estimate\"]\nanon_costs_b_se &lt;- fixef(fit_fe_med)[\"benefits\", \"Est.Error\"]\nanon_costs_b_dis &lt;- rnorm(10000, anon_costs_b_b, anon_costs_b_se)\n\nanon_costs_ab_dis &lt;- anon_costs_a_dis * anon_costs_b_dis\nanon_costs_ab_m &lt;- median(anon_costs_ab_dis)\nanon_costs_ab_ll &lt;- quantile(anon_costs_ab_dis, .025)\nanon_costs_ab_ul &lt;- quantile(anon_costs_ab_dis, .975)\n\nThe effect is significant (b = -0.01, 95% MC CI [-0.02, 0])."
  },
  {
    "objectID": "power_analyses.html",
    "href": "power_analyses.html",
    "title": "Power Analyses",
    "section": "",
    "text": "library(BayesFactor)\nlibrary(brms)\nlibrary(broom)\nlibrary(ggplot2)\nlibrary(knitr)\nlibrary(magrittr)\nlibrary(tidyverse)"
  },
  {
    "objectID": "power_analyses.html#generate-design",
    "href": "power_analyses.html#generate-design",
    "title": "Power Analyses",
    "section": "Generate design",
    "text": "Generate design\n\ngenerate_design &lt;- function(groupsize, \n                            persis, \n                            anon, \n                            topics, \n                            repetition, \n                            ...){\n  \n  # function generates underlying (empty) datastructure\n  \n  # count number of groups\n  groups &lt;- persis * anon * topics * repetition\n  \n  # make datastructure\n  expand.grid(\n    participant = 1:groupsize, \n    persistence = 1:persis - 1, # -1 to make binary\n    anonymity = 1:anon - 1, \n    topic = 1:topics,\n    repetition = 1:repetition) %&gt;% \n    as.data.frame() %&gt;% \n    rownames_to_column(\"id\") %&gt;% \n    mutate(\n      group = rep(c(1:groups), each = groupsize))\n}"
  },
  {
    "objectID": "power_analyses.html#simulate-data",
    "href": "power_analyses.html#simulate-data",
    "title": "Power Analyses",
    "section": "Simulate data",
    "text": "Simulate data\n\nsim_d &lt;- function(d_frame, \n                  seed, # make results reproducible\n                  effects, # vector of effects we anticipate\n                  sd, \n                  groupsize, \n                  ...){\n  \n  # function to simulate data\n\n  # set.seed(seed)  # uncomment to make results reproducible\n  \n  # compute how many participants per cell (exp. condition)\n  n_cell &lt;- groupsize_n * topics_n * repetition_n\n  \n  # create the DV. \n  # For now, this will be standardized, bc. of lack of concrete data\n  d_frame$expressions &lt;- NA # create variable that'll be filled next\n  \n  # run loop creating DVs\n  for(i in 1 : repetition_n){\n    for(j in 1 : topics_n){\n      d_frame[d_frame$persistence == 0 & \n              d_frame$anonymity == 0 & \n              d_frame$repetition == i & \n              d_frame$topic == j, ]$expressions &lt;- \n        rnorm(groupsize_n, effects[\"pers0_anon_0_m\"], sd)\n      d_frame[d_frame$persistence == 1 & \n              d_frame$anonymity == 0 & \n              d_frame$repetition == i & \n              d_frame$topic == j, ]$expressions &lt;- \n        rnorm(groupsize_n, effects[\"pers1_anon_0_m\"], sd)\n      d_frame[d_frame$persistence == 0 & \n              d_frame$anonymity == 1 & \n              d_frame$repetition == i & \n              d_frame$topic == j, ]$expressions &lt;- \n        rnorm(groupsize_n, effects[\"pers0_anon_1_m\"], sd)\n      d_frame[d_frame$persistence == 1 & \n              d_frame$anonymity == 1 & \n              d_frame$repetition == i & \n              d_frame$topic == j, ]$expressions &lt;- \n        rnorm(groupsize_n, effects[\"pers1_anon_1_m\"], sd)\n    }\n  }\n  return(d_frame)\n}"
  },
  {
    "objectID": "power_analyses.html#analyze-data",
    "href": "power_analyses.html#analyze-data",
    "title": "Power Analyses",
    "section": "Analyze data",
    "text": "Analyze data\n\nanalyze_d &lt;- function(object, approach, ...) {\n\n  # function to analyze data and to extract results\n  \n  # get means\n  means &lt;- group_by(object, persistence, anonymity) %&gt;% \n    summarize(mean = mean(expressions), .groups = 'drop')\n  \n  results &lt;- data.frame(\n    reps = repetition_n,\n    n = nrow(object), \n    per0_anon0_m = filter(means, persistence == 0, anonymity == 0)$mean,\n    per0_anon1_m = filter(means, persistence == 0, anonymity == 1)$mean,\n    per1_anon0_m = filter(means, persistence == 1, anonymity == 0)$mean,\n    per1_anon1_m = filter(means, persistence == 1, anonymity == 1)$mean\n  )\n\n  \n    # get estimates from regression\n    fit &lt;- lm(expressions ~ persistence + anonymity, object)\n    fit_rslt &lt;- tidy(fit)\n  \n    # combine result\n    results &lt;- cbind(\n      results,\n      persistence_est = fit_rslt[fit_rslt$term == \"persistence\",]$estimate,\n      persistence_p = fit_rslt[fit_rslt$term == \"persistence\",]$p.value,\n      anonymity_est = fit_rslt[fit_rslt$term == \"anonymity\",]$estimate,\n      anonymity_p = fit_rslt[fit_rslt$term == \"anonymity\",]$p.value\n    )\n  return(results)\n}"
  },
  {
    "objectID": "power_analyses.html#design-and-simulate",
    "href": "power_analyses.html#design-and-simulate",
    "title": "Power Analyses",
    "section": "Design and simulate",
    "text": "Design and simulate\n\ndes_sim_fit &lt;- function(...){\n  \n  # function to report and extract results\n  \n  d_frame &lt;- generate_design(...)\n  d &lt;- sim_d(d_frame, ...)\n  analyze_d(d, ...)\n}"
  },
  {
    "objectID": "power_analyses.html#estimate-power",
    "href": "power_analyses.html#estimate-power",
    "title": "Power Analyses",
    "section": "Estimate power",
    "text": "Estimate power\n\nest_pow &lt;- function(sims_n, approach, ...){\n  # function to run analyse sims_n times\n\n  tibble(sim = 1:sims_n) %&gt;% \n  mutate(\n    effect = map(sim, \n                 des_sim_fit, \n                 groupsize = groupsize_n, \n                 persis = persis_n, \n                 anon = anon_n, \n                 topics = topics_n, \n                 repetition = repetition_n, \n                 effects = effects_est, \n                 sd = sd_est,\n                 approach = approach)\n    ) %&gt;%\n  unnest(effect) %&gt;%\n  as.data.frame()\n}"
  },
  {
    "objectID": "power_analyses.html#set-up",
    "href": "power_analyses.html#set-up",
    "title": "Power Analyses",
    "section": "Set-up",
    "text": "Set-up\nWe first create an empty data frame, in which we will then later simulate the data.\n\n# create design frame\nd_frame &lt;- generate_design(\n  groupsize  = groupsize_n,\n  persis     = persis_n,  \n  anon      = anon_n,     \n  topics     = topics_n,  \n  repetition = repetition_n\n  )\nd_frame\n\nCheck if data-frame is alright.\n\nxtabs(~persistence + anonymity + topic + repetition, d_frame)\n\n, , topic = 1, repetition = 1\n\n           anonymity\npersistence  0  1\n          0 20 20\n          1 20 20\n\n, , topic = 2, repetition = 1\n\n           anonymity\npersistence  0  1\n          0 20 20\n          1 20 20\n\n, , topic = 3, repetition = 1\n\n           anonymity\npersistence  0  1\n          0 20 20\n          1 20 20\n\n, , topic = 1, repetition = 2\n\n           anonymity\npersistence  0  1\n          0 20 20\n          1 20 20\n\n, , topic = 2, repetition = 2\n\n           anonymity\npersistence  0  1\n          0 20 20\n          1 20 20\n\n, , topic = 3, repetition = 2\n\n           anonymity\npersistence  0  1\n          0 20 20\n          1 20 20\n\n, , topic = 1, repetition = 3\n\n           anonymity\npersistence  0  1\n          0 20 20\n          1 20 20\n\n, , topic = 2, repetition = 3\n\n           anonymity\npersistence  0  1\n          0 20 20\n          1 20 20\n\n, , topic = 3, repetition = 3\n\n           anonymity\npersistence  0  1\n          0 20 20\n          1 20 20\n\n, , topic = 1, repetition = 4\n\n           anonymity\npersistence  0  1\n          0 20 20\n          1 20 20\n\n, , topic = 2, repetition = 4\n\n           anonymity\npersistence  0  1\n          0 20 20\n          1 20 20\n\n, , topic = 3, repetition = 4\n\n           anonymity\npersistence  0  1\n          0 20 20\n          1 20 20\n\n\nAllocation of participants to experimental groups worked just fine."
  },
  {
    "objectID": "power_analyses.html#simulate-data-1",
    "href": "power_analyses.html#simulate-data-1",
    "title": "Power Analyses",
    "section": "Simulate data",
    "text": "Simulate data\nLet’s create a single data-set and analyze it.\n\nd &lt;- sim_d(d_frame, seed = 1, effects_est, sd_est, groupsize_n)\nwrite.csv(d, \"data/data_simulated.csv\") # save data."
  },
  {
    "objectID": "power_analyses.html#analyse-data",
    "href": "power_analyses.html#analyse-data",
    "title": "Power Analyses",
    "section": "Analyse data",
    "text": "Analyse data\nLet’s check if means were created alright:\n\nd %&gt;% \n  group_by(persistence, anonymity) %&gt;% \n  summarize(mean = mean(expressions), .groups = 'drop') %&gt;% \n  kable()\n\n\n\n\npersistence\nanonymity\nmean\n\n\n\n\n0\n0\n-0.15\n\n\n0\n1\n-0.03\n\n\n1\n0\n-0.45\n\n\n1\n1\n-0.19\n\n\n\n\n\nSample size small and single study, but general tendency seems to be alright.\nLet’s also quickly run a regression.\n\nfit &lt;- lm(expressions ~ persistence + anonymity, d)\nsummary(fit)\n\n\nCall:\nlm(formula = expressions ~ persistence + anonymity, data = d)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-3.011 -0.675 -0.029  0.691  3.792 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  -0.1817     0.0577   -3.15  0.00170 ** \npersistence  -0.2316     0.0667   -3.47  0.00054 ***\nanonymity     0.1848     0.0667    2.77  0.00570 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1 on 957 degrees of freedom\nMultiple R-squared:  0.0202,    Adjusted R-squared:  0.0182 \nF-statistic: 9.87 on 2 and 957 DF,  p-value: 0.000057\n\n\nResults look reasonable. Both persistence and anonymity reduce disclosure."
  },
  {
    "objectID": "power_analyses.html#set-up-1",
    "href": "power_analyses.html#set-up-1",
    "title": "Power Analyses",
    "section": "Set-Up",
    "text": "Set-Up\n\nn_sim &lt;- 1000\nn_reps &lt;- 5\n\nWe simulate 1000 data sets for the power analyses. Up to 5 times will the set-up be repeated."
  },
  {
    "objectID": "power_analyses.html#small-effects",
    "href": "power_analyses.html#small-effects",
    "title": "Power Analyses",
    "section": "Small effects",
    "text": "Small effects\n\nRun analyses\nLet’s next run our actual power analysis, using the effect sizes defined above (small standardized effects).\nWe run a power analysis with 1000 simulations per design. We test 5 designs, that is 1 to 5 repetitions.\n\n# create empy data frame\ncolumns &lt;- c(\"sim\", \"reps\", \"per0_anon0_m\", \"per0_anon1_m\", \n             \"per1_anon0_m\", \"per1_anon1_m\", \"persistence_est\", \n             \"persistence_p\", \"anonymity_est\", \"anonymity_p\", \"n\")\nsims_freq_s &lt;- data.frame(matrix(nrow = 0, ncol = length(columns))) \ncolnames(sims_freq_s) = columns\n\nt1 &lt;- Sys.time()\nfor(i in 1 : n_reps){\n  repetition_n  &lt;- i\n  sims_freq_s &lt;- rbind(sims_freq_s, est_pow(approach = \"frequentist\", sims_n = n_sim))\n}\nt2 &lt;- Sys.time()\nt2 - t1\n\nTime difference of 43 secs\n\n\n\n\nVisualization\nLet’s inspect the results. First persistence:\n\nggplot(sims_freq_s) +\n  geom_point(aes(sim, persistence_est, color = persistence_p &lt; .05), \n             size = .2, alpha = .5) + \n  scale_color_manual(values = c(\"darkgrey\", \"blue\")) +\n  facet_wrap(facets = \"reps\", nrow = 1) +\n  labs(color = \"significant\")\n\n\n\n\n\n\n\n\nShows that with more repetitions, effect size move closer to actual population value.\nTo make sure, let’s next check anonymity – should provide identical results.\n\nggplot(sims_freq_s) +\n  geom_point(aes(sim, anonymity_est, color = anonymity_p &lt; .05), \n             size = .2, alpha = .5) + \n  scale_color_manual(values = c(\"darkgrey\", \"blue\")) +\n  facet_wrap(facets = \"reps\", nrow = 1) +\n  labs(color = \"significant\")\n\n\n\n\n\n\n\n\nLooks good.\n\n\nCell means & main effects\nNext, we compute the average means in the four cells averaged across simulations, plus the two main effects. This is more of a sanity check to see if our population values can be reproduced.\n\nsims_freq_s %&gt;% \n  group_by(reps) %&gt;% \n  summarise(per0_anon0 = mean(per0_anon0_m),\n            per0_anon1 = mean(per0_anon1_m),\n            per1_anon0 = mean(per1_anon0_m),\n            per1_anon1 = mean(per1_anon1_m),\n            persistence = mean(persistence_est), \n            anonymity = mean(anonymity_est)\n            ) %&gt;% \n  as.data.frame() %&gt;% \n  kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\nreps\nper0_anon0\nper0_anon1\nper1_anon0\nper1_anon1\npersistence\nanonymity\n\n\n\n\n1\n-0.2\n0\n-0.4\n-0.2\n-0.2\n0.2\n\n\n2\n-0.2\n0\n-0.4\n-0.2\n-0.2\n0.2\n\n\n3\n-0.2\n0\n-0.4\n-0.2\n-0.2\n0.2\n\n\n4\n-0.2\n0\n-0.4\n-0.2\n-0.2\n0.2\n\n\n5\n-0.2\n0\n-0.4\n-0.2\n-0.2\n0.2\n\n\n\n\n\nShows that the means resemble those we defined a priori. Same for main effects.\n\n\nPower estimates\nNow, let’s compute power for each number of replication.\n\npower_freq_s &lt;- sims_freq_s %&gt;% \n  group_by(reps) %&gt;% \n  summarise(n = max(n),\n            persistence = sum(persistence_p &lt; .05 & persistence_est &lt; 0) / n_sim,\n            anonymity = sum(anonymity_p &lt; .05 & anonymity_est &gt; 0) / n_sim)\nkable(power_freq_s)\n\n\n\n\nreps\nn\npersistence\nanonymity\n\n\n\n\n1\n240\n0.34\n0.34\n\n\n2\n480\n0.58\n0.57\n\n\n3\n720\n0.77\n0.76\n\n\n4\n960\n0.86\n0.87\n\n\n5\n1200\n0.93\n0.92\n\n\n\n\n\n\ndat_fr_s &lt;- pivot_longer(power_freq_s, c(-reps, -n), names_to = \"manipulation\", values_to = \"effect\")\npower_fig &lt;- ggplot(dat_fr_s, aes(reps, effect, color = manipulation)) +\n  geom_point(alpha = .9) +\n  scale_x_discrete(limits = c(1:n_reps))\npower_fig\n\n\n\n\n\n\n\n\nIf we replicate the study at least 5 times, then we get more than 80% power."
  },
  {
    "objectID": "power_analyses.html#small-to-medium-effects",
    "href": "power_analyses.html#small-to-medium-effects",
    "title": "Power Analyses",
    "section": "Small-to-medium effects",
    "text": "Small-to-medium effects\nLet’s next rerun our power analysis, using slightly larger effect sized (small to medium).\n\npers0_anon_0_m &lt;- -0.35\npers0_anon_1_m &lt;-  0.00\npers1_anon_0_m &lt;- -0.70\npers1_anon_1_m &lt;- -0.35\neffects_est &lt;- c(pers0_anon_0_m, pers0_anon_1_m, pers1_anon_0_m, pers1_anon_1_m)\nnames(effects_est) &lt;- c(\"pers0_anon_0_m\", \"pers0_anon_1_m\", \"pers1_anon_0_m\", \"pers1_anon_1_m\")\nsd_est &lt;- 1\n\n\nRun analyses\nEverything as above, but now assuming larger effects.\n\n# create empy data frame\ncolumns &lt;- c(\"sim\", \"reps\", \"per0_anon0_m\", \"per0_anon1_m\", \n             \"per1_anon0_m\", \"per1_anon1_m\", \"persistence_est\", \n             \"persistence_p\", \"anonymity_est\", \"anonymity_p\", \"n\")\nsims_freq_sm &lt;- data.frame(matrix(nrow = 0, ncol = length(columns))) \ncolnames(sims_freq_sm) = columns\n\nt1 &lt;- Sys.time()\nfor(i in 1 : n_reps){\n  repetition_n  &lt;- i\n  sims_freq_sm &lt;- rbind(sims_freq_sm, est_pow(approach = \"frequentist\", sims_n = n_sim))\n}\nt2 &lt;- Sys.time()\nt2 - t1\n\n\n\nVisualization\nLet’s inspect the results. First persistence:\n\nggplot(sims_freq_sm) +\n  geom_point(aes(sim, persistence_est, color = persistence_p &lt; .05), \n             size = .2, alpha = .5) + \n  scale_color_manual(values = c(\"darkgrey\", \"blue\")) +\n  facet_wrap(facets = \"reps\", nrow = 1) +\n  labs(color = \"significant\")\n\n\n\n\n\n\n\n\nShows that with more repetitions, effect size moves closer to actual population value.\nTo make sure, let’s next check anonymity – should provide identical results.\n\nggplot(sims_freq_sm) +\n  geom_point(aes(sim, anonymity_est, color = anonymity_p &lt; .05), \n             size = .2, alpha = .5) + \n  scale_color_manual(values = c(\"darkgrey\", \"blue\")) +\n  facet_wrap(facets = \"reps\", nrow = 1) +\n  labs(color = \"significant\")\n\n\n\n\n\n\n\n\nLooks good.\n\n\nCell means & main effects\nNext, we compute the average means in the four cells averaged across simulations, plus the two main effects. This is more of a sanity check to see if our population values can be reproduced.\n\nsims_freq_sm %&gt;% \n  group_by(reps) %&gt;% \n  summarise(per0_anon0 = mean(per0_anon0_m),\n            per0_anon1 = mean(per0_anon1_m),\n            per1_anon0 = mean(per1_anon0_m),\n            per1_anon1 = mean(per1_anon1_m),\n            persistence = mean(persistence_est), \n            anonymity = mean(anonymity_est)\n            ) %&gt;% \n  kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\nreps\nper0_anon0\nper0_anon1\nper1_anon0\nper1_anon1\npersistence\nanonymity\n\n\n\n\n1\n-0.35\n0\n-0.7\n-0.35\n-0.35\n0.35\n\n\n2\n-0.35\n0\n-0.7\n-0.35\n-0.35\n0.35\n\n\n3\n-0.35\n0\n-0.7\n-0.35\n-0.35\n0.35\n\n\n4\n-0.35\n0\n-0.7\n-0.35\n-0.35\n0.35\n\n\n5\n-0.35\n0\n-0.7\n-0.35\n-0.35\n0.35\n\n\n\n\n\nShows that the means resemble those we defined a priori. Same for main effects.\n\n\nPower estimates\nNow, let’s compute power for each number of replication.\n\npower_freq_sm &lt;- sims_freq_sm %&gt;% \n  group_by(reps) %&gt;% \n  summarise(persistence = sum(persistence_p &lt; .05 & persistence_est &lt; 0) / n_sim,\n            anonymity = sum(anonymity_p &lt; .05 & anonymity_est &gt; 0) / n_sim,\n            n = max(n))\nkable(power_freq_sm)\n\n\n\n\nreps\npersistence\nanonymity\nn\n\n\n\n\n1\n0.79\n0.77\n240\n\n\n2\n0.97\n0.97\n480\n\n\n3\n1.00\n1.00\n720\n\n\n4\n1.00\n1.00\n960\n\n\n5\n1.00\n1.00\n1200\n\n\n\n\n\nIf we replicate the study at least 3 times, then we get more than 80% power.\n\ndat_fr_sm &lt;- pivot_longer(power_freq_sm, c(-reps, -n), names_to = \"manipulation\", values_to = \"effect\")\npower_fig &lt;- ggplot(dat_fr_sm, aes(reps, effect, color = manipulation)) +\n  geom_point(alpha = .9) +\n  scale_x_discrete(limits = c(1:n_reps))\npower_fig"
  },
  {
    "objectID": "power_analyses.html#tables",
    "href": "power_analyses.html#tables",
    "title": "Power Analyses",
    "section": "Tables",
    "text": "Tables\nFor small effects:\n\ntab_s &lt;- cbind(\n  Replications = power_freq_s$reps,\n  N = power_freq_s$n,\n  pers_power = power_freq_s$persistence,\n  anon_power = power_freq_s$anonymity\n)\nkable(tab_s)\n\n\n\n\nReplications\nN\npers_power\nanon_power\n\n\n\n\n1\n240\n0.34\n0.34\n\n\n2\n480\n0.58\n0.57\n\n\n3\n720\n0.77\n0.76\n\n\n4\n960\n0.86\n0.87\n\n\n5\n1200\n0.93\n0.92\n\n\n\n\n\nFor small-to-medium effects\n\ntab_sm &lt;- cbind(\n  Replications = power_freq_sm$reps,\n  N = power_freq_sm$n,\n  pers_power = power_freq_sm$persistence, \n  anon_power = power_freq_sm$anonymity\n)\nkable(tab_sm)\n\n\n\n\nReplications\nN\npers_power\nanon_power\n\n\n\n\n1\n240\n0.79\n0.77\n\n\n2\n480\n0.97\n0.97\n\n\n3\n720\n1.00\n1.00\n\n\n4\n960\n1.00\n1.00\n\n\n5\n1200\n1.00\n1.00"
  },
  {
    "objectID": "power_analyses.html#figures",
    "href": "power_analyses.html#figures",
    "title": "Power Analyses",
    "section": "Figures",
    "text": "Figures\n\n# dat_bf_s &lt;- pivot_longer(power_bf_s, c(-reps, -n), names_to = \"manipulation\", values_to = \"effect\")\n# dat_bf_s$effectsize &lt;- \"small\"\n# dat_bf_sm &lt;- pivot_longer(power_bf_sm, c(-reps, -n), names_to = \"manipulation\", values_to = \"effect\")\n# dat_bf_sm$effectsize &lt;- \"small-to-medium\"\n# dat_bf &lt;- rbind(dat_bf_s, dat_bf_sm)\n# dat_bf$analysis &lt;- \"Bayes Factor &gt; 10\"\n# dat_bf$manipulation &lt;- recode(dat_bf$manipulation, `bf_pers &gt; 10` = \"persistence\", `BF_anon &gt; 10` = \"anonymity\")\n\ndat_fr_s$effectsize &lt;- \"small\"\ndat_fr_sm$effectsize &lt;- \"small-to-medium\"\ndat_fr &lt;- rbind(dat_fr_s, dat_fr_sm)\n# dat_fr$analysis &lt;- \"Frequentist\"\n\ndat &lt;- dat_fr %&gt;% \n  rename(Manipulation = manipulation,\n         `Effect size` = effectsize,\n         Effect = effect,\n         Replications = reps) %&gt;% \n  mutate(\n    # analysis = factor(analysis, levels = c(\"Frequentist\", \"Bayes Factor &gt; 10\")),\n    `Effect size` = factor(`Effect size`, levels = c(\"small-to-medium\", \"small\")))\n\npower_fig &lt;- ggplot(dat, aes(Replications, Effect, color = `Effect size`, shape = Manipulation)) +\n  scale_color_manual(values=c(\"black\", \"grey60\")) +\n  geom_vline(xintercept = 4, linetype = \"dashed\", color = \"grey\") + \n  geom_point(alpha = .9) +\n  scale_x_discrete(limits = c(1:n_reps))\npower_fig\n\n\n\n\n\n\n\nggsave(\"figures/fig_power.png\", width = 8, height = 4)"
  },
  {
    "objectID": "data_wrangling.html",
    "href": "data_wrangling.html",
    "title": "Data preparation",
    "section": "",
    "text": "This document contains the code to prepare the data of the study “The Effects of Technological Affordances on Political Opinion Expression in Social Media: A Field Experiment”.\nMain output of this code is the dataset DataAggregated_T1T2.csv which contains all data from the first and second questionnaire, matched with aggregated content data from the field phase (e.g., number of contributions / words / opinion expressions per participant).\nFor reasons of privacy, the raw data cannot be included in the online supplement. However, we do include the final edited dataset, which is anonymous.\nlibrary(lavaan)\nlibrary(ltm)\nlibrary(readxl)\nlibrary(tidyverse)\nlibrary(sjlabelled)"
  },
  {
    "objectID": "data_wrangling.html#merge-t2-data-to-discord-t1-dataset",
    "href": "data_wrangling.html#merge-t2-data-to-discord-t1-dataset",
    "title": "Data preparation",
    "section": "Merge T2 Data to Discord / T1 Dataset",
    "text": "Merge T2 Data to Discord / T1 Dataset\n\n#### read T2 data ####\ndat_T2 &lt;- read.csv(\"data/data_T2_Fragebogen.csv\", header = TRUE, sep = \";\")\nnrow(dat_T2)\n\n[1] 1372\n\n# indicate which variables are from T2 Questionnaire\ncolnames(dat_T2) &lt;- paste(colnames(dat_T2), \"T2\", sep = \"_\") \ndat_T2 &lt;- dat_T2[dat_T2$FINISHED_T2 == 1, ]\nnrow(dat_T2)\n\n[1] 1024\n\nlength(which(table(dat_T2$IV01_RV1_T2) &gt;= 2))\n\n[1] 25\n\n\n25 people have multiple complete datasets in the T2 survey. Keep the first version\n\ndat_T2$IV01_RV1_T2 &lt;- as.integer(dat_T2$IV01_RV1_T2)\ndat_merged_T1T2 &lt;- left_join(dat_full_T1, dat_T2, by = c(\"case\" = \"IV01_RV1_T2\"), \n                             relationship = \"many-to-one\", multiple = \"first\", \n                             keep = TRUE)\n\nnrow(dat_merged_T1T2)\n\n[1] 13439\n\n\nIV01_RV1_T2 contains the case numbers in the T2 dataset. Individuals not in T2 receive NA.\n\nnrow(dat)\n\n[1] 13252\n\nnrow(dat_merged_T1T2) \n\n[1] 13439\n\nncol(dat_merged_T1T2) # + 1 (roles)\n\n[1] 471\n\nncol(dat) + ncol(dat_T1) + ncol(dat_T2)\n\n[1] 470\n\nwrite.csv(dat_merged_T1T2, \"data/Data_Discord_AllVP_T1T2.csv\", row.names = FALSE)\n\nlength(unique(dat_merged_T1T2$case))\n\n[1] 960\n\nlength(unique(dat_merged_T1T2$CASE_T1))\n\n[1] 960\n\nlength(unique(dat_merged_T1T2$IV01_RV1_T2))\n\n[1] 706\n\n\n706 Discord users filled out T2\n\nAdd Experimental Condition based on “roles” variable\n\ntable(dat_merged_T1T2$roles)\n\n\n Berlin1  Berlin2  Berlin3  Berlin4   Dubai1   Dubai2   Dubai3   Dubai4 \n     373      117      159      518      123      228      163      257 \nFlorenz1 Florenz2 Florenz3 Florenz4  London1  London2  London3  London4 \n     206      224      158      161      365      336      842      148 \n Madrid1  Madrid2  Madrid3  Madrid4    Oslo1    Oslo2    Oslo3    Oslo4 \n     156      275      239      345      205      342      239      256 \n  Paris1   Paris2   Paris3   Paris4    Prag1    Prag2    Prag3    Prag4 \n     286      109      240      193      322      187      397      255 \n    Rio1     Rio2     Rio3     Rio4     Rom1     Rom2     Rom3     Rom4 \n     317      222      406      187      440      379      106      113 \n Sydney1  Sydney2  Sydney3  Sydney4   Tokio1   Tokio2   Tokio3   Tokio4 \n     613      139      200      277      220      275      753      368 \n\n#### Anonymity ####\ndat_merged_T1T2$anonymity &lt;- NA\n\ndat_merged_T1T2$anonymity &lt;- ifelse(\n  grepl(\n    \"rom|london|madrid|prag|berlin|paris\", \n    dat_merged_T1T2$roles, \n    ignore.case = TRUE\n    ), \n  \"low\", \n  ifelse(\n    grepl(\n      \"tokio|dubai|oslo|rio|florenz|sydney\", \n      dat_merged_T1T2$roles, \n      ignore.case = TRUE\n      ), \n    \"high\", \n    \"other\"\n    )\n  )\n\ntable(dat_merged_T1T2$anonymity)\n\n\nhigh  low \n6539 6900 \n\n#### Persistence ####\ndat_merged_T1T2$persistence &lt;- NA\n\ndat_merged_T1T2$persistence &lt;- ifelse(\n  grepl(\n    \"london|dubai|prag|rio|paris|sydney\", \n    dat_merged_T1T2$roles, \n    ignore.case = TRUE)\n  , \"low\",\n  ifelse(\n    grepl(\n      \"rom|tokio|madrid|oslo|berlin|florenz\", \n      dat_merged_T1T2$roles, \n      ignore.case = TRUE\n      ), \n    \"high\", \n    \"other\"\n    )\n  )\n\ntable(dat_merged_T1T2$persistence)\n\n\nhigh  low \n6627 6812 \n\n#### Topic ####\ndat_merged_T1T2$topic &lt;- NA \n\ndat_merged_T1T2$topic &lt;- ifelse(\n  grepl(\n    \"rom|london|tokio|dubai\", \n    dat_merged_T1T2$roles, \n    ignore.case = TRUE\n    ), \n  \"gender\", \n  ifelse(\n    grepl(\n      \"madrid|prag|oslo|rio\", \n      dat_merged_T1T2$roles, \n      ignore.case = TRUE\n      ), \n    \"climate\", \n    ifelse(\n      grepl(\n        \"berlin|paris|florenz|sydney\", \n        dat_merged_T1T2$roles, \n        ignore.case = TRUE\n        ), \n      \"migration\", \n      \"other\"\n      )\n    )\n  )\n\ntable(dat_merged_T1T2$topic)\n\n\n  climate    gender migration \n     4350      5116      3973 \n\n\nNote: The numbers above cannot be interpreted as the exact numbers of messages per participant, since the rows in the dat_merged_T1T2 dataset also contain rows for participants which did not write anything (with message then being NA)."
  },
  {
    "objectID": "planned_analyses.html",
    "href": "planned_analyses.html",
    "title": "Planned analyses",
    "section": "",
    "text": "library(brms)\nlibrary(ggplot2)\nlibrary(knitr)\nlibrary(lme4)\nlibrary(magrittr)\nlibrary(mice)\nlibrary(tidyverse)\nIn what follows, we outline how we plan to analyze the data. Please note that depending on violation of assumptions or non-convergence of models, we likely need to further adjust the model, which is why we cannot preregister the exact model we will ultimately run. But the general approach will be as follows."
  },
  {
    "objectID": "planned_analyses.html#bayesian-mixed-effects-modeling",
    "href": "planned_analyses.html#bayesian-mixed-effects-modeling",
    "title": "Planned analyses",
    "section": "Bayesian mixed effects modeling",
    "text": "Bayesian mixed effects modeling\n\nFixed effects\n\nfit_fe &lt;- \n  brm_multiple(\n    expressions ~ 1 + persistence * anonymity + \n      (1 | topic) + \n      (1 | group), \n    data = d,\n    silent = 2,\n    refresh = 0,  \n    chains = 2,\n    family = zero_inflated_poisson(\"log\")\n    )\n\nRunning /Library/Frameworks/R.framework/Resources/bin/R CMD SHLIB foo.c\nusing C compiler: ‘Apple clang version 15.0.0 (clang-1500.3.9.4)’\nusing SDK: ‘MacOSX14.4.sdk’\nclang -arch arm64 -I\"/Library/Frameworks/R.framework/Resources/include\" -DNDEBUG   -I\"/Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library/Rcpp/include/\"  -I\"/Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library/RcppEigen/include/\"  -I\"/Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library/RcppEigen/include/unsupported\"  -I\"/Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library/BH/include\" -I\"/Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library/StanHeaders/include/src/\"  -I\"/Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library/StanHeaders/include/\"  -I\"/Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library/RcppParallel/include/\"  -I\"/Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library/rstan/include\" -DEIGEN_NO_DEBUG  -DBOOST_DISABLE_ASSERTS  -DBOOST_PENDING_INTEGER_LOG2_HPP  -DSTAN_THREADS  -DUSE_STANC3 -DSTRICT_R_HEADERS  -DBOOST_PHOENIX_NO_VARIADIC_EXPRESSION  -D_HAS_AUTO_PTR_ETC=0  -include '/Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library/StanHeaders/include/stan/math/prim/fun/Eigen.hpp'  -D_REENTRANT -DRCPP_PARALLEL_USE_TBB=1   -I/opt/R/arm64/include    -fPIC  -falign-functions=64 -Wall -g -O2  -c foo.c -o foo.o\nIn file included from &lt;built-in&gt;:1:\nIn file included from /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library/StanHeaders/include/stan/math/prim/fun/Eigen.hpp:22:\nIn file included from /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library/RcppEigen/include/Eigen/Dense:1:\nIn file included from /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library/RcppEigen/include/Eigen/Core:19:\n/Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library/RcppEigen/include/Eigen/src/Core/util/Macros.h:679:10: fatal error: 'cmath' file not found\n#include &lt;cmath&gt;\n         ^~~~~~~\n1 error generated.\nmake: *** [foo.o] Error 1\n\nsummary(fit_fe)\n\n Family: zero_inflated_poisson \n  Links: mu = log; zi = identity \nFormula: expressions ~ 1 + persistence * anonymity + (1 | topic) + (1 | group) \n   Data: d (Number of observations: 960) \n  Draws: 200 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 200000\n\nMultilevel Hyperparameters:\n~group (Number of levels: 48) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.03      0.02     0.00     0.08 1.01    17434    53849\n\n~topic (Number of levels: 3) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.08      0.12     0.00     0.46 1.04     2745      924\n\nRegression Coefficients:\n                      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nIntercept                 0.81      0.08     0.66     0.97 1.07     1655\npersistence              -0.10      0.05    -0.19    -0.01 1.01     8941\nanonymity                 0.12      0.05     0.03     0.21 1.01     8891\npersistence:anonymity     0.13      0.09    -0.06     0.31 1.01     8432\n                      Tail_ESS\nIntercept                 1128\npersistence              37367\nanonymity                59711\npersistence:anonymity    28623\n\nFurther Distributional Parameters:\n   Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nzi     0.03      0.01     0.01     0.06 1.02     4874     3452\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n\n\nRandom effects\n\nfit_re &lt;- \n  brm_multiple(\n    expressions ~ 1 + persistence * anonymity + \n      (1 + persistence * anonymity | topic) + \n      (1 + persistence * anonymity | group), \n    data = d,\n    silent = 2,\n    refresh = 0, \n    chains = 2,\n    family = zero_inflated_poisson(\"log\")\n    )\n\nRunning /Library/Frameworks/R.framework/Resources/bin/R CMD SHLIB foo.c\nusing C compiler: ‘Apple clang version 15.0.0 (clang-1500.3.9.4)’\nusing SDK: ‘MacOSX14.4.sdk’\nclang -arch arm64 -I\"/Library/Frameworks/R.framework/Resources/include\" -DNDEBUG   -I\"/Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library/Rcpp/include/\"  -I\"/Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library/RcppEigen/include/\"  -I\"/Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library/RcppEigen/include/unsupported\"  -I\"/Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library/BH/include\" -I\"/Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library/StanHeaders/include/src/\"  -I\"/Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library/StanHeaders/include/\"  -I\"/Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library/RcppParallel/include/\"  -I\"/Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library/rstan/include\" -DEIGEN_NO_DEBUG  -DBOOST_DISABLE_ASSERTS  -DBOOST_PENDING_INTEGER_LOG2_HPP  -DSTAN_THREADS  -DUSE_STANC3 -DSTRICT_R_HEADERS  -DBOOST_PHOENIX_NO_VARIADIC_EXPRESSION  -D_HAS_AUTO_PTR_ETC=0  -include '/Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library/StanHeaders/include/stan/math/prim/fun/Eigen.hpp'  -D_REENTRANT -DRCPP_PARALLEL_USE_TBB=1   -I/opt/R/arm64/include    -fPIC  -falign-functions=64 -Wall -g -O2  -c foo.c -o foo.o\nIn file included from &lt;built-in&gt;:1:\nIn file included from /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library/StanHeaders/include/stan/math/prim/fun/Eigen.hpp:22:\nIn file included from /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library/RcppEigen/include/Eigen/Dense:1:\nIn file included from /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library/RcppEigen/include/Eigen/Core:19:\n/Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library/RcppEigen/include/Eigen/src/Core/util/Macros.h:679:10: fatal error: 'cmath' file not found\n#include &lt;cmath&gt;\n         ^~~~~~~\n1 error generated.\nmake: *** [foo.o] Error 1\n\nsummary(fit_re)\n\n Family: zero_inflated_poisson \n  Links: mu = log; zi = identity \nFormula: expressions ~ 1 + persistence * anonymity + (1 + persistence * anonymity | topic) + (1 + persistence * anonymity | group) \n   Data: d (Number of observations: 960) \n  Draws: 200 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 200000\n\nMultilevel Hyperparameters:\n~group (Number of levels: 48) \n                                       Estimate Est.Error l-95% CI u-95% CI\nsd(Intercept)                              0.03      0.02     0.00     0.09\nsd(persistence)                            0.06      0.05     0.00     0.18\nsd(anonymity)                              0.06      0.05     0.00     0.18\nsd(persistence:anonymity)                  0.13      0.10     0.00     0.36\ncor(Intercept,persistence)                -0.03      0.45    -0.82     0.80\ncor(Intercept,anonymity)                  -0.02      0.45    -0.83     0.80\ncor(persistence,anonymity)                 0.03      0.45    -0.80     0.82\ncor(Intercept,persistence:anonymity)       0.03      0.45    -0.80     0.83\ncor(persistence,persistence:anonymity)    -0.02      0.45    -0.82     0.81\ncor(anonymity,persistence:anonymity)      -0.02      0.45    -0.82     0.80\n                                       Rhat Bulk_ESS Tail_ESS\nsd(Intercept)                          1.01    30498    22262\nsd(persistence)                        1.00    48431    63936\nsd(anonymity)                          1.01    15705    13221\nsd(persistence:anonymity)              1.01    10178     6521\ncor(Intercept,persistence)             1.01    50963    35279\ncor(Intercept,anonymity)               1.01    10997     4004\ncor(persistence,anonymity)             1.00    62763    56409\ncor(Intercept,persistence:anonymity)   1.00    42269    60115\ncor(persistence,persistence:anonymity) 1.01    30295    73540\ncor(anonymity,persistence:anonymity)   1.01    21876    69623\n\n~topic (Number of levels: 3) \n                                       Estimate Est.Error l-95% CI u-95% CI\nsd(Intercept)                              0.12      0.17     0.00     0.64\nsd(persistence)                            0.28      0.34     0.01     1.28\nsd(anonymity)                              0.25      0.32     0.01     1.18\nsd(persistence:anonymity)                  0.40      0.50     0.01     1.87\ncor(Intercept,persistence)                -0.03      0.47    -0.84     0.82\ncor(Intercept,anonymity)                   0.02      0.47    -0.83     0.85\ncor(persistence,anonymity)                -0.05      0.46    -0.86     0.82\ncor(Intercept,persistence:anonymity)       0.02      0.46    -0.83     0.84\ncor(persistence,persistence:anonymity)    -0.03      0.46    -0.84     0.82\ncor(anonymity,persistence:anonymity)       0.02      0.46    -0.82     0.84\n                                       Rhat Bulk_ESS Tail_ESS\nsd(Intercept)                          1.02     8353     2840\nsd(persistence)                        1.02     6855     2664\nsd(anonymity)                          1.01     9196     3439\nsd(persistence:anonymity)              1.02     9187     7182\ncor(Intercept,persistence)             1.01    20993    56190\ncor(Intercept,anonymity)               1.01    14624     6647\ncor(persistence,anonymity)             1.01    22094    18190\ncor(Intercept,persistence:anonymity)   1.00    50244    71238\ncor(persistence,persistence:anonymity) 1.01    14783    35239\ncor(anonymity,persistence:anonymity)   1.01    34864    40821\n\nRegression Coefficients:\n                      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nIntercept                 0.81      0.10     0.60     1.02 1.03     3534\npersistence              -0.10      0.21    -0.60     0.34 1.03     4376\nanonymity                 0.12      0.20    -0.31     0.56 1.02     5889\npersistence:anonymity     0.12      0.33    -0.59     0.84 1.02     8115\n                      Tail_ESS\nIntercept                 2553\npersistence               1755\nanonymity                 2891\npersistence:anonymity     7981\n\nFurther Distributional Parameters:\n   Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nzi     0.03      0.01     0.01     0.06 1.01     8739    53150\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1)."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "The Effects of Technological Affordances on Political Opinion Expression in Social Media: A Field Experiment",
    "section": "",
    "text": "On this website, you can find the companion material for the paper The Effects of Technological Affordances on Political Opinion Expression in Social Media: A Field Experiment.\nYou can find the following information here:\n\nStatistical analyses\nStatistical analyses with words as outcome\nPower analyses\nPlanned analyses\nData preparation\nDeviations from preregistration\n\nThis website is produced directly from the project’s github repository. You can download the material and the data, file an issue, or submit a pull request."
  },
  {
    "objectID": "analyses_words_new.html",
    "href": "analyses_words_new.html",
    "title": "Analyses with words as outcome",
    "section": "",
    "text": "library(brms)\nlibrary(ggplot2)\nlibrary(kableExtra)\nlibrary(lme4)\nlibrary(lmerTest)\nlibrary(rmarkdown)\nlibrary(performance)\nlibrary(see)\nlibrary(sjmisc)\nlibrary(tidyverse)\n\noptions(\n  digits = 3\n)\nset.seed(170819)\n\n\n\n\n\n# function to silence brms output\nhush &lt;- \n  function(\n    code\n    ){\n    sink(\"/dev/null\")\n    tmp = code\n    sink()\n    return(tmp)\n    }\n\n\n\n\n\nd_words &lt;- read_csv(\"data/DataAggregated_T1T2_nwords.csv\")\nd &lt;- read_csv(\"data/data.csv\")\n\n# get words from dataframe\nd$n_Words &lt;- d_words$n_Words\n\n# same as above; but original file name:\n# d &lt;- read_csv(\"data/DataAggregated_T1T2_costsbenefits.csv\")\n\n# load image for work in IDE\n# load(\"data/image_words.RData\")\n\nd &lt;- d |&gt; \n  rename(\n    group = roles,\n    gender = DE01_T1,\n    age = DE02_01_T1,\n    pol_stance = DE06_01_T1\n  ) |&gt; \n  mutate(\n    female = as.logical(2 - gender),\n    gender = factor(gender, labels = c(\"female\", \"male\")),\n    n_Words = replace_na(n_Words, 0)\n  )\n\n# recode to make as sum coding\nd$anonymity_dev &lt;- factor(d$anonymity)\ncontrasts(d$anonymity_dev) &lt;- contr.sum(2)\nd$persistence_dev &lt;- factor(d$persistence)\ncontrasts(d$persistence_dev) &lt;- contr.sum(2)"
  },
  {
    "objectID": "analyses_words_new.html#packages",
    "href": "analyses_words_new.html#packages",
    "title": "Analyses with words as outcome",
    "section": "",
    "text": "library(brms)\nlibrary(ggplot2)\nlibrary(kableExtra)\nlibrary(lme4)\nlibrary(lmerTest)\nlibrary(rmarkdown)\nlibrary(performance)\nlibrary(see)\nlibrary(sjmisc)\nlibrary(tidyverse)\n\noptions(\n  digits = 3\n)\nset.seed(170819)"
  },
  {
    "objectID": "analyses_words_new.html#custom-functions",
    "href": "analyses_words_new.html#custom-functions",
    "title": "Analyses with words as outcome",
    "section": "",
    "text": "# function to silence brms output\nhush &lt;- \n  function(\n    code\n    ){\n    sink(\"/dev/null\")\n    tmp = code\n    sink()\n    return(tmp)\n    }"
  },
  {
    "objectID": "analyses_words_new.html#data",
    "href": "analyses_words_new.html#data",
    "title": "Analyses with words as outcome",
    "section": "",
    "text": "d_words &lt;- read_csv(\"data/DataAggregated_T1T2_nwords.csv\")\nd &lt;- read_csv(\"data/data.csv\")\n\n# get words from dataframe\nd$n_Words &lt;- d_words$n_Words\n\n# same as above; but original file name:\n# d &lt;- read_csv(\"data/DataAggregated_T1T2_costsbenefits.csv\")\n\n# load image for work in IDE\n# load(\"data/image_words.RData\")\n\nd &lt;- d |&gt; \n  rename(\n    group = roles,\n    gender = DE01_T1,\n    age = DE02_01_T1,\n    pol_stance = DE06_01_T1\n  ) |&gt; \n  mutate(\n    female = as.logical(2 - gender),\n    gender = factor(gender, labels = c(\"female\", \"male\")),\n    n_Words = replace_na(n_Words, 0)\n  )\n\n# recode to make as sum coding\nd$anonymity_dev &lt;- factor(d$anonymity)\ncontrasts(d$anonymity_dev) &lt;- contr.sum(2)\nd$persistence_dev &lt;- factor(d$persistence)\ncontrasts(d$persistence_dev) &lt;- contr.sum(2)"
  },
  {
    "objectID": "analyses_words_new.html#fixed-effects",
    "href": "analyses_words_new.html#fixed-effects",
    "title": "Analyses with words as outcome",
    "section": "Fixed effects",
    "text": "Fixed effects\nWe preregistered to analyze fixed effects.\n\nfit_fe_1 &lt;- \n  hush(\n    brm(\n      n_Words ~ \n        1 + persistence_dev * anonymity_dev + age + female + pol_stance +\n        (1 | topic/group)\n      , data = d\n      , chains = 4\n      , cores = 4\n      , iter = 6000\n      , warmup = 2000\n      , family = zero_inflated_poisson()\n      , control = list(\n        adapt_delta = .95\n        , max_treedepth = 12\n        )\n      , save_pars = save_pars(all = TRUE)\n      , silent = 2\n      )\n  )\n\nWarning: There were 559 divergent transitions after warmup. See\nhttps://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup\nto find out why this is a problem and how to eliminate them.\n\n\nWarning: There were 237 transitions after warmup that exceeded the maximum treedepth. Increase max_treedepth above 12. See\nhttps://mc-stan.org/misc/warnings.html#maximum-treedepth-exceeded\n\n\nWarning: Examine the pairs() plot to diagnose sampling problems\n\n\nShows some convergence warnings. Let’s inspect model.\n\nplot(fit_fe_1, ask = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTrace-plots look alright.\nLet’s look at results.\n\nsummary(fit_fe_1)\n\nWarning: There were 559 divergent transitions after warmup. Increasing\nadapt_delta above 0.95 may help. See\nhttp://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup\n\n\n Family: zero_inflated_poisson \n  Links: mu = log; zi = identity \nFormula: n_Words ~ 1 + persistence_dev * anonymity_dev + age + female + pol_stance + (1 | topic/group) \n   Data: d (Number of observations: 960) \n  Draws: 4 chains, each with iter = 6000; warmup = 2000; thin = 1;\n         total post-warmup draws = 16000\n\nMultilevel Hyperparameters:\n~topic (Number of levels: 3) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.15      0.17     0.00     0.63 1.00     2715     4759\n\n~topic:group (Number of levels: 48) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.37      0.04     0.30     0.45 1.00     2772     4125\n\nRegression Coefficients:\n                                Estimate Est.Error l-95% CI u-95% CI Rhat\nIntercept                           5.78      0.11     5.55     6.02 1.00\npersistence_dev1                   -0.04      0.05    -0.14     0.07 1.00\nanonymity_dev1                     -0.05      0.05    -0.16     0.05 1.00\nage                                 0.01      0.00     0.01     0.01 1.00\nfemaleTRUE                         -0.13      0.00    -0.13    -0.12 1.00\npol_stance                         -0.02      0.00    -0.02    -0.02 1.00\npersistence_dev1:anonymity_dev1     0.05      0.05    -0.06     0.15 1.00\n                                Bulk_ESS Tail_ESS\nIntercept                           4283     4646\npersistence_dev1                    3303     4336\nanonymity_dev1                      3106     4651\nage                                16884    12262\nfemaleTRUE                         10329     7781\npol_stance                         12176     8724\npersistence_dev1:anonymity_dev1     3269     3896\n\nFurther Distributional Parameters:\n   Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nzi     0.21      0.01     0.18     0.23 1.00     8989     7641\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nNo significant effect emerged.\nLet’s inspect ICC\n\nvar_ratio_fe &lt;- performance::variance_decomposition(\n  fit_fe_1\n  , by_group = TRUE)\nvar_ratio_fe\n\n# Random Effect Variances and ICC\n\nConditioned on: all random effects\n\n## Variance Ratio (comparable to ICC)\nRatio: 0.45  CI 95%: [0.12 0.66]\n\n## Variances of Posterior Predicted Distribution\nConditioned on fixed effects: 43442.51  CI 95%: [27273.26 70002.16]\nConditioned on rand. effects: 79718.68  CI 95%: [74074.94 85167.06]\n\n## Difference in Variances\nDifference: 36192.27  CI 95%: [9511.86 52872.17]\n\n\n45.485 percent of variance in words communicated explained by both topics and groups.\nLet’s visualize results to see what they exactly mean.\n\np &lt;- plot(\n  conditional_effects(\n    fit_fe_1\n    ), \n  ask = FALSE,\n  plot = FALSE\n  )\n\np_anon &lt;- \n  p[[\"anonymity_dev\"]] +\n  xlab(\"Anonymity\") +\n  ylab(\"Words\") +\n  scale_x_discrete(\n    limits = rev\n  )\n  #    ) +\n  # scale_y_continuous(\n  #   limits = c(5, 14)\n  #   , breaks = c(6, 8, 10, 12, 14)\n  #   )\n\np_pers &lt;- \n  p[[\"persistence_dev\"]] +\n  xlab(\"Persistence\") +\n  ylab(\"Words\") +\n  scale_x_discrete(\n    limits = rev\n   ) +\n  # scale_y_continuous(\n  #   limits = c(5, 14)\n  #   , breaks = c(6, 8, 10, 12, 14)\n  #   ) +\n  theme(\n    axis.title.y = element_blank()\n    )\n\np_int &lt;- \n  p[[\"persistence_dev:anonymity_dev\"]] +\n  xlab(\"Persistence\") +\n  scale_x_discrete(\n    limits = rev\n     ) +\n  scale_color_discrete(\n    labels = c(\"low\", \"high\")\n    ) +\n  guides(\n    fill = \"none\",\n    color = guide_legend(\n      title = \"Anonymity\"\n      )\n    ) +\n  # scale_y_continuous(\n  #   limits = c(5, 14)\n  #   , breaks = c(6, 8, 10, 12, 14)\n  #   ) +\n  theme(\n    axis.title.y = element_blank()\n    )\n\nplot &lt;- cowplot::plot_grid(\n  p_anon, p_pers, p_int, \n  labels = c('A', 'B', \"C\"), \n  nrow = 1,\n  rel_widths = c(2, 2, 3)\n  )\n\nplot\n\n\n\n\n\n\n\nggsave(\"figures/results.png\", plot, width = 8, height = 4)\n\nShows that there are no main effects. There seems to be a (nonsignificant) interaction effect. In low persistence environment, anonymity is conducive to communication; in high it’s the opposite.\nLet’s look at posteriors\n\np_1 &lt;- \n  pp_check(fit_fe_1) + \n  labs(title = \"Zero-inflated poisson\")\n\nUsing 10 posterior draws for ppc type 'dens_overlay' by default.\n\np_1\n\n\n\n\n\n\n\n\nThe actual distribution cannot be precisely reproduced, but it’s also not too far off."
  },
  {
    "objectID": "analyses_words_new.html#random-effects",
    "href": "analyses_words_new.html#random-effects",
    "title": "Analyses with words as outcome",
    "section": "Random effects",
    "text": "Random effects\nWe preregistered to explore and compare models with random effects. So let’s model how the experimental conditions affect the outcomes differently depending on topic.\n\nfit_re_1 &lt;- \n  hush(\n    brm(\n      n_Words ~ \n        1 + persistence_dev * anonymity_dev + age + female + pol_stance +\n        (1 + persistence_dev * anonymity_dev | topic) + \n        (1 | topic:group)\n      , data = d\n      , chains = 4\n      , cores = 4\n      , iter = 6000\n      , warmup = 2000\n      , family = zero_inflated_poisson()\n      , control = list(\n        adapt_delta = .95\n        , max_treedepth = 15\n        )\n      , save_pars = save_pars(all = TRUE)\n    )\n  )\n\nWarning: There were 525 divergent transitions after warmup. See\nhttps://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup\nto find out why this is a problem and how to eliminate them.\n\n\nWarning: Examine the pairs() plot to diagnose sampling problems\n\n\nShows some convergence warnings.\nLet’s inspect model.\n\nplot(fit_re_1, ask = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTraceplots look alright.\nLet’s look at results.\n\nsummary(fit_re_1)\n\nWarning: There were 525 divergent transitions after warmup. Increasing\nadapt_delta above 0.95 may help. See\nhttp://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup\n\n\n Family: zero_inflated_poisson \n  Links: mu = log; zi = identity \nFormula: n_Words ~ 1 + persistence_dev * anonymity_dev + age + female + pol_stance + (1 + persistence_dev * anonymity_dev | topic) + (1 | topic:group) \n   Data: d (Number of observations: 960) \n  Draws: 4 chains, each with iter = 6000; warmup = 2000; thin = 1;\n         total post-warmup draws = 16000\n\nMultilevel Hyperparameters:\n~topic (Number of levels: 3) \n                                                      Estimate Est.Error\nsd(Intercept)                                             0.26      0.41\nsd(persistence_dev1)                                      0.30      0.45\nsd(anonymity_dev1)                                        0.26      0.40\nsd(persistence_dev1:anonymity_dev1)                       0.38      0.48\ncor(Intercept,persistence_dev1)                          -0.01      0.47\ncor(Intercept,anonymity_dev1)                            -0.00      0.47\ncor(persistence_dev1,anonymity_dev1)                     -0.01      0.47\ncor(Intercept,persistence_dev1:anonymity_dev1)           -0.04      0.46\ncor(persistence_dev1,persistence_dev1:anonymity_dev1)     0.03      0.47\ncor(anonymity_dev1,persistence_dev1:anonymity_dev1)      -0.01      0.46\n                                                      l-95% CI u-95% CI Rhat\nsd(Intercept)                                             0.00     1.43 1.00\nsd(persistence_dev1)                                      0.01     1.64 1.00\nsd(anonymity_dev1)                                        0.00     1.42 1.00\nsd(persistence_dev1:anonymity_dev1)                       0.01     1.75 1.00\ncor(Intercept,persistence_dev1)                          -0.85     0.83 1.00\ncor(Intercept,anonymity_dev1)                            -0.83     0.84 1.00\ncor(persistence_dev1,anonymity_dev1)                     -0.84     0.83 1.00\ncor(Intercept,persistence_dev1:anonymity_dev1)           -0.85     0.81 1.00\ncor(persistence_dev1,persistence_dev1:anonymity_dev1)    -0.82     0.85 1.00\ncor(anonymity_dev1,persistence_dev1:anonymity_dev1)      -0.83     0.83 1.00\n                                                      Bulk_ESS Tail_ESS\nsd(Intercept)                                             6069     6047\nsd(persistence_dev1)                                      4910     6104\nsd(anonymity_dev1)                                        5291     5949\nsd(persistence_dev1:anonymity_dev1)                       3597     4722\ncor(Intercept,persistence_dev1)                          20373    11843\ncor(Intercept,anonymity_dev1)                            22746    11797\ncor(persistence_dev1,anonymity_dev1)                     17202    12534\ncor(Intercept,persistence_dev1:anonymity_dev1)           19402    12987\ncor(persistence_dev1,persistence_dev1:anonymity_dev1)    16036    13418\ncor(anonymity_dev1,persistence_dev1:anonymity_dev1)      12041    13726\n\n~topic:group (Number of levels: 48) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.37      0.04     0.29     0.46 1.00     6304     9612\n\nRegression Coefficients:\n                                Estimate Est.Error l-95% CI u-95% CI Rhat\nIntercept                           5.77      0.25     5.24     6.21 1.00\npersistence_dev1                   -0.04      0.27    -0.58     0.51 1.00\nanonymity_dev1                     -0.06      0.24    -0.59     0.37 1.00\nage                                 0.01      0.00     0.01     0.01 1.00\nfemaleTRUE                         -0.12      0.00    -0.13    -0.12 1.00\npol_stance                         -0.02      0.00    -0.02    -0.02 1.00\npersistence_dev1:anonymity_dev1     0.05      0.33    -0.65     0.75 1.00\n                                Bulk_ESS Tail_ESS\nIntercept                           6778     4541\npersistence_dev1                    7308     5714\nanonymity_dev1                      7787     5343\nage                                15915    15238\nfemaleTRUE                         22631    10396\npol_stance                         16822     9683\npersistence_dev1:anonymity_dev1     6387     4994\n\nFurther Distributional Parameters:\n   Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nzi     0.21      0.01     0.18     0.23 1.00    31492    11056\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nAgain, no main or interaction effects.\nLet’s see if the random effects model fits better\n\nfit_fe_1 &lt;- add_criterion(\n  fit_fe_1\n  , \"kfold\" \n  , K = 10\n  , cores = 4\n  )\n\nFitting model 1 out of 10\n\n\nFitting model 2 out of 10\n\n\nFitting model 3 out of 10\n\n\nFitting model 4 out of 10\n\n\nFitting model 5 out of 10\n\n\nFitting model 6 out of 10\n\n\nFitting model 7 out of 10\n\n\nFitting model 8 out of 10\n\n\nFitting model 9 out of 10\n\n\nFitting model 10 out of 10\n\nfit_re_1 &lt;- add_criterion(\n  fit_re_1\n  , \"kfold\"\n  , K = 10\n  , cores = 4\n  )\n\nFitting model 1 out of 10\n\n\nStart sampling\n\n\nFitting model 2 out of 10\n\n\nStart sampling\n\n\nFitting model 3 out of 10\n\n\nStart sampling\n\n\nFitting model 4 out of 10\n\n\nStart sampling\n\n\nFitting model 5 out of 10\n\n\nStart sampling\n\n\nFitting model 6 out of 10\n\n\nStart sampling\n\n\nFitting model 7 out of 10\n\n\nStart sampling\n\n\nFitting model 8 out of 10\n\n\nStart sampling\n\n\nFitting model 9 out of 10\n\n\nStart sampling\n\n\nFitting model 10 out of 10\n\n\nStart sampling\n\ncomp_1 &lt;- loo_compare(fit_fe_1, fit_re_1, criterion = \"kfold\")\ncomp_1\n\n         elpd_diff se_diff\nfit_re_1     0.0       0.0\nfit_fe_1 -2842.7    2820.7\n\n\nAlthough model comparisons showed that the model with random effects fitted better, the difference was not significant (Δ ELPD = -2842.75, 95% CI [-8371.271, 2685.78]. Hence, for reasons of parsimony the model with fixed effects is preferred."
  },
  {
    "objectID": "analyses_words_new.html#hurdle",
    "href": "analyses_words_new.html#hurdle",
    "title": "Analyses with words as outcome",
    "section": "Hurdle",
    "text": "Hurdle\nLet’s now estimate a fixed effects model with hurdles.\n\nfit_hrdl_1 &lt;- \n  hush(\n    brm(\n      bf(\n        n_Words ~ \n          1 + persistence_dev * anonymity_dev + age + female + pol_stance +\n          (1 | topic) + \n          (1 | topic:group),\n        zi ~ \n          1 + persistence_dev * anonymity_dev + age + female + pol_stance +\n          (1 | topic) + \n          (1 | topic:group)\n      )\n    , data = d\n    , chains = 4\n    , cores = 4\n    , iter = 6000\n    , warmup = 2000\n    , family = zero_inflated_poisson()\n    , control = list(\n      adapt_delta = .95\n      , max_treedepth = 15\n      )\n    )\n  )\n\nWarning: There were 518 divergent transitions after warmup. See\nhttps://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup\nto find out why this is a problem and how to eliminate them.\n\n\nWarning: Examine the pairs() plot to diagnose sampling problems\n\n\nAgian, some warnings.\nLet’s inspect model.\n\nplot(fit_hrdl_1, ask = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTrace-plots look alright.\n\nsummary(fit_hrdl_1)\n\nWarning: There were 518 divergent transitions after warmup. Increasing\nadapt_delta above 0.95 may help. See\nhttp://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup\n\n\n Family: zero_inflated_poisson \n  Links: mu = log; zi = logit \nFormula: n_Words ~ 1 + persistence_dev * anonymity_dev + age + female + pol_stance + (1 | topic) + (1 | topic:group) \n         zi ~ 1 + persistence_dev * anonymity_dev + age + female + pol_stance + (1 | topic) + (1 | topic:group)\n   Data: d (Number of observations: 960) \n  Draws: 4 chains, each with iter = 6000; warmup = 2000; thin = 1;\n         total post-warmup draws = 16000\n\nMultilevel Hyperparameters:\n~topic (Number of levels: 3) \n                 Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)        0.14      0.16     0.00     0.60 1.00     4317     6264\nsd(zi_Intercept)     0.35      0.50     0.01     1.76 1.00     4375     5635\n\n~topic:group (Number of levels: 48) \n                 Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)        0.37      0.04     0.30     0.46 1.00     4196     6563\nsd(zi_Intercept)     0.24      0.14     0.02     0.53 1.00     4472     6744\n\nRegression Coefficients:\n                                   Estimate Est.Error l-95% CI u-95% CI Rhat\nIntercept                              5.78      0.11     5.56     6.01 1.00\nzi_Intercept                          -1.87      0.51    -2.79    -0.84 1.00\npersistence_dev1                      -0.04      0.05    -0.14     0.07 1.00\nanonymity_dev1                        -0.05      0.05    -0.16     0.05 1.00\nage                                    0.01      0.00     0.01     0.01 1.00\nfemaleTRUE                            -0.12      0.00    -0.13    -0.12 1.00\npol_stance                            -0.02      0.00    -0.02    -0.02 1.00\npersistence_dev1:anonymity_dev1        0.04      0.05    -0.06     0.15 1.00\nzi_persistence_dev1                    0.05      0.09    -0.13     0.23 1.00\nzi_anonymity_dev1                      0.03      0.09    -0.14     0.21 1.00\nzi_age                                 0.02      0.01     0.00     0.03 1.00\nzi_femaleTRUE                          0.14      0.18    -0.21     0.49 1.00\nzi_pol_stance                         -0.05      0.04    -0.13     0.03 1.00\nzi_persistence_dev1:anonymity_dev1     0.01      0.09    -0.17     0.19 1.00\n                                   Bulk_ESS Tail_ESS\nIntercept                              5212     5627\nzi_Intercept                          10949     6527\npersistence_dev1                       2858     5138\nanonymity_dev1                         3055     5142\nage                                   16275    12055\nfemaleTRUE                            29563    10725\npol_stance                            17068     9763\npersistence_dev1:anonymity_dev1        2754     5019\nzi_persistence_dev1                   20542    11569\nzi_anonymity_dev1                     19022    11360\nzi_age                                23044    11719\nzi_femaleTRUE                         24228    10957\nzi_pol_stance                         25684    11393\nzi_persistence_dev1:anonymity_dev1    17845    10858\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nSame results, no main effects, slightly larger but still nonsignificant interaction effect."
  },
  {
    "objectID": "analyses_words_new.html#frequentist",
    "href": "analyses_words_new.html#frequentist",
    "title": "Analyses with words as outcome",
    "section": "Frequentist",
    "text": "Frequentist\nLook at results from a frequentist perspective.\n\nFixed effects\nEstimate nested model.\n\nfit_fe_1_frq &lt;- \n  lmer(\n    n_Words ~ \n      1 + \n      (1 | topic/group) + \n      persistence_dev * anonymity_dev + age + female + pol_stance\n    , data = d\n    )\n\nsummary(fit_fe_1_frq)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: n_Words ~ 1 + (1 | topic/group) + persistence_dev * anonymity_dev +  \n    age + female + pol_stance\n   Data: d\n\nREML criterion at convergence: 15030\n\nScaled residuals: \n   Min     1Q Median     3Q    Max \n-1.208 -0.507 -0.235  0.221 13.409 \n\nRandom effects:\n Groups      Name        Variance Std.Dev.\n group:topic (Intercept)  13591   117     \n topic       (Intercept)      0     0     \n Residual                381808   618     \nNumber of obs: 960, groups:  group:topic, 48; topic, 3\n\nFixed effects:\n                                Estimate Std. Error      df t value Pr(&gt;|t|)   \n(Intercept)                      277.629    104.780 910.923    2.65   0.0082 **\npersistence_dev1                 -28.500     26.099  43.505   -1.09   0.2808   \nanonymity_dev1                   -24.313     26.260  44.563   -0.93   0.3595   \nage                                3.663      1.760 950.062    2.08   0.0377 * \nfemaleTRUE                       -60.301     43.364 946.729   -1.39   0.1647   \npol_stance                         0.468     10.152 949.443    0.05   0.9632   \npersistence_dev1:anonymity_dev1    6.706     26.168  43.950    0.26   0.7990   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) prss_1 anny_1 age    fmTRUE pl_stn\nprsstnc_dv1  0.018                                   \nannymty_dv1  0.063  0.000                            \nage         -0.758 -0.011 -0.058                     \nfemaleTRUE  -0.468 -0.016  0.049  0.251              \npol_stance  -0.546 -0.011 -0.067 -0.002  0.063       \nprsstn_1:_1  0.023  0.001 -0.002 -0.053 -0.039  0.045\noptimizer (nloptwrap) convergence code: 0 (OK)\nboundary (singular) fit: see help('isSingular')\n\n\nQuite weird that topic doesn’t get any variance at all. Perhaps due to small cluster size? With Bayesian estimation, it worked alright. Also, again no significant effects.\nEstimate without nesting.\n\nfit_fe_2_frq &lt;- \n  lmer(\n    n_Words ~ \n      1 + \n      (1 | group) +\n      persistence_dev * anonymity_dev + age + female + pol_stance + topic\n    , data = d\n    )\n\nsummary(fit_fe_2_frq)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: n_Words ~ 1 + (1 | group) + persistence_dev * anonymity_dev +  \n    age + female + pol_stance + topic\n   Data: d\n\nREML criterion at convergence: 15009\n\nScaled residuals: \n   Min     1Q Median     3Q    Max \n-1.200 -0.508 -0.233  0.219 13.366 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n group    (Intercept)  14508   120     \n Residual             381804   618     \nNumber of obs: 960, groups:  group, 48\n\nFixed effects:\n                                Estimate Std. Error      df t value Pr(&gt;|t|)  \n(Intercept)                      267.434    111.482 618.730    2.40    0.017 *\npersistence_dev1                 -28.506     26.462  41.531   -1.08    0.288  \nanonymity_dev1                   -24.265     26.622  42.515   -0.91    0.367  \nage                                3.680      1.762 948.098    2.09    0.037 *\nfemaleTRUE                       -59.385     43.404 944.642   -1.37    0.172  \npol_stance                         0.324     10.160 947.596    0.03    0.975  \ntopicgender                      -13.401     64.870  41.660   -0.21    0.837  \ntopicmigration                    42.524     64.842  41.590    0.66    0.516  \npersistence_dev1:anonymity_dev1    6.660     26.531  41.946    0.25    0.803  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) prss_1 anny_1 age    fmTRUE pl_stn tpcgnd tpcmgr\nprsstnc_dv1  0.016                                                 \nannymty_dv1  0.059  0.000                                          \nage         -0.722 -0.011 -0.057                                   \nfemaleTRUE  -0.435 -0.016  0.048  0.250                            \npol_stance  -0.505 -0.010 -0.066 -0.003  0.064                     \ntopicgender -0.285  0.000 -0.002  0.020 -0.028 -0.024              \ntopicmigrtn -0.300  0.000 -0.001  0.028  0.000 -0.018  0.500       \nprsstn_1:_1  0.022  0.001 -0.002 -0.052 -0.039  0.044 -0.001 -0.002\n\n\nAlso shows no significant effects.\nFor curiosity, estimate also without hierarchical structure.\n\nfit_fe_3_frq &lt;- \n  lm(\n    n_Words ~ \n      1 + \n      persistence_dev * anonymity_dev + topic + age + female + pol_stance\n    , data = d\n    )\n\nsummary(fit_fe_3_frq)\n\n\nCall:\nlm(formula = n_Words ~ 1 + persistence_dev * anonymity_dev + \n    topic + age + female + pol_stance, data = d)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n  -604   -327   -150    125   8448 \n\nCoefficients:\n                                Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept)                       239.86     108.03    2.22    0.027 *\npersistence_dev1                  -28.61      20.28   -1.41    0.159  \nanonymity_dev1                    -25.20      20.49   -1.23    0.219  \ntopicgender                       -13.59      49.74   -0.27    0.785  \ntopicmigration                     42.39      49.71    0.85    0.394  \nage                                 3.91       1.77    2.21    0.027 *\nfemaleTRUE                        -60.28      43.67   -1.38    0.168  \npol_stance                          3.77      10.21    0.37    0.712  \npersistence_dev1:anonymity_dev1     6.94      20.37    0.34    0.733  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 628 on 951 degrees of freedom\nMultiple R-squared:  0.0139,    Adjusted R-squared:  0.00557 \nF-statistic: 1.67 on 8 and 951 DF,  p-value: 0.101\n\n\nAlso here, no significant effects."
  },
  {
    "objectID": "analyses_words_new.html#gender",
    "href": "analyses_words_new.html#gender",
    "title": "Analyses with words as outcome",
    "section": "Gender",
    "text": "Gender\nAs preregistered, let’s see if effects differ across genders.\n\nfit_fe_gen &lt;- \n  hush(\n    brm(\n      n_Words ~ \n        1 + persistence_dev * anonymity_dev * gender + age + pol_stance +\n        (1 | topic/group)\n      , data = d\n      , chains = 4\n      , cores = 4\n      , iter = 8000\n      , warmup = 2000\n      , family = zero_inflated_poisson()\n      , control = list(\n        adapt_delta = .95\n        , max_treedepth = 12\n        )\n      )\n  )\n\nWarning: There were 815 divergent transitions after warmup. See\nhttps://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup\nto find out why this is a problem and how to eliminate them.\n\n\nWarning: There were 1125 transitions after warmup that exceeded the maximum treedepth. Increase max_treedepth above 12. See\nhttps://mc-stan.org/misc/warnings.html#maximum-treedepth-exceeded\n\n\nWarning: Examine the pairs() plot to diagnose sampling problems\n\n\nAgain, some warnings.\nLet’s inspect model.\n\nplot(fit_fe_gen, ask = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTraceplots look alright.\nLet’s look at results.\n\nsummary(fit_fe_gen)\n\nWarning: There were 815 divergent transitions after warmup. Increasing\nadapt_delta above 0.95 may help. See\nhttp://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup\n\n\n Family: zero_inflated_poisson \n  Links: mu = log; zi = identity \nFormula: n_Words ~ 1 + persistence_dev * anonymity_dev * gender + age + pol_stance + (1 | topic/group) \n   Data: d (Number of observations: 960) \n  Draws: 4 chains, each with iter = 8000; warmup = 2000; thin = 1;\n         total post-warmup draws = 24000\n\nMultilevel Hyperparameters:\n~topic (Number of levels: 3) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.16      0.21     0.00     0.74 1.00     2230     1189\n\n~topic:group (Number of levels: 48) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.36      0.04     0.29     0.45 1.00     5390     8676\n\nRegression Coefficients:\n                                           Estimate Est.Error l-95% CI u-95% CI\nIntercept                                      5.66      0.12     5.41     5.91\npersistence_dev1                               0.01      0.05    -0.09     0.12\nanonymity_dev1                                -0.10      0.05    -0.21    -0.00\ngendermale                                     0.11      0.00     0.11     0.12\nage                                            0.01      0.00     0.01     0.01\npol_stance                                    -0.02      0.00    -0.02    -0.01\npersistence_dev1:anonymity_dev1                0.04      0.05    -0.07     0.14\npersistence_dev1:gendermale                   -0.12      0.00    -0.12    -0.11\nanonymity_dev1:gendermale                      0.13      0.00     0.12     0.13\npersistence_dev1:anonymity_dev1:gendermale     0.04      0.00     0.04     0.05\n                                           Rhat Bulk_ESS Tail_ESS\nIntercept                                  1.00     4483     1383\npersistence_dev1                           1.00     6205     8840\nanonymity_dev1                             1.00     6211     7914\ngendermale                                 1.00    20263    13441\nage                                        1.00    22439    18918\npol_stance                                 1.00    21345    13579\npersistence_dev1:anonymity_dev1            1.00     5838     6616\npersistence_dev1:gendermale                1.00    14006    12104\nanonymity_dev1:gendermale                  1.00    16834    13056\npersistence_dev1:anonymity_dev1:gendermale 1.00    19399    13871\n\nFurther Distributional Parameters:\n   Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nzi     0.21      0.01     0.18     0.23 1.00    16050    12599\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nIndeed, several gender effects.\n\nFor females, the effect of persistence is larger, that is more positive.\nFor females, the effect of anonymity is smaller, that is more negative.\nFor females, the interaction effect is also a bit smaller, that is more negative.\n\nLet’s visualize results.\n\np_gen &lt;- plot(\n  conditional_effects(\n    fit_fe_gen\n    ), \n  ask = FALSE,\n  plot = FALSE\n  )\n\np_gen_pers &lt;- \n  p_gen[[\"persistence_dev:gender\"]] +\n  xlab(\"Persistence\") +\n  ylab(\"Words\") +\n  # scale_y_continuous(\n  #   limits = c(4, 15),\n  #   breaks = c(5, 7.5, 10, 12.5, 15)\n  # ) +\n  scale_x_discrete(\n    limits = rev\n  ) +\n  guides(\n    fill = \"none\"\n    , color = \"none\"\n    )\n\np_gen_anon &lt;- \n  p_gen[[\"anonymity_dev:gender\"]] +\n  xlab(\"Anonymity\") +\n  ylab(\"Words\") +\n  # scale_y_continuous(\n  #   limits = c(3.5, 15),\n  #   breaks = c(5, 7.5, 10, 12.5, 15)\n  # ) +\n  theme(\n    axis.title.y = element_blank()\n    ) +\n  guides(\n    fill = \"none\"\n    ) + \n  scale_x_discrete(\n    limits = rev\n  ) +\n  scale_color_discrete(\n    name = \"Gender\"\n    )\n\nplot_gen &lt;- cowplot::plot_grid(\n  p_gen_pers, p_gen_anon, \n  labels = c('A', 'B'), \n  nrow = 1,\n  rel_widths = c(4, 5)\n  )\n\nplot_gen\n\n\n\n\n\n\n\nggsave(\"figures/results_gen.png\", plot_gen, width = 8, height = 4)"
  },
  {
    "objectID": "analyses_words_new.html#benefits",
    "href": "analyses_words_new.html#benefits",
    "title": "Analyses with words as outcome",
    "section": "Benefits",
    "text": "Benefits\nLet’s see if benefits differ across experimental groups.\nWe first look at the experimental group’s descriptives\n\nd |&gt; \n  group_by(persistence) |&gt; \n  summarize(benefits_m = mean(benefits, na.rm = TRUE)) |&gt; \n  as.data.frame() |&gt; \n  kable()\n\n\n\n\npersistence\nbenefits_m\n\n\n\n\nhigh\n3.12\n\n\nlow\n3.23\n\n\n\n\n\nLooking at persistence, we see people with lower persistence reporting slightly higher benefits.\n\nd |&gt; \n  group_by(anonymity) |&gt; \n  summarize(benefits_m = mean(benefits, na.rm = TRUE)) |&gt; \n  as.data.frame() |&gt; \n  kable()\n\n\n\n\nanonymity\nbenefits_m\n\n\n\n\nhigh\n3.15\n\n\nlow\n3.20\n\n\n\n\n\nLooking at anonymity, we see people with low anonymity reporting marginally higher benefits.\n\nd |&gt; \n  group_by(persistence, anonymity) |&gt; \n  summarize(benefits_m = mean(benefits, na.rm = T)) |&gt; \n  as.data.frame() |&gt; \n  kable()\n\n`summarise()` has grouped output by 'persistence'. You can override using the\n`.groups` argument.\n\n\n\n\n\npersistence\nanonymity\nbenefits_m\n\n\n\n\nhigh\nhigh\n3.07\n\n\nhigh\nlow\n3.18\n\n\nlow\nhigh\n3.22\n\n\nlow\nlow\n3.23\n\n\n\n\n\nLooking at both groups combined, we see that low anonymity and low persistence yielded highest benefits.\nLet’s look if effects are significant.\n\nfit_fe_ben_1 &lt;- \n  hush(\n    brm(\n      benefits ~ \n        1 + persistence_dev * anonymity_dev  + age + female + pol_stance +\n        (1 | topic/group)\n      , data = d\n      , chains = 4\n      , cores = 4\n      , iter = 6000\n      , warmup = 2000\n      , control = list(\n        adapt_delta = .95\n        , max_treedepth = 12\n        )\n      )\n  )\n\nWarning: Rows containing NAs were excluded from the model.\n\n\nWarning: There were 119 divergent transitions after warmup. See\nhttps://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup\nto find out why this is a problem and how to eliminate them.\n\n\nWarning: Examine the pairs() plot to diagnose sampling problems\n\n\nLet’s inspect model.\n\nplot(fit_fe_ben_1, ask = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTraceplots look alright.\nLet’s look at results.\n\nsummary(fit_fe_ben_1)\n\nWarning: There were 119 divergent transitions after warmup. Increasing\nadapt_delta above 0.95 may help. See\nhttp://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup\n\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: benefits ~ 1 + persistence_dev * anonymity_dev + age + female + pol_stance + (1 | topic/group) \n   Data: d (Number of observations: 705) \n  Draws: 4 chains, each with iter = 6000; warmup = 2000; thin = 1;\n         total post-warmup draws = 16000\n\nMultilevel Hyperparameters:\n~topic (Number of levels: 3) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.13      0.18     0.00     0.67 1.00     2834     1761\n\n~topic:group (Number of levels: 48) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.08      0.05     0.00     0.18 1.00     3508     4024\n\nRegression Coefficients:\n                                Estimate Est.Error l-95% CI u-95% CI Rhat\nIntercept                           3.22      0.17     2.87     3.55 1.00\npersistence_dev1                   -0.05      0.03    -0.11     0.01 1.00\nanonymity_dev1                     -0.03      0.03    -0.09     0.03 1.00\nage                                -0.00      0.00    -0.01     0.00 1.00\nfemaleTRUE                         -0.07      0.06    -0.19     0.04 1.00\npol_stance                          0.02      0.01    -0.01     0.04 1.00\npersistence_dev1:anonymity_dev1    -0.02      0.03    -0.08     0.04 1.00\n                                Bulk_ESS Tail_ESS\nIntercept                           5256     3238\npersistence_dev1                   13714     8987\nanonymity_dev1                     15562     9606\nage                                22366    11104\nfemaleTRUE                         13893     9395\npol_stance                         16363    11427\npersistence_dev1:anonymity_dev1    11999     8868\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     0.74      0.02     0.70     0.78 1.00    15218    10579\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nNo significant effects. But note that effect of persistence on perceived benefits only marginally not significant."
  },
  {
    "objectID": "analyses_words_new.html#costs",
    "href": "analyses_words_new.html#costs",
    "title": "Analyses with words as outcome",
    "section": "Costs",
    "text": "Costs\nLet’s see if perceived differed across experimental groups.\nWe first look at the experimental group’s descriptives\n\nd |&gt; \n  group_by(persistence) |&gt; \n  summarize(costs = mean(costs, na.rm = TRUE)) |&gt; \n  as.data.frame() |&gt; \n  kable()\n\n\n\n\npersistence\ncosts\n\n\n\n\nhigh\n1.99\n\n\nlow\n1.99\n\n\n\n\n\nLooking at persistence, we see both groups report equal costs.\n\nd |&gt; \n  group_by(anonymity) |&gt; \n  summarize(costs = mean(costs, na.rm = TRUE)) |&gt; \n  as.data.frame() |&gt; \n  kable()\n\n\n\n\nanonymity\ncosts\n\n\n\n\nhigh\n1.89\n\n\nlow\n2.09\n\n\n\n\n\nLooking at anonymity, we see people with low anonymity report slightly higher costs.\n\nd |&gt; \n  group_by(persistence, anonymity) |&gt; \n  summarize(costs = mean(costs, na.rm = TRUE)) |&gt; \n  as.data.frame() |&gt; \n  kable()\n\n`summarise()` has grouped output by 'persistence'. You can override using the\n`.groups` argument.\n\n\n\n\n\npersistence\nanonymity\ncosts\n\n\n\n\nhigh\nhigh\n1.90\n\n\nhigh\nlow\n2.07\n\n\nlow\nhigh\n1.87\n\n\nlow\nlow\n2.11\n\n\n\n\n\nLooking at both groups combined, we see that highest costs were reported by group with low anonymity and low persistence.\nLet’s look if effects are significant.\n\nfit_fe_costs_1 &lt;- \n  hush(\n    brm(\n      costs ~ \n        1 + persistence_dev * anonymity_dev + age + female + pol_stance +\n        (1 | topic/group)\n      , data = d\n      , chains = 4\n      , cores = 4\n      , iter = 8000\n      , warmup = 2000\n      , control = list(\n        adapt_delta = .95\n        , max_treedepth = 12\n        )\n      )\n  )\n\nWarning: Rows containing NAs were excluded from the model.\n\n\nWarning: There were 119 divergent transitions after warmup. See\nhttps://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup\nto find out why this is a problem and how to eliminate them.\n\n\nWarning: Examine the pairs() plot to diagnose sampling problems\n\n\nLet’s inspect model.\n\nplot(fit_fe_costs_1, ask = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTraceplots look alright.\nLet’s look at results.\n\nsummary(fit_fe_costs_1)\n\nWarning: There were 119 divergent transitions after warmup. Increasing\nadapt_delta above 0.95 may help. See\nhttp://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup\n\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: costs ~ 1 + persistence_dev * anonymity_dev + age + female + pol_stance + (1 | topic/group) \n   Data: d (Number of observations: 705) \n  Draws: 4 chains, each with iter = 8000; warmup = 2000; thin = 1;\n         total post-warmup draws = 24000\n\nMultilevel Hyperparameters:\n~topic (Number of levels: 3) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.14      0.22     0.00     0.79 1.00     4391     3051\n\n~topic:group (Number of levels: 48) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.07      0.05     0.00     0.17 1.00     7582     9602\n\nRegression Coefficients:\n                                Estimate Est.Error l-95% CI u-95% CI Rhat\nIntercept                           2.48      0.20     2.09     2.87 1.00\npersistence_dev1                    0.00      0.03    -0.06     0.07 1.00\nanonymity_dev1                     -0.08      0.03    -0.15    -0.02 1.00\nage                                -0.01      0.00    -0.02    -0.01 1.00\nfemaleTRUE                          0.01      0.07    -0.12     0.14 1.00\npol_stance                         -0.00      0.02    -0.04     0.03 1.00\npersistence_dev1:anonymity_dev1     0.02      0.03    -0.05     0.09 1.00\n                                Bulk_ESS Tail_ESS\nIntercept                           7138     4975\npersistence_dev1                   27961    11041\nanonymity_dev1                     31334    16273\nage                                40467    19477\nfemaleTRUE                         36893    17982\npol_stance                         42598    16990\npersistence_dev1:anonymity_dev1    31312    16982\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     0.84      0.02     0.80     0.89 1.00    35120    17084\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nWe find that anonymity does reduce costs."
  },
  {
    "objectID": "analyses_words_new.html#mediation",
    "href": "analyses_words_new.html#mediation",
    "title": "Analyses with words as outcome",
    "section": "Mediation",
    "text": "Mediation\nLet’s see if perceived benefits and costs were associated with increased words communicated.\n\nfit_fe_med &lt;- \n  hush(\n    brm(\n      n_Words ~ \n        1 + persistence_dev * anonymity_dev + benefits + costs  + age + female + pol_stance + \n        (1 | topic/group)\n      , data = d\n      , chains = 4\n      , cores = 4\n      , iter = 6000\n      , warmup = 2000\n      , family = zero_inflated_poisson()\n      , control = list(\n        adapt_delta = .95\n        , max_treedepth = 12\n        )\n      )\n  )\n\nWarning: Rows containing NAs were excluded from the model.\n\n\nWarning: There were 396 divergent transitions after warmup. See\nhttps://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup\nto find out why this is a problem and how to eliminate them.\n\n\nWarning: There were 1733 transitions after warmup that exceeded the maximum treedepth. Increase max_treedepth above 12. See\nhttps://mc-stan.org/misc/warnings.html#maximum-treedepth-exceeded\n\n\nWarning: Examine the pairs() plot to diagnose sampling problems\n\n\nLet’s look at results.\n\nsummary(fit_fe_med)\n\nWarning: There were 396 divergent transitions after warmup. Increasing\nadapt_delta above 0.95 may help. See\nhttp://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup\n\n\n Family: zero_inflated_poisson \n  Links: mu = log; zi = identity \nFormula: n_Words ~ 1 + persistence_dev * anonymity_dev + benefits + costs + age + female + pol_stance + (1 | topic/group) \n   Data: d (Number of observations: 705) \n  Draws: 4 chains, each with iter = 6000; warmup = 2000; thin = 1;\n         total post-warmup draws = 16000\n\nMultilevel Hyperparameters:\n~topic (Number of levels: 3) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.20      0.25     0.01     0.92 1.00     2579     4250\n\n~topic:group (Number of levels: 48) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.39      0.04     0.32     0.48 1.00     3713     5225\n\nRegression Coefficients:\n                                Estimate Est.Error l-95% CI u-95% CI Rhat\nIntercept                           5.99      0.15     5.67     6.31 1.00\npersistence_dev1                   -0.04      0.06    -0.15     0.07 1.00\nanonymity_dev1                     -0.04      0.06    -0.15     0.08 1.00\nbenefits                            0.06      0.00     0.06     0.07 1.00\ncosts                              -0.14      0.00    -0.14    -0.14 1.00\nage                                 0.01      0.00     0.01     0.01 1.00\nfemaleTRUE                         -0.09      0.00    -0.10    -0.09 1.00\npol_stance                         -0.01      0.00    -0.02    -0.01 1.00\npersistence_dev1:anonymity_dev1     0.05      0.06    -0.06     0.16 1.00\n                                Bulk_ESS Tail_ESS\nIntercept                           5407     4531\npersistence_dev1                    4451     5678\nanonymity_dev1                      4462     5930\nbenefits                           14066     8723\ncosts                              13336     8776\nage                                17268    13032\nfemaleTRUE                         13331     8887\npol_stance                         14543     9796\npersistence_dev1:anonymity_dev1     4646     5518\n\nFurther Distributional Parameters:\n   Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nzi     0.08      0.01     0.06     0.10 1.00    13751     9148\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nWe find that increased perceived costs are associated with decreased words communicated. Increased benefits are associated with increased words communicated. Let’s check if overall effect is significant.\n\nanon_costs_a_b &lt;- fixef(fit_fe_costs_1)[\"anonymity_dev1\", \"Estimate\"]\nanon_costs_a_se &lt;- fixef(fit_fe_costs_1)[\"anonymity_dev1\", \"Est.Error\"]\nanon_costs_a_dis &lt;- rnorm(10000, anon_costs_a_b, anon_costs_a_se)\n\nanon_costs_b_b &lt;- fixef(fit_fe_med)[\"benefits\", \"Estimate\"]\nanon_costs_b_se &lt;- fixef(fit_fe_med)[\"benefits\", \"Est.Error\"]\nanon_costs_b_dis &lt;- rnorm(10000, anon_costs_b_b, anon_costs_b_se)\n\nanon_costs_ab_dis &lt;- anon_costs_a_dis * anon_costs_b_dis\nanon_costs_ab_m &lt;- median(anon_costs_ab_dis)\nanon_costs_ab_ll &lt;- quantile(anon_costs_ab_dis, .025)\nanon_costs_ab_ul &lt;- quantile(anon_costs_ab_dis, .975)\n\nThe effect is significant (b = -0.01, 95% MC CI [-0.01, 0])."
  },
  {
    "objectID": "deviations.html",
    "href": "deviations.html",
    "title": "Deviations from Preregistration",
    "section": "",
    "text": "We decided to not exclude people who missed the questionnaire at T2, as participation wasn’t necessary for our analyses and would have only led to unnecessary dropouts.\nWe originally planned to use default (flat) priors (chains = 2, iterations = 2,000, warm-up = 1,000). However, to improve convergence, we increased chains, iterations, and warm-ups."
  }
]