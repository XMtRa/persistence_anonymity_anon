[
  {
    "objectID": "analyses_words_new.html",
    "href": "analyses_words_new.html",
    "title": "Additional analyses",
    "section": "",
    "text": "As preregistered, below we report additional analyses for which we used the actual number of communicated words as DV."
  },
  {
    "objectID": "analyses_words_new.html#packages",
    "href": "analyses_words_new.html#packages",
    "title": "Additional analyses",
    "section": "Packages",
    "text": "Packages\n\nlibrary(brms)\nlibrary(ggplot2)\nlibrary(kableExtra)\nlibrary(lme4)\nlibrary(lmerTest)\nlibrary(rmarkdown)\nlibrary(performance)\nlibrary(see)\nlibrary(sjmisc)\nlibrary(tidyverse)\n\noptions(\n  digits = 3\n)\nset.seed(170819)"
  },
  {
    "objectID": "analyses_words_new.html#custom-functions",
    "href": "analyses_words_new.html#custom-functions",
    "title": "Additional analyses",
    "section": "Custom functions",
    "text": "Custom functions\n\n# function to silence brms output\nhush &lt;- \n  function(\n    code\n    ){\n    sink(\"/dev/null\")\n    tmp = code\n    sink()\n    return(tmp)\n    }"
  },
  {
    "objectID": "analyses_words_new.html#data",
    "href": "analyses_words_new.html#data",
    "title": "Additional analyses",
    "section": "Data",
    "text": "Data\n\nd_words &lt;- read_csv(\"data/DataAggregated_T1T2_nwords.csv\")\nd &lt;- read_csv(\"data/data.csv\")\n\n# get words from dataframe\nd$n_Words &lt;- d_words$n_Words\n\n# same as above; but original file name:\n# d &lt;- read_csv(\"data/DataAggregated_T1T2_costsbenefits.csv\")\n\n# load image for work in IDE\n# load(\"data/image_words.RData\")\n\nd &lt;- d |&gt; \n  rename(\n    group = roles,\n    gender = DE01_T1,\n    age = DE02_01_T1,\n    pol_stance = DE06_01_T1\n  ) |&gt; \n  mutate(\n    female = as.logical(2 - gender),\n    gender = factor(gender, labels = c(\"female\", \"male\")),\n    n_Words = replace_na(n_Words, 0)\n  )\n\n# recode to make as sum coding\nd$anonymity_dev &lt;- factor(d$anonymity)\ncontrasts(d$anonymity_dev) &lt;- contr.sum(2)\nd$persistence_dev &lt;- factor(d$persistence)\ncontrasts(d$persistence_dev) &lt;- contr.sum(2)"
  },
  {
    "objectID": "analyses_words_new.html#fixed-effects",
    "href": "analyses_words_new.html#fixed-effects",
    "title": "Additional analyses",
    "section": "Fixed effects",
    "text": "Fixed effects\nWe preregistered to analyze fixed effects.\n\nfit_fe_1 &lt;- \n  hush(\n    brm(\n      n_Words ~ \n        1 + persistence_dev * anonymity_dev + age + female + pol_stance +\n        (1 | topic/group)\n      , data = d\n      , chains = 4\n      , cores = 4\n      , iter = 6000\n      , warmup = 2000\n      , family = zero_inflated_poisson()\n      , control = list(\n        adapt_delta = .95\n        , max_treedepth = 12\n        )\n      , save_pars = save_pars(all = TRUE)\n      , silent = 2\n      )\n  )\n\nWarning: There were 552 divergent transitions after warmup. See\nhttps://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup\nto find out why this is a problem and how to eliminate them.\n\n\nWarning: Examine the pairs() plot to diagnose sampling problems\n\n\nShows some convergence warnings. Let’s inspect model.\n\nplot(fit_fe_1, ask = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTrace-plots look alright.\nLet’s look at results.\n\nsummary(fit_fe_1)\n\nWarning: There were 552 divergent transitions after warmup. Increasing\nadapt_delta above 0.95 may help. See\nhttp://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup\n\n\n Family: zero_inflated_poisson \n  Links: mu = log; zi = identity \nFormula: n_Words ~ 1 + persistence_dev * anonymity_dev + age + female + pol_stance + (1 | topic/group) \n   Data: d (Number of observations: 960) \n  Draws: 4 chains, each with iter = 6000; warmup = 2000; thin = 1;\n         total post-warmup draws = 16000\n\nMultilevel Hyperparameters:\n~topic (Number of levels: 3) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.14      0.14     0.00     0.55 1.00     2554     4702\n\n~topic:group (Number of levels: 48) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.37      0.04     0.30     0.46 1.00     2681     3482\n\nRegression Coefficients:\n                                Estimate Est.Error l-95% CI u-95% CI Rhat\nIntercept                           5.79      0.10     5.58     5.98 1.00\npersistence_dev1                   -0.04      0.05    -0.14     0.07 1.00\nanonymity_dev1                     -0.05      0.05    -0.15     0.05 1.00\nage                                 0.01      0.00     0.01     0.01 1.00\nfemaleTRUE                         -0.13      0.00    -0.13    -0.12 1.00\npol_stance                         -0.02      0.00    -0.02    -0.02 1.00\npersistence_dev1:anonymity_dev1     0.04      0.05    -0.06     0.15 1.00\n                                Bulk_ESS Tail_ESS\nIntercept                           3333     4406\npersistence_dev1                    2256     3030\nanonymity_dev1                      2600     3825\nage                                16666    12405\nfemaleTRUE                          7318     6447\npol_stance                         10557     7720\npersistence_dev1:anonymity_dev1     2295     3497\n\nFurther Distributional Parameters:\n   Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nzi     0.21      0.01     0.18     0.23 1.00     7006     5765\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nNo significant effect emerged.\nLet’s inspect ICC\n\nvar_ratio_fe &lt;- performance::variance_decomposition(\n  fit_fe_1\n  , by_group = TRUE)\nvar_ratio_fe\n\n# Random Effect Variances and ICC\n\nConditioned on: all random effects\n\n## Variance Ratio (comparable to ICC)\nRatio: 0.45  CI 95%: [0.17 0.64]\n\n## Variances of Posterior Predicted Distribution\nConditioned on fixed effects: 43714.80  CI 95%: [28546.64 65961.20]\nConditioned on rand. effects: 79727.93  CI 95%: [74247.18 85107.51]\n\n## Difference in Variances\nDifference: 35884.99  CI 95%: [13659.26 51447.57]\n\n\n45.103 percent of variance in words communicated explained by both topics and groups.\nLet’s visualize results to see what they exactly mean.\n\np &lt;- plot(\n  conditional_effects(\n    fit_fe_1\n    ), \n  ask = FALSE,\n  plot = FALSE\n  )\n\np_anon &lt;- \n  p[[\"anonymity_dev\"]] +\n  xlab(\"Anonymity\") +\n  ylab(\"Words\") +\n  scale_x_discrete(\n    limits = rev\n  )\n  #    ) +\n  # scale_y_continuous(\n  #   limits = c(5, 14)\n  #   , breaks = c(6, 8, 10, 12, 14)\n  #   )\n\np_pers &lt;- \n  p[[\"persistence_dev\"]] +\n  xlab(\"Persistence\") +\n  ylab(\"Words\") +\n  scale_x_discrete(\n    limits = rev\n   ) +\n  # scale_y_continuous(\n  #   limits = c(5, 14)\n  #   , breaks = c(6, 8, 10, 12, 14)\n  #   ) +\n  theme(\n    axis.title.y = element_blank()\n    )\n\np_int &lt;- \n  p[[\"persistence_dev:anonymity_dev\"]] +\n  xlab(\"Persistence\") +\n  scale_x_discrete(\n    limits = rev\n     ) +\n  scale_color_discrete(\n    labels = c(\"low\", \"high\")\n    ) +\n  guides(\n    fill = \"none\",\n    color = guide_legend(\n      title = \"Anonymity\"\n      )\n    ) +\n  # scale_y_continuous(\n  #   limits = c(5, 14)\n  #   , breaks = c(6, 8, 10, 12, 14)\n  #   ) +\n  theme(\n    axis.title.y = element_blank()\n    )\n\nplot &lt;- cowplot::plot_grid(\n  p_anon, p_pers, p_int, \n  labels = c('A', 'B', \"C\"), \n  nrow = 1,\n  rel_widths = c(2, 2, 3)\n  )\n\nplot\n\n\n\n\n\n\n\nggsave(\"figures/results.png\", plot, width = 8, height = 4)\n\nShows that there are no main effects. There seems to be a (nonsignificant) interaction effect. In low persistence environment, anonymity is conducive to communication; in high it’s the opposite.\nLet’s look at posteriors\n\np_1 &lt;- \n  pp_check(fit_fe_1) + \n  labs(title = \"Zero-inflated poisson\")\n\nUsing 10 posterior draws for ppc type 'dens_overlay' by default.\n\np_1\n\n\n\n\n\n\n\n\nThe actual distribution cannot be precisely reproduced, but it’s also not too far off."
  },
  {
    "objectID": "analyses_words_new.html#random-effects",
    "href": "analyses_words_new.html#random-effects",
    "title": "Additional analyses",
    "section": "Random effects",
    "text": "Random effects\nWe preregistered to explore and compare models with random effects. So let’s model how the experimental conditions affect the outcomes differently depending on topic.\n\nfit_re_1 &lt;- \n  hush(\n    brm(\n      n_Words ~ \n        1 + persistence_dev * anonymity_dev + age + female + pol_stance +\n        (1 + persistence_dev * anonymity_dev | topic) + \n        (1 | topic:group)\n      , data = d\n      , chains = 4\n      , cores = 4\n      , iter = 6000\n      , warmup = 2000\n      , family = zero_inflated_poisson()\n      , control = list(\n        adapt_delta = .95\n        , max_treedepth = 15\n        )\n      , save_pars = save_pars(all = TRUE)\n    )\n  )\n\nWarning: There were 1395 divergent transitions after warmup. See\nhttps://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup\nto find out why this is a problem and how to eliminate them.\n\n\nWarning: Examine the pairs() plot to diagnose sampling problems\n\n\nShows some convergence warnings.\nLet’s inspect model.\n\nplot(fit_re_1, ask = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTraceplots look alright.\nLet’s look at results.\n\nsummary(fit_re_1)\n\nWarning: There were 1395 divergent transitions after warmup. Increasing\nadapt_delta above 0.95 may help. See\nhttp://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup\n\n\n Family: zero_inflated_poisson \n  Links: mu = log; zi = identity \nFormula: n_Words ~ 1 + persistence_dev * anonymity_dev + age + female + pol_stance + (1 + persistence_dev * anonymity_dev | topic) + (1 | topic:group) \n   Data: d (Number of observations: 960) \n  Draws: 4 chains, each with iter = 6000; warmup = 2000; thin = 1;\n         total post-warmup draws = 16000\n\nMultilevel Hyperparameters:\n~topic (Number of levels: 3) \n                                                      Estimate Est.Error\nsd(Intercept)                                             0.25      0.36\nsd(persistence_dev1)                                      0.27      0.37\nsd(anonymity_dev1)                                        0.23      0.33\nsd(persistence_dev1:anonymity_dev1)                       0.35      0.40\ncor(Intercept,persistence_dev1)                          -0.02      0.47\ncor(Intercept,anonymity_dev1)                             0.00      0.47\ncor(persistence_dev1,anonymity_dev1)                     -0.02      0.46\ncor(Intercept,persistence_dev1:anonymity_dev1)           -0.03      0.46\ncor(persistence_dev1,persistence_dev1:anonymity_dev1)     0.04      0.46\ncor(anonymity_dev1,persistence_dev1:anonymity_dev1)       0.00      0.46\n                                                      l-95% CI u-95% CI Rhat\nsd(Intercept)                                             0.00     1.30 1.00\nsd(persistence_dev1)                                      0.01     1.34 1.00\nsd(anonymity_dev1)                                        0.00     1.19 1.00\nsd(persistence_dev1:anonymity_dev1)                       0.01     1.45 1.00\ncor(Intercept,persistence_dev1)                          -0.84     0.83 1.00\ncor(Intercept,anonymity_dev1)                            -0.84     0.84 1.00\ncor(persistence_dev1,anonymity_dev1)                     -0.84     0.82 1.00\ncor(Intercept,persistence_dev1:anonymity_dev1)           -0.85     0.81 1.00\ncor(persistence_dev1,persistence_dev1:anonymity_dev1)    -0.81     0.84 1.00\ncor(anonymity_dev1,persistence_dev1:anonymity_dev1)      -0.83     0.83 1.00\n                                                      Bulk_ESS Tail_ESS\nsd(Intercept)                                             5391     6904\nsd(persistence_dev1)                                      4888     6903\nsd(anonymity_dev1)                                        4200     5188\nsd(persistence_dev1:anonymity_dev1)                       3355     1209\ncor(Intercept,persistence_dev1)                           9806     1289\ncor(Intercept,anonymity_dev1)                            17529    11188\ncor(persistence_dev1,anonymity_dev1)                     13950    12413\ncor(Intercept,persistence_dev1:anonymity_dev1)           15722    12168\ncor(persistence_dev1,persistence_dev1:anonymity_dev1)    12301    10178\ncor(anonymity_dev1,persistence_dev1:anonymity_dev1)      11901    12271\n\n~topic:group (Number of levels: 48) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.36      0.04     0.29     0.46 1.00     5279     8912\n\nRegression Coefficients:\n                                Estimate Est.Error l-95% CI u-95% CI Rhat\nIntercept                           5.79      0.21     5.33     6.22 1.00\npersistence_dev1                   -0.03      0.23    -0.49     0.45 1.00\nanonymity_dev1                     -0.05      0.20    -0.48     0.38 1.00\nage                                 0.01      0.00     0.01     0.01 1.00\nfemaleTRUE                         -0.13      0.00    -0.13    -0.12 1.00\npol_stance                         -0.02      0.00    -0.02    -0.02 1.00\npersistence_dev1:anonymity_dev1     0.04      0.26    -0.54     0.63 1.00\n                                Bulk_ESS Tail_ESS\nIntercept                           6315     5760\npersistence_dev1                    7361     5679\nanonymity_dev1                      7196     5404\nage                                15409    14365\nfemaleTRUE                         21841    10097\npol_stance                         16190     9405\npersistence_dev1:anonymity_dev1     5160     5346\n\nFurther Distributional Parameters:\n   Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nzi     0.21      0.01     0.18     0.23 1.00     5349     1072\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nAgain, no main or interaction effects."
  },
  {
    "objectID": "analyses_words_new.html#hurdle",
    "href": "analyses_words_new.html#hurdle",
    "title": "Additional analyses",
    "section": "Hurdle",
    "text": "Hurdle\nLet’s now estimate a fixed effects model with hurdles.\n\nfit_hrdl_1 &lt;- \n  hush(\n    brm(\n      bf(\n        n_Words ~ \n          1 + persistence_dev * anonymity_dev + age + female + pol_stance +\n          (1 | topic) + \n          (1 | topic:group),\n        zi ~ \n          1 + persistence_dev * anonymity_dev + age + female + pol_stance +\n          (1 | topic) + \n          (1 | topic:group)\n      )\n    , data = d\n    , chains = 4\n    , cores = 4\n    , iter = 6000\n    , warmup = 2000\n    , family = zero_inflated_poisson()\n    , control = list(\n      adapt_delta = .95\n      , max_treedepth = 15\n      )\n    )\n  )\n\nWarning: There were 4612 divergent transitions after warmup. See\nhttps://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup\nto find out why this is a problem and how to eliminate them.\n\n\nWarning: Examine the pairs() plot to diagnose sampling problems\n\n\nWarning: The largest R-hat is 1.6, indicating chains have not mixed.\nRunning the chains for more iterations may help. See\nhttps://mc-stan.org/misc/warnings.html#r-hat\n\n\nWarning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable.\nRunning the chains for more iterations may help. See\nhttps://mc-stan.org/misc/warnings.html#bulk-ess\n\n\nWarning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable.\nRunning the chains for more iterations may help. See\nhttps://mc-stan.org/misc/warnings.html#tail-ess\n\n\nAgian, some warnings.\nLet’s inspect model.\n\nplot(fit_hrdl_1, ask = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTrace-plots look alright.\n\nsummary(fit_hrdl_1)\n\nWarning: Parts of the model have not converged (some Rhats are &gt; 1.05). Be\ncareful when analysing the results! We recommend running more iterations and/or\nsetting stronger priors.\n\n\nWarning: There were 4612 divergent transitions after warmup. Increasing\nadapt_delta above 0.95 may help. See\nhttp://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup\n\n\n Family: zero_inflated_poisson \n  Links: mu = log; zi = logit \nFormula: n_Words ~ 1 + persistence_dev * anonymity_dev + age + female + pol_stance + (1 | topic) + (1 | topic:group) \n         zi ~ 1 + persistence_dev * anonymity_dev + age + female + pol_stance + (1 | topic) + (1 | topic:group)\n   Data: d (Number of observations: 960) \n  Draws: 4 chains, each with iter = 6000; warmup = 2000; thin = 1;\n         total post-warmup draws = 16000\n\nMultilevel Hyperparameters:\n~topic (Number of levels: 3) \n                 Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)        0.34      0.37     0.01     1.01 1.47        8       30\nsd(zi_Intercept)     0.37      0.49     0.01     1.55 1.09       51     3081\n\n~topic:group (Number of levels: 48) \n                 Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)        0.38      0.04     0.30     0.45 1.15       18     2374\nsd(zi_Intercept)     0.27      0.14     0.02     0.51 1.10       27     3529\n\nRegression Coefficients:\n                                   Estimate Est.Error l-95% CI u-95% CI Rhat\nIntercept                              5.63      0.29     5.13     6.00 1.57\nzi_Intercept                          -1.80      0.48    -2.77    -0.89 1.17\npersistence_dev1                      -0.03      0.05    -0.13     0.06 1.20\nanonymity_dev1                        -0.06      0.05    -0.15     0.05 1.15\nage                                    0.01      0.00     0.01     0.01 1.04\nfemaleTRUE                            -0.13      0.00    -0.13    -0.12 1.20\npol_stance                            -0.02      0.00    -0.02    -0.02 1.10\npersistence_dev1:anonymity_dev1        0.04      0.05    -0.05     0.14 1.45\nzi_persistence_dev1                    0.05      0.08    -0.12     0.22 1.26\nzi_anonymity_dev1                      0.02      0.08    -0.14     0.20 1.38\nzi_age                                 0.02      0.01     0.00     0.03 1.16\nzi_femaleTRUE                          0.06      0.21    -0.22     0.47 1.37\nzi_pol_stance                         -0.04      0.04    -0.12     0.03 1.15\nzi_persistence_dev1:anonymity_dev1    -0.00      0.08    -0.16     0.17 1.31\n                                   Bulk_ESS Tail_ESS\nIntercept                                 7       13\nzi_Intercept                             46     2461\npersistence_dev1                        115     3180\nanonymity_dev1                           19     1741\nage                                     121     5475\nfemaleTRUE                               13     1324\npol_stance                               25     4709\npersistence_dev1:anonymity_dev1        2329     3366\nzi_persistence_dev1                     405      574\nzi_anonymity_dev1                       115      884\nzi_age                                   16      479\nzi_femaleTRUE                             9       75\nzi_pol_stance                            17     2796\nzi_persistence_dev1:anonymity_dev1       88      827\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nSame results, no main effects, slightly larger but still nonsignificant interaction effect."
  },
  {
    "objectID": "analyses_words_new.html#frequentist",
    "href": "analyses_words_new.html#frequentist",
    "title": "Additional analyses",
    "section": "Frequentist",
    "text": "Frequentist\nLook at results from a frequentist perspective.\n\nFixed effects\nEstimate nested model.\n\nfit_fe_1_frq &lt;- \n  lmer(\n    n_Words ~ \n      1 + \n      (1 | topic/group) + \n      persistence_dev * anonymity_dev + age + female + pol_stance\n    , data = d\n    )\n\nsummary(fit_fe_1_frq)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: n_Words ~ 1 + (1 | topic/group) + persistence_dev * anonymity_dev +  \n    age + female + pol_stance\n   Data: d\n\nREML criterion at convergence: 15030\n\nScaled residuals: \n   Min     1Q Median     3Q    Max \n-1.208 -0.507 -0.235  0.221 13.409 \n\nRandom effects:\n Groups      Name        Variance Std.Dev.\n group:topic (Intercept)  13591   117     \n topic       (Intercept)      0     0     \n Residual                381808   618     \nNumber of obs: 960, groups:  group:topic, 48; topic, 3\n\nFixed effects:\n                                Estimate Std. Error      df t value Pr(&gt;|t|)   \n(Intercept)                      277.629    104.780 910.923    2.65   0.0082 **\npersistence_dev1                 -28.500     26.099  43.505   -1.09   0.2808   \nanonymity_dev1                   -24.313     26.260  44.563   -0.93   0.3595   \nage                                3.663      1.760 950.062    2.08   0.0377 * \nfemaleTRUE                       -60.301     43.364 946.729   -1.39   0.1647   \npol_stance                         0.468     10.152 949.443    0.05   0.9632   \npersistence_dev1:anonymity_dev1    6.706     26.168  43.950    0.26   0.7990   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) prss_1 anny_1 age    fmTRUE pl_stn\nprsstnc_dv1  0.018                                   \nannymty_dv1  0.063  0.000                            \nage         -0.758 -0.011 -0.058                     \nfemaleTRUE  -0.468 -0.016  0.049  0.251              \npol_stance  -0.546 -0.011 -0.067 -0.002  0.063       \nprsstn_1:_1  0.023  0.001 -0.002 -0.053 -0.039  0.045\noptimizer (nloptwrap) convergence code: 0 (OK)\nboundary (singular) fit: see help('isSingular')\n\n\nQuite weird that topic doesn’t get any variance at all. Perhaps due to small cluster size? With Bayesian estimation, it worked alright. Also, again no significant effects.\nEstimate without nesting.\n\nfit_fe_2_frq &lt;- \n  lmer(\n    n_Words ~ \n      1 + \n      (1 | group) +\n      persistence_dev * anonymity_dev + age + female + pol_stance + topic\n    , data = d\n    )\n\nsummary(fit_fe_2_frq)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: n_Words ~ 1 + (1 | group) + persistence_dev * anonymity_dev +  \n    age + female + pol_stance + topic\n   Data: d\n\nREML criterion at convergence: 15009\n\nScaled residuals: \n   Min     1Q Median     3Q    Max \n-1.200 -0.508 -0.233  0.219 13.366 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n group    (Intercept)  14508   120     \n Residual             381804   618     \nNumber of obs: 960, groups:  group, 48\n\nFixed effects:\n                                Estimate Std. Error      df t value Pr(&gt;|t|)  \n(Intercept)                      267.434    111.482 618.730    2.40    0.017 *\npersistence_dev1                 -28.506     26.462  41.531   -1.08    0.288  \nanonymity_dev1                   -24.265     26.622  42.515   -0.91    0.367  \nage                                3.680      1.762 948.098    2.09    0.037 *\nfemaleTRUE                       -59.385     43.404 944.642   -1.37    0.172  \npol_stance                         0.324     10.160 947.596    0.03    0.975  \ntopicgender                      -13.401     64.870  41.660   -0.21    0.837  \ntopicmigration                    42.524     64.842  41.590    0.66    0.516  \npersistence_dev1:anonymity_dev1    6.660     26.531  41.946    0.25    0.803  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) prss_1 anny_1 age    fmTRUE pl_stn tpcgnd tpcmgr\nprsstnc_dv1  0.016                                                 \nannymty_dv1  0.059  0.000                                          \nage         -0.722 -0.011 -0.057                                   \nfemaleTRUE  -0.435 -0.016  0.048  0.250                            \npol_stance  -0.505 -0.010 -0.066 -0.003  0.064                     \ntopicgender -0.285  0.000 -0.002  0.020 -0.028 -0.024              \ntopicmigrtn -0.300  0.000 -0.001  0.028  0.000 -0.018  0.500       \nprsstn_1:_1  0.022  0.001 -0.002 -0.052 -0.039  0.044 -0.001 -0.002\n\n\nAlso shows no significant effects.\nFor curiosity, estimate also without hierarchical structure.\n\nfit_fe_3_frq &lt;- \n  lm(\n    n_Words ~ \n      1 + \n      persistence_dev * anonymity_dev + topic + age + female + pol_stance\n    , data = d\n    )\n\nsummary(fit_fe_3_frq)\n\n\nCall:\nlm(formula = n_Words ~ 1 + persistence_dev * anonymity_dev + \n    topic + age + female + pol_stance, data = d)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n  -604   -327   -150    125   8448 \n\nCoefficients:\n                                Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept)                       239.86     108.03    2.22    0.027 *\npersistence_dev1                  -28.61      20.28   -1.41    0.159  \nanonymity_dev1                    -25.20      20.49   -1.23    0.219  \ntopicgender                       -13.59      49.74   -0.27    0.785  \ntopicmigration                     42.39      49.71    0.85    0.394  \nage                                 3.91       1.77    2.21    0.027 *\nfemaleTRUE                        -60.28      43.67   -1.38    0.168  \npol_stance                          3.77      10.21    0.37    0.712  \npersistence_dev1:anonymity_dev1     6.94      20.37    0.34    0.733  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 628 on 951 degrees of freedom\nMultiple R-squared:  0.0139,    Adjusted R-squared:  0.00557 \nF-statistic: 1.67 on 8 and 951 DF,  p-value: 0.101\n\n\nAlso here, no significant effects."
  },
  {
    "objectID": "analyses_words_new.html#gender",
    "href": "analyses_words_new.html#gender",
    "title": "Additional analyses",
    "section": "Gender",
    "text": "Gender\nAs preregistered, let’s see if effects differ across genders.\n\nfit_fe_gen &lt;- \n  hush(\n    brm(\n      n_Words ~ \n        1 + persistence_dev * anonymity_dev * gender + age + pol_stance +\n        (1 | topic/group)\n      , data = d\n      , chains = 4\n      , cores = 4\n      , iter = 8000\n      , warmup = 2000\n      , family = zero_inflated_poisson()\n      , control = list(\n        adapt_delta = .95\n        , max_treedepth = 12\n        )\n      )\n  )\n\nWarning: There were 668 divergent transitions after warmup. See\nhttps://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup\nto find out why this is a problem and how to eliminate them.\n\n\nWarning: There were 1932 transitions after warmup that exceeded the maximum treedepth. Increase max_treedepth above 12. See\nhttps://mc-stan.org/misc/warnings.html#maximum-treedepth-exceeded\n\n\nWarning: Examine the pairs() plot to diagnose sampling problems\n\n\nAgain, some warnings.\nLet’s inspect model.\n\nplot(fit_fe_gen, ask = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTraceplots look alright.\nLet’s look at results.\n\nsummary(fit_fe_gen)\n\nWarning: There were 668 divergent transitions after warmup. Increasing\nadapt_delta above 0.95 may help. See\nhttp://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup\n\n\n Family: zero_inflated_poisson \n  Links: mu = log; zi = identity \nFormula: n_Words ~ 1 + persistence_dev * anonymity_dev * gender + age + pol_stance + (1 | topic/group) \n   Data: d (Number of observations: 960) \n  Draws: 4 chains, each with iter = 8000; warmup = 2000; thin = 1;\n         total post-warmup draws = 24000\n\nMultilevel Hyperparameters:\n~topic (Number of levels: 3) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.16      0.20     0.00     0.68 1.00     4328     5277\n\n~topic:group (Number of levels: 48) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.36      0.04     0.29     0.45 1.00     5814     7818\n\nRegression Coefficients:\n                                           Estimate Est.Error l-95% CI u-95% CI\nIntercept                                      5.65      0.12     5.39     5.89\npersistence_dev1                               0.01      0.05    -0.09     0.12\nanonymity_dev1                                -0.10      0.05    -0.21     0.00\ngendermale                                     0.11      0.00     0.11     0.12\nage                                            0.01      0.00     0.01     0.01\npol_stance                                    -0.02      0.00    -0.02    -0.01\npersistence_dev1:anonymity_dev1                0.04      0.05    -0.07     0.14\npersistence_dev1:gendermale                   -0.12      0.00    -0.12    -0.11\nanonymity_dev1:gendermale                      0.13      0.00     0.12     0.13\npersistence_dev1:anonymity_dev1:gendermale     0.04      0.00     0.04     0.05\n                                           Rhat Bulk_ESS Tail_ESS\nIntercept                                  1.00     8096     6617\npersistence_dev1                           1.00     7001     8930\nanonymity_dev1                             1.00     6682     6900\ngendermale                                 1.00    17172    12719\nage                                        1.00    24748    19520\npol_stance                                 1.00    20680    13875\npersistence_dev1:anonymity_dev1            1.00     6765     8163\npersistence_dev1:gendermale                1.00    19135    12599\nanonymity_dev1:gendermale                  1.00    19549    13771\npersistence_dev1:anonymity_dev1:gendermale 1.00    18969    13261\n\nFurther Distributional Parameters:\n   Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nzi     0.21      0.01     0.18     0.23 1.00    18269    12552\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nIndeed, several gender effects.\n\nFor females, the effect of persistence is larger, that is more positive.\nFor females, the effect of anonymity is smaller, that is more negative.\nFor females, the interaction effect is also a bit smaller, that is more negative.\n\nLet’s visualize results.\n\np_gen &lt;- plot(\n  conditional_effects(\n    fit_fe_gen\n    ), \n  ask = FALSE,\n  plot = FALSE\n  )\n\np_gen_pers &lt;- \n  p_gen[[\"persistence_dev:gender\"]] +\n  xlab(\"Persistence\") +\n  ylab(\"Words\") +\n  # scale_y_continuous(\n  #   limits = c(4, 15),\n  #   breaks = c(5, 7.5, 10, 12.5, 15)\n  # ) +\n  scale_x_discrete(\n    limits = rev\n  ) +\n  guides(\n    fill = \"none\"\n    , color = \"none\"\n    )\n\np_gen_anon &lt;- \n  p_gen[[\"anonymity_dev:gender\"]] +\n  xlab(\"Anonymity\") +\n  ylab(\"Words\") +\n  # scale_y_continuous(\n  #   limits = c(3.5, 15),\n  #   breaks = c(5, 7.5, 10, 12.5, 15)\n  # ) +\n  theme(\n    axis.title.y = element_blank()\n    ) +\n  guides(\n    fill = \"none\"\n    ) + \n  scale_x_discrete(\n    limits = rev\n  ) +\n  scale_color_discrete(\n    name = \"Gender\"\n    )\n\nplot_gen &lt;- cowplot::plot_grid(\n  p_gen_pers, p_gen_anon, \n  labels = c('A', 'B'), \n  nrow = 1,\n  rel_widths = c(4, 5)\n  )\n\nplot_gen\n\n\n\n\n\n\n\nggsave(\"figures/results_gen.png\", plot_gen, width = 8, height = 4)"
  },
  {
    "objectID": "analyses_words_new.html#benefits",
    "href": "analyses_words_new.html#benefits",
    "title": "Additional analyses",
    "section": "Benefits",
    "text": "Benefits\nLet’s see if benefits differ across experimental groups.\nWe first look at the experimental group’s descriptives\n\nd |&gt; \n  group_by(persistence) |&gt; \n  summarize(benefits_m = mean(benefits, na.rm = TRUE)) |&gt; \n  as.data.frame() |&gt; \n  kable()\n\n\n\n\npersistence\nbenefits_m\n\n\n\n\nhigh\n3.12\n\n\nlow\n3.23\n\n\n\n\n\nLooking at persistence, we see people with lower persistence reporting slightly higher benefits.\n\nd |&gt; \n  group_by(anonymity) |&gt; \n  summarize(benefits_m = mean(benefits, na.rm = TRUE)) |&gt; \n  as.data.frame() |&gt; \n  kable()\n\n\n\n\nanonymity\nbenefits_m\n\n\n\n\nhigh\n3.15\n\n\nlow\n3.20\n\n\n\n\n\nLooking at anonymity, we see people with low anonymity reporting marginally higher benefits.\n\nd |&gt; \n  group_by(persistence, anonymity) |&gt; \n  summarize(benefits_m = mean(benefits, na.rm = T)) |&gt; \n  as.data.frame() |&gt; \n  kable()\n\n`summarise()` has grouped output by 'persistence'. You can override using the\n`.groups` argument.\n\n\n\n\n\npersistence\nanonymity\nbenefits_m\n\n\n\n\nhigh\nhigh\n3.07\n\n\nhigh\nlow\n3.18\n\n\nlow\nhigh\n3.22\n\n\nlow\nlow\n3.23\n\n\n\n\n\nLooking at both groups combined, we see that low anonymity and low persistence yielded highest benefits.\nLet’s look if effects are significant.\n\nfit_fe_ben_1 &lt;- \n  hush(\n    brm(\n      benefits ~ \n        1 + persistence_dev * anonymity_dev  + age + female + pol_stance +\n        (1 | topic/group)\n      , data = d\n      , chains = 4\n      , cores = 4\n      , iter = 6000\n      , warmup = 2000\n      , control = list(\n        adapt_delta = .95\n        , max_treedepth = 12\n        )\n      )\n  )\n\nWarning: Rows containing NAs were excluded from the model.\n\n\nWarning: There were 132 divergent transitions after warmup. See\nhttps://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup\nto find out why this is a problem and how to eliminate them.\n\n\nWarning: Examine the pairs() plot to diagnose sampling problems\n\n\nLet’s inspect model.\n\nplot(fit_fe_ben_1, ask = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTraceplots look alright.\nLet’s look at results.\n\nsummary(fit_fe_ben_1)\n\nWarning: There were 132 divergent transitions after warmup. Increasing\nadapt_delta above 0.95 may help. See\nhttp://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup\n\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: benefits ~ 1 + persistence_dev * anonymity_dev + age + female + pol_stance + (1 | topic/group) \n   Data: d (Number of observations: 705) \n  Draws: 4 chains, each with iter = 6000; warmup = 2000; thin = 1;\n         total post-warmup draws = 16000\n\nMultilevel Hyperparameters:\n~topic (Number of levels: 3) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.12      0.15     0.00     0.57 1.00     2529     1623\n\n~topic:group (Number of levels: 48) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.08      0.05     0.00     0.17 1.00     3856     5881\n\nRegression Coefficients:\n                                Estimate Est.Error l-95% CI u-95% CI Rhat\nIntercept                           3.22      0.17     2.88     3.55 1.00\npersistence_dev1                   -0.05      0.03    -0.11     0.01 1.00\nanonymity_dev1                     -0.03      0.03    -0.09     0.03 1.00\nage                                -0.00      0.00    -0.01     0.00 1.00\nfemaleTRUE                         -0.07      0.06    -0.19     0.04 1.00\npol_stance                          0.02      0.01    -0.01     0.04 1.00\npersistence_dev1:anonymity_dev1    -0.02      0.03    -0.08     0.04 1.00\n                                Bulk_ESS Tail_ESS\nIntercept                           3824     1941\npersistence_dev1                   12119     7664\nanonymity_dev1                     13553    11734\nage                                20319    10995\nfemaleTRUE                         20568    11618\npol_stance                         13942     5815\npersistence_dev1:anonymity_dev1    18752    11685\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     0.74      0.02     0.70     0.78 1.00    16092    10467\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nNo significant effects. But note that effect of persistence on perceived benefits only marginally not significant."
  },
  {
    "objectID": "analyses_words_new.html#costs",
    "href": "analyses_words_new.html#costs",
    "title": "Additional analyses",
    "section": "Costs",
    "text": "Costs\nLet’s see if perceived differed across experimental groups.\nWe first look at the experimental group’s descriptives\n\nd |&gt; \n  group_by(persistence) |&gt; \n  summarize(costs = mean(costs, na.rm = TRUE)) |&gt; \n  as.data.frame() |&gt; \n  kable()\n\n\n\n\npersistence\ncosts\n\n\n\n\nhigh\n1.99\n\n\nlow\n1.99\n\n\n\n\n\nLooking at persistence, we see both groups report equal costs.\n\nd |&gt; \n  group_by(anonymity) |&gt; \n  summarize(costs = mean(costs, na.rm = TRUE)) |&gt; \n  as.data.frame() |&gt; \n  kable()\n\n\n\n\nanonymity\ncosts\n\n\n\n\nhigh\n1.89\n\n\nlow\n2.09\n\n\n\n\n\nLooking at anonymity, we see people with low anonymity report slightly higher costs.\n\nd |&gt; \n  group_by(persistence, anonymity) |&gt; \n  summarize(costs = mean(costs, na.rm = TRUE)) |&gt; \n  as.data.frame() |&gt; \n  kable()\n\n`summarise()` has grouped output by 'persistence'. You can override using the\n`.groups` argument.\n\n\n\n\n\npersistence\nanonymity\ncosts\n\n\n\n\nhigh\nhigh\n1.90\n\n\nhigh\nlow\n2.07\n\n\nlow\nhigh\n1.87\n\n\nlow\nlow\n2.11\n\n\n\n\n\nLooking at both groups combined, we see that highest costs were reported by group with low anonymity and low persistence.\nLet’s look if effects are significant.\n\nfit_fe_costs_1 &lt;- \n  hush(\n    brm(\n      costs ~ \n        1 + persistence_dev * anonymity_dev + age + female + pol_stance +\n        (1 | topic/group)\n      , data = d\n      , chains = 4\n      , cores = 4\n      , iter = 8000\n      , warmup = 2000\n      , control = list(\n        adapt_delta = .95\n        , max_treedepth = 12\n        )\n      )\n  )\n\nWarning: Rows containing NAs were excluded from the model.\n\n\nWarning: There were 239 divergent transitions after warmup. See\nhttps://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup\nto find out why this is a problem and how to eliminate them.\n\n\nWarning: Examine the pairs() plot to diagnose sampling problems\n\n\nLet’s inspect model.\n\nplot(fit_fe_costs_1, ask = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTraceplots look alright.\nLet’s look at results.\n\nsummary(fit_fe_costs_1)\n\nWarning: There were 239 divergent transitions after warmup. Increasing\nadapt_delta above 0.95 may help. See\nhttp://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup\n\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: costs ~ 1 + persistence_dev * anonymity_dev + age + female + pol_stance + (1 | topic/group) \n   Data: d (Number of observations: 705) \n  Draws: 4 chains, each with iter = 8000; warmup = 2000; thin = 1;\n         total post-warmup draws = 24000\n\nMultilevel Hyperparameters:\n~topic (Number of levels: 3) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.14      0.21     0.00     0.72 1.00     1494      515\n\n~topic:group (Number of levels: 48) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.07      0.05     0.00     0.17 1.00     6748     8434\n\nRegression Coefficients:\n                                Estimate Est.Error l-95% CI u-95% CI Rhat\nIntercept                           2.48      0.19     2.10     2.87 1.00\npersistence_dev1                    0.00      0.03    -0.07     0.07 1.00\nanonymity_dev1                     -0.08      0.03    -0.15    -0.02 1.00\nage                                -0.01      0.00    -0.02    -0.01 1.00\nfemaleTRUE                          0.01      0.07    -0.12     0.14 1.00\npol_stance                         -0.00      0.02    -0.04     0.03 1.00\npersistence_dev1:anonymity_dev1     0.02      0.04    -0.05     0.09 1.00\n                                Bulk_ESS Tail_ESS\nIntercept                           2061      445\npersistence_dev1                   23119    14791\nanonymity_dev1                     22255    16736\nage                                 3533     3184\nfemaleTRUE                          4726     1481\npol_stance                          4395     1896\npersistence_dev1:anonymity_dev1    19628    14789\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     0.84      0.02     0.80     0.89 1.00     2480      483\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nWe find that anonymity does reduce costs."
  },
  {
    "objectID": "analyses_words_new.html#mediation",
    "href": "analyses_words_new.html#mediation",
    "title": "Additional analyses",
    "section": "Mediation",
    "text": "Mediation\nLet’s see if perceived benefits and costs were associated with increased words communicated.\n\nfit_fe_med &lt;- \n  hush(\n    brm(\n      n_Words ~ \n        1 + persistence_dev * anonymity_dev + benefits + costs  + age + female + pol_stance + \n        (1 | topic/group)\n      , data = d\n      , chains = 4\n      , cores = 4\n      , iter = 6000\n      , warmup = 2000\n      , family = zero_inflated_poisson()\n      , control = list(\n        adapt_delta = .95\n        , max_treedepth = 12\n        )\n      )\n  )\n\nWarning: Rows containing NAs were excluded from the model.\n\n\nWarning: There were 528 divergent transitions after warmup. See\nhttps://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup\nto find out why this is a problem and how to eliminate them.\n\n\nWarning: There were 570 transitions after warmup that exceeded the maximum treedepth. Increase max_treedepth above 12. See\nhttps://mc-stan.org/misc/warnings.html#maximum-treedepth-exceeded\n\n\nWarning: Examine the pairs() plot to diagnose sampling problems\n\n\nLet’s look at results.\n\nsummary(fit_fe_med)\n\nWarning: There were 528 divergent transitions after warmup. Increasing\nadapt_delta above 0.95 may help. See\nhttp://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup\n\n\n Family: zero_inflated_poisson \n  Links: mu = log; zi = identity \nFormula: n_Words ~ 1 + persistence_dev * anonymity_dev + benefits + costs + age + female + pol_stance + (1 | topic/group) \n   Data: d (Number of observations: 705) \n  Draws: 4 chains, each with iter = 6000; warmup = 2000; thin = 1;\n         total post-warmup draws = 16000\n\nMultilevel Hyperparameters:\n~topic (Number of levels: 3) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.19      0.22     0.00     0.80 1.00     2528     3504\n\n~topic:group (Number of levels: 48) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.39      0.04     0.32     0.49 1.00     3616     5273\n\nRegression Coefficients:\n                                Estimate Est.Error l-95% CI u-95% CI Rhat\nIntercept                           5.98      0.14     5.68     6.28 1.00\npersistence_dev1                   -0.04      0.06    -0.16     0.07 1.00\nanonymity_dev1                     -0.04      0.06    -0.15     0.07 1.00\nbenefits                            0.06      0.00     0.06     0.07 1.00\ncosts                              -0.14      0.00    -0.14    -0.14 1.00\nage                                 0.01      0.00     0.01     0.01 1.00\nfemaleTRUE                         -0.09      0.00    -0.10    -0.09 1.00\npol_stance                         -0.01      0.00    -0.02    -0.01 1.00\npersistence_dev1:anonymity_dev1     0.05      0.06    -0.06     0.16 1.00\n                                Bulk_ESS Tail_ESS\nIntercept                           4854     3306\npersistence_dev1                    4193     5107\nanonymity_dev1                      4213     5248\nbenefits                           12217     9176\ncosts                              12666     8803\nage                                16687    12376\nfemaleTRUE                         12610     9014\npol_stance                         13892     8775\npersistence_dev1:anonymity_dev1     4018     5166\n\nFurther Distributional Parameters:\n   Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nzi     0.08      0.01     0.06     0.10 1.00    12135     7666\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nWe find that increased perceived costs are associated with decreased words communicated. Increased benefits are associated with increased words communicated. Let’s check if overall effect is significant.\n\nanon_costs_a_b &lt;- fixef(fit_fe_costs_1)[\"anonymity_dev1\", \"Estimate\"]\nanon_costs_a_se &lt;- fixef(fit_fe_costs_1)[\"anonymity_dev1\", \"Est.Error\"]\nanon_costs_a_dis &lt;- rnorm(10000, anon_costs_a_b, anon_costs_a_se)\n\nanon_costs_b_b &lt;- fixef(fit_fe_med)[\"benefits\", \"Estimate\"]\nanon_costs_b_se &lt;- fixef(fit_fe_med)[\"benefits\", \"Est.Error\"]\nanon_costs_b_dis &lt;- rnorm(10000, anon_costs_b_b, anon_costs_b_se)\n\nanon_costs_ab_dis &lt;- anon_costs_a_dis * anon_costs_b_dis\nanon_costs_ab_m &lt;- median(anon_costs_ab_dis)\nanon_costs_ab_ll &lt;- quantile(anon_costs_ab_dis, .025)\nanon_costs_ab_ul &lt;- quantile(anon_costs_ab_dis, .975)\n\nThe effect is significant (b = -0.01, 95% MC CI [-0.01, 0])."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "The Effects of Technological Affordances on Political Opinion Expression in Social Media: A Field Experiment",
    "section": "",
    "text": "On this website, you can find the companion material for the paper The Effects of Technological Affordances on Political Opinion Expression in Social Media: A Field Experiment.\nYou can find the following information here:\n\nStatistical analyses\nStatistical analyses with words as outcome\nPower analyses\nPlanned analyses\nDeviations from preregistration\n\nThis website is produced directly from the project’s github repository. You can download the material and the data, file an issue, or submit a pull request."
  },
  {
    "objectID": "power_analyses.html",
    "href": "power_analyses.html",
    "title": "Power Analyses",
    "section": "",
    "text": "library(BayesFactor)\nlibrary(brms)\nlibrary(broom)\nlibrary(ggplot2)\nlibrary(knitr)\nlibrary(magrittr)\nlibrary(tidyverse)"
  },
  {
    "objectID": "power_analyses.html#generate-design",
    "href": "power_analyses.html#generate-design",
    "title": "Power Analyses",
    "section": "Generate design",
    "text": "Generate design\n\ngenerate_design &lt;- function(groupsize, \n                            persis, \n                            anon, \n                            topics, \n                            repetition, \n                            ...){\n  \n  # function generates underlying (empty) datastructure\n  \n  # count number of groups\n  groups &lt;- persis * anon * topics * repetition\n  \n  # make datastructure\n  expand.grid(\n    participant = 1:groupsize, \n    persistence = 1:persis - 1, # -1 to make binary\n    anonymity = 1:anon - 1, \n    topic = 1:topics,\n    repetition = 1:repetition) %&gt;% \n    as.data.frame() %&gt;% \n    rownames_to_column(\"id\") %&gt;% \n    mutate(\n      group = rep(c(1:groups), each = groupsize))\n}"
  },
  {
    "objectID": "power_analyses.html#simulate-data",
    "href": "power_analyses.html#simulate-data",
    "title": "Power Analyses",
    "section": "Simulate data",
    "text": "Simulate data\n\nsim_d &lt;- function(d_frame, \n                  seed, # make results reproducible\n                  effects, # vector of effects we anticipate\n                  sd, \n                  groupsize, \n                  ...){\n  \n  # function to simulate data\n\n  # set.seed(seed)  # uncomment to make results reproducible\n  \n  # compute how many participants per cell (exp. condition)\n  n_cell &lt;- groupsize_n * topics_n * repetition_n\n  \n  # create the DV. \n  # For now, this will be standardized, bc. of lack of concrete data\n  d_frame$expressions &lt;- NA # create variable that'll be filled next\n  \n  # run loop creating DVs\n  for(i in 1 : repetition_n){\n    for(j in 1 : topics_n){\n      d_frame[d_frame$persistence == 0 & \n              d_frame$anonymity == 0 & \n              d_frame$repetition == i & \n              d_frame$topic == j, ]$expressions &lt;- \n        rnorm(groupsize_n, effects[\"pers0_anon_0_m\"], sd)\n      d_frame[d_frame$persistence == 1 & \n              d_frame$anonymity == 0 & \n              d_frame$repetition == i & \n              d_frame$topic == j, ]$expressions &lt;- \n        rnorm(groupsize_n, effects[\"pers1_anon_0_m\"], sd)\n      d_frame[d_frame$persistence == 0 & \n              d_frame$anonymity == 1 & \n              d_frame$repetition == i & \n              d_frame$topic == j, ]$expressions &lt;- \n        rnorm(groupsize_n, effects[\"pers0_anon_1_m\"], sd)\n      d_frame[d_frame$persistence == 1 & \n              d_frame$anonymity == 1 & \n              d_frame$repetition == i & \n              d_frame$topic == j, ]$expressions &lt;- \n        rnorm(groupsize_n, effects[\"pers1_anon_1_m\"], sd)\n    }\n  }\n  return(d_frame)\n}"
  },
  {
    "objectID": "power_analyses.html#analyze-data",
    "href": "power_analyses.html#analyze-data",
    "title": "Power Analyses",
    "section": "Analyze data",
    "text": "Analyze data\n\nanalyze_d &lt;- function(object, approach, ...) {\n\n  # function to analyze data and to extract results\n  \n  # get means\n  means &lt;- group_by(object, persistence, anonymity) %&gt;% \n    summarize(mean = mean(expressions), .groups = 'drop')\n  \n  results &lt;- data.frame(\n    reps = repetition_n,\n    n = nrow(object), \n    per0_anon0_m = filter(means, persistence == 0, anonymity == 0)$mean,\n    per0_anon1_m = filter(means, persistence == 0, anonymity == 1)$mean,\n    per1_anon0_m = filter(means, persistence == 1, anonymity == 0)$mean,\n    per1_anon1_m = filter(means, persistence == 1, anonymity == 1)$mean\n  )\n\n  \n    # get estimates from regression\n    fit &lt;- lm(expressions ~ persistence + anonymity, object)\n    fit_rslt &lt;- tidy(fit)\n  \n    # combine result\n    results &lt;- cbind(\n      results,\n      persistence_est = fit_rslt[fit_rslt$term == \"persistence\",]$estimate,\n      persistence_p = fit_rslt[fit_rslt$term == \"persistence\",]$p.value,\n      anonymity_est = fit_rslt[fit_rslt$term == \"anonymity\",]$estimate,\n      anonymity_p = fit_rslt[fit_rslt$term == \"anonymity\",]$p.value\n    )\n  return(results)\n}"
  },
  {
    "objectID": "power_analyses.html#design-and-simulate",
    "href": "power_analyses.html#design-and-simulate",
    "title": "Power Analyses",
    "section": "Design and simulate",
    "text": "Design and simulate\n\ndes_sim_fit &lt;- function(...){\n  \n  # function to report and extract results\n  \n  d_frame &lt;- generate_design(...)\n  d &lt;- sim_d(d_frame, ...)\n  analyze_d(d, ...)\n}"
  },
  {
    "objectID": "power_analyses.html#estimate-power",
    "href": "power_analyses.html#estimate-power",
    "title": "Power Analyses",
    "section": "Estimate power",
    "text": "Estimate power\n\nest_pow &lt;- function(sims_n, approach, ...){\n  # function to run analyse sims_n times\n\n  tibble(sim = 1:sims_n) %&gt;% \n  mutate(\n    effect = map(sim, \n                 des_sim_fit, \n                 groupsize = groupsize_n, \n                 persis = persis_n, \n                 anon = anon_n, \n                 topics = topics_n, \n                 repetition = repetition_n, \n                 effects = effects_est, \n                 sd = sd_est,\n                 approach = approach)\n    ) %&gt;%\n  unnest(effect) %&gt;%\n  as.data.frame()\n}"
  },
  {
    "objectID": "power_analyses.html#set-up",
    "href": "power_analyses.html#set-up",
    "title": "Power Analyses",
    "section": "Set-up",
    "text": "Set-up\nWe first create an empty data frame, in which we will then later simulate the data.\n\n# create design frame\nd_frame &lt;- generate_design(\n  groupsize  = groupsize_n,\n  persis     = persis_n,  \n  anon      = anon_n,     \n  topics     = topics_n,  \n  repetition = repetition_n\n  )\nd_frame\n\nCheck if data-frame is alright.\n\nxtabs(~persistence + anonymity + topic + repetition, d_frame)\n\n, , topic = 1, repetition = 1\n\n           anonymity\npersistence  0  1\n          0 20 20\n          1 20 20\n\n, , topic = 2, repetition = 1\n\n           anonymity\npersistence  0  1\n          0 20 20\n          1 20 20\n\n, , topic = 3, repetition = 1\n\n           anonymity\npersistence  0  1\n          0 20 20\n          1 20 20\n\n, , topic = 1, repetition = 2\n\n           anonymity\npersistence  0  1\n          0 20 20\n          1 20 20\n\n, , topic = 2, repetition = 2\n\n           anonymity\npersistence  0  1\n          0 20 20\n          1 20 20\n\n, , topic = 3, repetition = 2\n\n           anonymity\npersistence  0  1\n          0 20 20\n          1 20 20\n\n, , topic = 1, repetition = 3\n\n           anonymity\npersistence  0  1\n          0 20 20\n          1 20 20\n\n, , topic = 2, repetition = 3\n\n           anonymity\npersistence  0  1\n          0 20 20\n          1 20 20\n\n, , topic = 3, repetition = 3\n\n           anonymity\npersistence  0  1\n          0 20 20\n          1 20 20\n\n, , topic = 1, repetition = 4\n\n           anonymity\npersistence  0  1\n          0 20 20\n          1 20 20\n\n, , topic = 2, repetition = 4\n\n           anonymity\npersistence  0  1\n          0 20 20\n          1 20 20\n\n, , topic = 3, repetition = 4\n\n           anonymity\npersistence  0  1\n          0 20 20\n          1 20 20\n\n\nAllocation of participants to experimental groups worked just fine."
  },
  {
    "objectID": "power_analyses.html#simulate-data-1",
    "href": "power_analyses.html#simulate-data-1",
    "title": "Power Analyses",
    "section": "Simulate data",
    "text": "Simulate data\nLet’s create a single data-set and analyze it.\n\nd &lt;- sim_d(d_frame, seed = 1, effects_est, sd_est, groupsize_n)\nwrite.csv(d, \"data/data_simulated.csv\") # save data."
  },
  {
    "objectID": "power_analyses.html#analyse-data",
    "href": "power_analyses.html#analyse-data",
    "title": "Power Analyses",
    "section": "Analyse data",
    "text": "Analyse data\nLet’s check if means were created alright:\n\nd %&gt;% \n  group_by(persistence, anonymity) %&gt;% \n  summarize(mean = mean(expressions), .groups = 'drop') %&gt;% \n  kable()\n\n\n\n\npersistence\nanonymity\nmean\n\n\n\n\n0\n0\n-0.1460706\n\n\n0\n1\n-0.0326302\n\n\n1\n0\n-0.4490249\n\n\n1\n1\n-0.1929650\n\n\n\n\n\nSample size small and single study, but general tendency seems to be alright.\nLet’s also quickly run a regression.\n\nfit &lt;- lm(expressions ~ persistence + anonymity, d)\nsummary(fit)\n\n\nCall:\nlm(formula = expressions ~ persistence + anonymity, data = d)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.0111 -0.6753 -0.0290  0.6915  3.7920 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -0.18173    0.05775  -3.147 0.001701 ** \npersistence -0.23164    0.06668  -3.474 0.000536 ***\nanonymity    0.18475    0.06668   2.771 0.005702 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.033 on 957 degrees of freedom\nMultiple R-squared:  0.02022,   Adjusted R-squared:  0.01817 \nF-statistic: 9.873 on 2 and 957 DF,  p-value: 5.702e-05\n\n\nResults look reasonable. Both persistence and anonymity reduce disclosure."
  },
  {
    "objectID": "power_analyses.html#set-up-1",
    "href": "power_analyses.html#set-up-1",
    "title": "Power Analyses",
    "section": "Set-Up",
    "text": "Set-Up\n\nn_sim &lt;- 1000\nn_reps &lt;- 5\n\nWe simulate 1000 data sets for the power analyses. Up to 5 times will the set-up be repeated."
  },
  {
    "objectID": "power_analyses.html#small-effects",
    "href": "power_analyses.html#small-effects",
    "title": "Power Analyses",
    "section": "Small effects",
    "text": "Small effects\n\nRun analyses\nLet’s next run our actual power analysis, using the effect sizes defined above (small standardized effects).\nWe run a power analysis with 1000 simulations per design. We test 5 designs, that is 1 to 5 repetitions.\n\n# create empy data frame\ncolumns &lt;- c(\"sim\", \"reps\", \"per0_anon0_m\", \"per0_anon1_m\", \n             \"per1_anon0_m\", \"per1_anon1_m\", \"persistence_est\", \n             \"persistence_p\", \"anonymity_est\", \"anonymity_p\", \"n\")\nsims_freq_s &lt;- data.frame(matrix(nrow = 0, ncol = length(columns))) \ncolnames(sims_freq_s) = columns\n\nt1 &lt;- Sys.time()\nfor(i in 1 : n_reps){\n  repetition_n  &lt;- i\n  sims_freq_s &lt;- rbind(sims_freq_s, est_pow(approach = \"frequentist\", sims_n = n_sim))\n}\nt2 &lt;- Sys.time()\nt2 - t1\n\nTime difference of 30.5522 secs\n\n\n\n\nVisualization\nLet’s inspect the results. First persistence:\n\nggplot(sims_freq_s) +\n  geom_point(aes(sim, persistence_est, color = persistence_p &lt; .05), \n             size = .2, alpha = .5) + \n  scale_color_manual(values = c(\"darkgrey\", \"blue\")) +\n  facet_wrap(facets = \"reps\", nrow = 1) +\n  labs(color = \"significant\")\n\n\n\n\n\n\n\n\nShows that with more repetitions, effect size move closer to actual population value.\nTo make sure, let’s next check anonymity – should provide identical results.\n\nggplot(sims_freq_s) +\n  geom_point(aes(sim, anonymity_est, color = anonymity_p &lt; .05), \n             size = .2, alpha = .5) + \n  scale_color_manual(values = c(\"darkgrey\", \"blue\")) +\n  facet_wrap(facets = \"reps\", nrow = 1) +\n  labs(color = \"significant\")\n\n\n\n\n\n\n\n\nLooks good.\n\n\nCell means & main effects\nNext, we compute the average means in the four cells averaged across simulations, plus the two main effects. This is more of a sanity check to see if our population values can be reproduced.\n\nsims_freq_s %&gt;% \n  group_by(reps) %&gt;% \n  summarise(per0_anon0 = mean(per0_anon0_m),\n            per0_anon1 = mean(per0_anon1_m),\n            per1_anon0 = mean(per1_anon0_m),\n            per1_anon1 = mean(per1_anon1_m),\n            persistence = mean(persistence_est), \n            anonymity = mean(anonymity_est)\n            ) %&gt;% \n  as.data.frame() %&gt;% \n  kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\nreps\nper0_anon0\nper0_anon1\nper1_anon0\nper1_anon1\npersistence\nanonymity\n\n\n\n\n1\n-0.2036146\n0.0005666\n-0.3999596\n-0.1994476\n-0.1981796\n0.2023466\n\n\n2\n-0.1989367\n-0.0033509\n-0.3990509\n-0.2003664\n-0.1985648\n0.1971352\n\n\n3\n-0.1990174\n0.0010106\n-0.3973053\n-0.2033331\n-0.2013158\n0.1970001\n\n\n4\n-0.1976968\n-0.0017485\n-0.3996051\n-0.2018917\n-0.2010258\n0.1968309\n\n\n5\n-0.1963275\n-0.0035055\n-0.3982119\n-0.2004496\n-0.1994143\n0.1952921\n\n\n\n\n\nShows that the means resemble those we defined a priori. Same for main effects.\n\n\nPower estimates\nNow, let’s compute power for each number of replication.\n\npower_freq_s &lt;- sims_freq_s %&gt;% \n  group_by(reps) %&gt;% \n  summarise(n = max(n),\n            persistence = sum(persistence_p &lt; .05 & persistence_est &lt; 0) / n_sim,\n            anonymity = sum(anonymity_p &lt; .05 & anonymity_est &gt; 0) / n_sim)\nkable(power_freq_s)\n\n\n\n\nreps\nn\npersistence\nanonymity\n\n\n\n\n1\n240\n0.335\n0.344\n\n\n2\n480\n0.584\n0.569\n\n\n3\n720\n0.771\n0.758\n\n\n4\n960\n0.864\n0.866\n\n\n5\n1200\n0.934\n0.917\n\n\n\n\n\n\ndat_fr_s &lt;- pivot_longer(power_freq_s, c(-reps, -n), names_to = \"manipulation\", values_to = \"effect\")\npower_fig &lt;- ggplot(dat_fr_s, aes(reps, effect, color = manipulation)) +\n  geom_point(alpha = .9) +\n  scale_x_discrete(limits = c(1:n_reps))\npower_fig\n\n\n\n\n\n\n\n\nIf we replicate the study at least 5 times, then we get more than 80% power."
  },
  {
    "objectID": "power_analyses.html#small-to-medium-effects",
    "href": "power_analyses.html#small-to-medium-effects",
    "title": "Power Analyses",
    "section": "Small-to-medium effects",
    "text": "Small-to-medium effects\nLet’s next rerun our power analysis, using slightly larger effect sized (small to medium).\n\npers0_anon_0_m &lt;- -0.35\npers0_anon_1_m &lt;-  0.00\npers1_anon_0_m &lt;- -0.70\npers1_anon_1_m &lt;- -0.35\neffects_est &lt;- c(pers0_anon_0_m, pers0_anon_1_m, pers1_anon_0_m, pers1_anon_1_m)\nnames(effects_est) &lt;- c(\"pers0_anon_0_m\", \"pers0_anon_1_m\", \"pers1_anon_0_m\", \"pers1_anon_1_m\")\nsd_est &lt;- 1\n\n\nRun analyses\nEverything as above, but now assuming larger effects.\n\n# create empy data frame\ncolumns &lt;- c(\"sim\", \"reps\", \"per0_anon0_m\", \"per0_anon1_m\", \n             \"per1_anon0_m\", \"per1_anon1_m\", \"persistence_est\", \n             \"persistence_p\", \"anonymity_est\", \"anonymity_p\", \"n\")\nsims_freq_sm &lt;- data.frame(matrix(nrow = 0, ncol = length(columns))) \ncolnames(sims_freq_sm) = columns\n\nt1 &lt;- Sys.time()\nfor(i in 1 : n_reps){\n  repetition_n  &lt;- i\n  sims_freq_sm &lt;- rbind(sims_freq_sm, est_pow(approach = \"frequentist\", sims_n = n_sim))\n}\nt2 &lt;- Sys.time()\nt2 - t1\n\n\n\nVisualization\nLet’s inspect the results. First persistence:\n\nggplot(sims_freq_sm) +\n  geom_point(aes(sim, persistence_est, color = persistence_p &lt; .05), \n             size = .2, alpha = .5) + \n  scale_color_manual(values = c(\"darkgrey\", \"blue\")) +\n  facet_wrap(facets = \"reps\", nrow = 1) +\n  labs(color = \"significant\")\n\n\n\n\n\n\n\n\nShows that with more repetitions, effect size moves closer to actual population value.\nTo make sure, let’s next check anonymity – should provide identical results.\n\nggplot(sims_freq_sm) +\n  geom_point(aes(sim, anonymity_est, color = anonymity_p &lt; .05), \n             size = .2, alpha = .5) + \n  scale_color_manual(values = c(\"darkgrey\", \"blue\")) +\n  facet_wrap(facets = \"reps\", nrow = 1) +\n  labs(color = \"significant\")\n\n\n\n\n\n\n\n\nLooks good.\n\n\nCell means & main effects\nNext, we compute the average means in the four cells averaged across simulations, plus the two main effects. This is more of a sanity check to see if our population values can be reproduced.\n\nsims_freq_sm %&gt;% \n  group_by(reps) %&gt;% \n  summarise(per0_anon0 = mean(per0_anon0_m),\n            per0_anon1 = mean(per0_anon1_m),\n            per1_anon0 = mean(per1_anon0_m),\n            per1_anon1 = mean(per1_anon1_m),\n            persistence = mean(persistence_est), \n            anonymity = mean(anonymity_est)\n            ) %&gt;% \n  kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\nreps\nper0_anon0\nper0_anon1\nper1_anon0\nper1_anon1\npersistence\nanonymity\n\n\n\n\n1\n-0.3529767\n0.0016533\n-0.7008929\n-0.3525972\n-0.3510833\n0.3514628\n\n\n2\n-0.3488914\n0.0030501\n-0.6995804\n-0.3545085\n-0.3541238\n0.3485067\n\n\n3\n-0.3504833\n0.0010607\n-0.6964101\n-0.3487588\n-0.3478731\n0.3495976\n\n\n4\n-0.3494230\n-0.0014467\n-0.6983255\n-0.3508370\n-0.3491464\n0.3477324\n\n\n5\n-0.3519374\n0.0031855\n-0.6978309\n-0.3493555\n-0.3492172\n0.3517991\n\n\n\n\n\nShows that the means resemble those we defined a priori. Same for main effects.\n\n\nPower estimates\nNow, let’s compute power for each number of replication.\n\npower_freq_sm &lt;- sims_freq_sm %&gt;% \n  group_by(reps) %&gt;% \n  summarise(persistence = sum(persistence_p &lt; .05 & persistence_est &lt; 0) / n_sim,\n            anonymity = sum(anonymity_p &lt; .05 & anonymity_est &gt; 0) / n_sim,\n            n = max(n))\nkable(power_freq_sm)\n\n\n\n\nreps\npersistence\nanonymity\nn\n\n\n\n\n1\n0.792\n0.767\n240\n\n\n2\n0.971\n0.966\n480\n\n\n3\n0.997\n0.997\n720\n\n\n4\n0.999\n1.000\n960\n\n\n5\n1.000\n1.000\n1200\n\n\n\n\n\nIf we replicate the study at least 3 times, then we get more than 80% power.\n\ndat_fr_sm &lt;- pivot_longer(power_freq_sm, c(-reps, -n), names_to = \"manipulation\", values_to = \"effect\")\npower_fig &lt;- ggplot(dat_fr_sm, aes(reps, effect, color = manipulation)) +\n  geom_point(alpha = .9) +\n  scale_x_discrete(limits = c(1:n_reps))\npower_fig"
  },
  {
    "objectID": "power_analyses.html#tables",
    "href": "power_analyses.html#tables",
    "title": "Power Analyses",
    "section": "Tables",
    "text": "Tables\nFor small effects:\n\ntab_s &lt;- cbind(\n  Replications = power_freq_s$reps,\n  N = power_freq_s$n,\n  pers_power = power_freq_s$persistence,\n  anon_power = power_freq_s$anonymity\n)\nkable(tab_s)\n\n\n\n\nReplications\nN\npers_power\nanon_power\n\n\n\n\n1\n240\n0.335\n0.344\n\n\n2\n480\n0.584\n0.569\n\n\n3\n720\n0.771\n0.758\n\n\n4\n960\n0.864\n0.866\n\n\n5\n1200\n0.934\n0.917\n\n\n\n\n\nFor small-to-medium effects\n\ntab_sm &lt;- cbind(\n  Replications = power_freq_sm$reps,\n  N = power_freq_sm$n,\n  pers_power = power_freq_sm$persistence, \n  anon_power = power_freq_sm$anonymity\n)\nkable(tab_sm)\n\n\n\n\nReplications\nN\npers_power\nanon_power\n\n\n\n\n1\n240\n0.792\n0.767\n\n\n2\n480\n0.971\n0.966\n\n\n3\n720\n0.997\n0.997\n\n\n4\n960\n0.999\n1.000\n\n\n5\n1200\n1.000\n1.000"
  },
  {
    "objectID": "power_analyses.html#figures",
    "href": "power_analyses.html#figures",
    "title": "Power Analyses",
    "section": "Figures",
    "text": "Figures\n\n# dat_bf_s &lt;- pivot_longer(power_bf_s, c(-reps, -n), names_to = \"manipulation\", values_to = \"effect\")\n# dat_bf_s$effectsize &lt;- \"small\"\n# dat_bf_sm &lt;- pivot_longer(power_bf_sm, c(-reps, -n), names_to = \"manipulation\", values_to = \"effect\")\n# dat_bf_sm$effectsize &lt;- \"small-to-medium\"\n# dat_bf &lt;- rbind(dat_bf_s, dat_bf_sm)\n# dat_bf$analysis &lt;- \"Bayes Factor &gt; 10\"\n# dat_bf$manipulation &lt;- recode(dat_bf$manipulation, `bf_pers &gt; 10` = \"persistence\", `BF_anon &gt; 10` = \"anonymity\")\n\ndat_fr_s$effectsize &lt;- \"small\"\ndat_fr_sm$effectsize &lt;- \"small-to-medium\"\ndat_fr &lt;- rbind(dat_fr_s, dat_fr_sm)\n# dat_fr$analysis &lt;- \"Frequentist\"\n\ndat &lt;- dat_fr %&gt;% \n  rename(Manipulation = manipulation,\n         `Effect size` = effectsize,\n         Effect = effect,\n         Replications = reps) %&gt;% \n  mutate(\n    # analysis = factor(analysis, levels = c(\"Frequentist\", \"Bayes Factor &gt; 10\")),\n    `Effect size` = factor(`Effect size`, levels = c(\"small-to-medium\", \"small\")))\n\npower_fig &lt;- ggplot(dat, aes(Replications, Effect, color = `Effect size`, shape = Manipulation)) +\n  scale_color_manual(values=c(\"black\", \"grey60\")) +\n  geom_vline(xintercept = 4, linetype = \"dashed\", color = \"grey\") + \n  geom_point(alpha = .9) +\n  scale_x_discrete(limits = c(1:n_reps))\npower_fig\n\n\n\n\n\n\n\nggsave(\"figures/fig_power.png\", width = 8, height = 4)"
  },
  {
    "objectID": "deviations.html",
    "href": "deviations.html",
    "title": "Deviations from Preregistration",
    "section": "",
    "text": "We decided to not exclude people who missed the questionnaire at T2, as participation wasn’t necessary for our analyses and would have only led to unnecessary dropouts.\nWe originally preregistered to have crossed multilevel structure, when in reality the structure is nested (groups are nested in topics).\nWe initially didn’t include control variables. However, including pre-treatment control variables improves parameter estimation (see Gelman, A., Hill, J., & Vehtari, A. (2020). Regression and other stories (1st ed.). Cambridge University Press. https://doi.org/10.1017/978113916187), which is why we decided to include it.\nTogether, We hence corrected this as follows:\n\nPreregistered: expressions ~ 1 + persistence * anonymity + (1 | topic) + (1 | group)\nUpdated: expressions ~ 1 + age + female + pol_stance + persistence * anonymity + (1 | topic/group)\n\nWe originally planned to use default (flat) priors (chains = 2, iterations = 2,000, warm-up = 1,000). However, to improve convergence, we increased chains, iterations, and warm-ups.\nWe originally planned to conduct multiple imputation. However, because for the central analyses there were no missing data, this wasn’t necessary"
  },
  {
    "objectID": "planned_analyses.html",
    "href": "planned_analyses.html",
    "title": "Planned analyses",
    "section": "",
    "text": "library(brms)\nlibrary(ggplot2)\nlibrary(knitr)\nlibrary(lme4)\nlibrary(magrittr)\nlibrary(mice)\nlibrary(tidyverse)\nIn what follows, we outline how we plan to analyze the data. Please note that depending on violation of assumptions or non-convergence of models, we likely need to further adjust the model, which is why we cannot preregister the exact model we will ultimately run. But the general approach will be as follows."
  },
  {
    "objectID": "planned_analyses.html#bayesian-mixed-effects-modeling",
    "href": "planned_analyses.html#bayesian-mixed-effects-modeling",
    "title": "Planned analyses",
    "section": "Bayesian mixed effects modeling",
    "text": "Bayesian mixed effects modeling\n\nFixed effects\n\nfit_fe &lt;- \n  brm_multiple(\n    expressions ~ 1 + persistence * anonymity + \n      (1 | topic) + \n      (1 | group), \n    data = d,\n    silent = 2,\n    refresh = 0,  \n    chains = 2,\n    family = zero_inflated_poisson(\"log\")\n    )\n\nsummary(fit_fe)\n\n Family: zero_inflated_poisson \n  Links: mu = log; zi = identity \nFormula: expressions ~ 1 + persistence * anonymity + (1 | topic) + (1 | group) \n   Data: d (Number of observations: 960) \n  Draws: 200 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 200000\n\nMultilevel Hyperparameters:\n~group (Number of levels: 48) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.03      0.02     0.00     0.09 1.01    13744    40109\n\n~topic (Number of levels: 3) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.09      0.14     0.00     0.44 1.05     2245      813\n\nRegression Coefficients:\n                      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nIntercept                 0.81      0.07     0.67     0.94 1.06     2092\npersistence              -0.10      0.05    -0.19    -0.01 1.01     9585\nanonymity                 0.12      0.05     0.03     0.21 1.01    10175\npersistence:anonymity     0.12      0.09    -0.06     0.31 1.01     8376\n                      Tail_ESS\nIntercept                 1220\npersistence              38273\nanonymity                63450\npersistence:anonymity    25836\n\nFurther Distributional Parameters:\n   Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nzi     0.03      0.01     0.01     0.06 1.02     4681     5829\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n\n\nRandom effects\n\nfit_re &lt;- \n  brm_multiple(\n    expressions ~ 1 + persistence * anonymity + \n      (1 + persistence * anonymity | topic) + \n      (1 + persistence * anonymity | group), \n    data = d,\n    silent = 2,\n    refresh = 0, \n    chains = 2,\n    family = zero_inflated_poisson(\"log\")\n    )\n\nsummary(fit_re)\n\n Family: zero_inflated_poisson \n  Links: mu = log; zi = identity \nFormula: expressions ~ 1 + persistence * anonymity + (1 + persistence * anonymity | topic) + (1 + persistence * anonymity | group) \n   Data: d (Number of observations: 960) \n  Draws: 200 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 200000\n\nMultilevel Hyperparameters:\n~group (Number of levels: 48) \n                                       Estimate Est.Error l-95% CI u-95% CI\nsd(Intercept)                              0.03      0.02     0.00     0.09\nsd(persistence)                            0.06      0.05     0.00     0.18\nsd(anonymity)                              0.06      0.05     0.00     0.18\nsd(persistence:anonymity)                  0.12      0.10     0.00     0.35\ncor(Intercept,persistence)                -0.03      0.45    -0.83     0.80\ncor(Intercept,anonymity)                  -0.01      0.45    -0.82     0.81\ncor(persistence,anonymity)                 0.03      0.45    -0.81     0.82\ncor(Intercept,persistence:anonymity)       0.03      0.45    -0.80     0.83\ncor(persistence,persistence:anonymity)    -0.02      0.45    -0.82     0.80\ncor(anonymity,persistence:anonymity)      -0.02      0.45    -0.82     0.80\n                                       Rhat Bulk_ESS Tail_ESS\nsd(Intercept)                          1.01    17536    44380\nsd(persistence)                        1.01    19179    49567\nsd(anonymity)                          1.01    27423    25849\nsd(persistence:anonymity)              1.01    21086    51097\ncor(Intercept,persistence)             1.01    17439    43783\ncor(Intercept,anonymity)               1.01    14408    22168\ncor(persistence,anonymity)             1.01     9238     3278\ncor(Intercept,persistence:anonymity)   1.01    14660    16370\ncor(persistence,persistence:anonymity) 1.01    29892    95587\ncor(anonymity,persistence:anonymity)   1.01    11672    35895\n\n~topic (Number of levels: 3) \n                                       Estimate Est.Error l-95% CI u-95% CI\nsd(Intercept)                              0.12      0.17     0.00     0.62\nsd(persistence)                            0.28      0.35     0.01     1.27\nsd(anonymity)                              0.24      0.31     0.01     1.17\nsd(persistence:anonymity)                  0.42      0.59     0.01     2.08\ncor(Intercept,persistence)                -0.03      0.46    -0.84     0.82\ncor(Intercept,anonymity)                   0.02      0.46    -0.82     0.84\ncor(persistence,anonymity)                -0.05      0.47    -0.86     0.81\ncor(Intercept,persistence:anonymity)       0.02      0.46    -0.82     0.84\ncor(persistence,persistence:anonymity)    -0.04      0.46    -0.85     0.81\ncor(anonymity,persistence:anonymity)       0.02      0.46    -0.82     0.85\n                                       Rhat Bulk_ESS Tail_ESS\nsd(Intercept)                          1.02     6204     2206\nsd(persistence)                        1.01    10929     7453\nsd(anonymity)                          1.01    10454     6697\nsd(persistence:anonymity)              1.04     2876     1164\ncor(Intercept,persistence)             1.01    21790    18450\ncor(Intercept,anonymity)               1.01    21695    57354\ncor(persistence,anonymity)             1.02     7616     4088\ncor(Intercept,persistence:anonymity)   1.01    21972    35474\ncor(persistence,persistence:anonymity) 1.01    25380    54882\ncor(anonymity,persistence:anonymity)   1.01    16162    32143\n\nRegression Coefficients:\n                      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nIntercept                 0.82      0.10     0.62     1.04 1.04     3243\npersistence              -0.10      0.21    -0.56     0.36 1.01     8330\nanonymity                 0.12      0.18    -0.29     0.52 1.01    10602\npersistence:anonymity     0.15      0.44    -0.54     1.00 1.04     2758\n                      Tail_ESS\nIntercept                 1639\npersistence               7268\nanonymity                 6515\npersistence:anonymity     1165\n\nFurther Distributional Parameters:\n   Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nzi     0.03      0.01     0.01     0.06 1.03     4211     2437\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1)."
  },
  {
    "objectID": "analyses.html",
    "href": "analyses.html",
    "title": "Analyses",
    "section": "",
    "text": "library(brms)\nlibrary(ggplot2)\nlibrary(kableExtra)\nlibrary(lme4)\nlibrary(lmerTest)\nlibrary(rmarkdown)\nlibrary(naniar)\nlibrary(performance)\nlibrary(see)\nlibrary(sjmisc)\nlibrary(tidyverse)\n\noptions(\n  digits = 3\n)\nset.seed(170819)\n\n\n\n\n\n# function to silence brms output\nhush &lt;- \n  function(\n    code\n    ){\n    sink(\"/dev/null\")\n    tmp = code\n    sink()\n    return(tmp)\n    }\n\n\n\n\n\nd &lt;- read_csv(\"data/data.csv\")\n\n# same as above; but original file name:\n# d &lt;- read_csv(\"data/DataAggregated_T1T2_costsbenefits.csv\")\n\n# load image for work in IDE\n# load(\"data/image.RData\")\n\nd &lt;- d |&gt; \n  rename(\n    group = roles,\n    op_expr = n_OE,\n    gender = DE01_T1,\n    age = DE02_01_T1,\n    pol_stance = DE06_01_T1\n  ) |&gt; \n  mutate(\n    female = as.logical(2 - gender),\n    gender = factor(gender, labels = c(\"female\", \"male\"))\n  )\n\n# recode to make as sum coding\nd$anonymity_dev &lt;- factor(d$anonymity)\ncontrasts(d$anonymity_dev) &lt;- contr.sum(2)\nd$persistence_dev &lt;- factor(d$persistence)\ncontrasts(d$persistence_dev) &lt;- contr.sum(2)"
  },
  {
    "objectID": "analyses.html#packages",
    "href": "analyses.html#packages",
    "title": "Analyses",
    "section": "",
    "text": "library(brms)\nlibrary(ggplot2)\nlibrary(kableExtra)\nlibrary(lme4)\nlibrary(lmerTest)\nlibrary(rmarkdown)\nlibrary(naniar)\nlibrary(performance)\nlibrary(see)\nlibrary(sjmisc)\nlibrary(tidyverse)\n\noptions(\n  digits = 3\n)\nset.seed(170819)"
  },
  {
    "objectID": "analyses.html#custom-functions",
    "href": "analyses.html#custom-functions",
    "title": "Analyses",
    "section": "",
    "text": "# function to silence brms output\nhush &lt;- \n  function(\n    code\n    ){\n    sink(\"/dev/null\")\n    tmp = code\n    sink()\n    return(tmp)\n    }"
  },
  {
    "objectID": "analyses.html#data",
    "href": "analyses.html#data",
    "title": "Analyses",
    "section": "",
    "text": "d &lt;- read_csv(\"data/data.csv\")\n\n# same as above; but original file name:\n# d &lt;- read_csv(\"data/DataAggregated_T1T2_costsbenefits.csv\")\n\n# load image for work in IDE\n# load(\"data/image.RData\")\n\nd &lt;- d |&gt; \n  rename(\n    group = roles,\n    op_expr = n_OE,\n    gender = DE01_T1,\n    age = DE02_01_T1,\n    pol_stance = DE06_01_T1\n  ) |&gt; \n  mutate(\n    female = as.logical(2 - gender),\n    gender = factor(gender, labels = c(\"female\", \"male\"))\n  )\n\n# recode to make as sum coding\nd$anonymity_dev &lt;- factor(d$anonymity)\ncontrasts(d$anonymity_dev) &lt;- contr.sum(2)\nd$persistence_dev &lt;- factor(d$persistence)\ncontrasts(d$persistence_dev) &lt;- contr.sum(2)"
  },
  {
    "objectID": "analyses.html#opinion-expressions",
    "href": "analyses.html#opinion-expressions",
    "title": "Analyses",
    "section": "Opinion expressions",
    "text": "Opinion expressions\nLet’s look at the distribution of communicated number of words.\n\nggplot(d, aes(op_expr)) +\n  geom_histogram(bins = 50)\n\n\n\n\n\n\n\n\nLet’s also look at how many did not express any opinions at all.\nNumber:\n\nlength(which(d$op_expr == 0))\n\n[1] 205\n\n\nPercentage:\n\nlength(which(d$op_expr == 0)) / length(d$op_expr)\n\n[1] 0.214\n\n\nStats:\n\nsummary(d$op_expr)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n    0.0     1.0     6.0     9.3    12.0   186.0"
  },
  {
    "objectID": "analyses.html#communicated-words",
    "href": "analyses.html#communicated-words",
    "title": "Analyses",
    "section": "Communicated words",
    "text": "Communicated words\nLet’s look at the distribution of communicated number of words.\n\nggplot(d, aes(n_Words)) +\n  geom_histogram(bins = 50)\n\nWarning: Removed 198 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\n\n\n\n\n\n\n\nLet’s also look at how many did not write any words at all.\n\nlength(which(d$n_Words == 0))\n\n[1] 0\n\n\nEveryone wrote at least one word.\nStats:\n\nsummary(d$n_Words)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n      1     149     336     496     602    8843     198"
  },
  {
    "objectID": "analyses.html#cross-contamination",
    "href": "analyses.html#cross-contamination",
    "title": "Analyses",
    "section": "Cross contamination",
    "text": "Cross contamination\nLet’s look at cross contamination, i.e. if anonymity affected perceived persistence and if persistence affects perceived anonymity.\n\nd |&gt; \n  group_by(anonymity) |&gt; \n  summarize(\n    \"Perceived persistence\" = mean(per_persistence, na.rm = TRUE)\n    ) |&gt; \n  as.data.frame() |&gt; \n  kable()\n\n\n\n\nanonymity\nPerceived persistence\n\n\n\n\nhigh\n2.89\n\n\nlow\n3.00\n\n\n\n\n\nThere was next to no difference among groups.\n\nmodel_pers &lt;- lm(\n  per_persistence ~ anonymity_dev,\n  d\n)\n\nsummary(model_pers)\n\n\nCall:\nlm(formula = per_persistence ~ anonymity_dev, data = d)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-2.005 -1.671  0.108  1.662  2.108 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)      2.9485     0.0591   49.86   &lt;2e-16 ***\nanonymity_dev1  -0.0561     0.0591   -0.95     0.34    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.57 on 703 degrees of freedom\n  (255 observations deleted due to missingness)\nMultiple R-squared:  0.00128,   Adjusted R-squared:  -0.000141 \nF-statistic: 0.901 on 1 and 703 DF,  p-value: 0.343\n\n\nThe difference was not statistically significant. No cross contamination re. anonymity.\n\nd |&gt; \n  group_by(persistence) |&gt; \n  summarize(\n    \"Perceived anonymity\" = mean(per_anonymity, na.rm = TRUE)\n    ) |&gt; \n  as.data.frame() |&gt; \n  kable()\n\n\n\n\npersistence\nPerceived anonymity\n\n\n\n\nhigh\n2.76\n\n\nlow\n2.93\n\n\n\n\n\nThere was next to no difference in the groups’ means.\n\nmodel_anon &lt;- lm(\n  per_anonymity ~ persistence_dev,\n  d\n)\nsummary(model_anon)\n\n\nCall:\nlm(formula = per_anonymity ~ persistence_dev, data = d)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-1.933 -1.763 -0.763  2.067  2.237 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)        2.8479     0.0698   40.83   &lt;2e-16 ***\npersistence_dev1  -0.0848     0.0698   -1.22     0.22    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.85 on 703 degrees of freedom\n  (255 observations deleted due to missingness)\nMultiple R-squared:  0.0021,    Adjusted R-squared:  0.00068 \nF-statistic: 1.48 on 1 and 703 DF,  p-value: 0.224\n\n\nAgain, no significant difference. In conclusion, no cross-contamination."
  },
  {
    "objectID": "analyses.html#fixed-effects",
    "href": "analyses.html#fixed-effects",
    "title": "Analyses",
    "section": "Fixed effects",
    "text": "Fixed effects\nWe preregistered to analyze fixed effects.\n\nfit_fe_1 &lt;- \n  hush(\n    brm(\n      op_expr ~ \n        1 + persistence_dev * anonymity_dev + age + female + pol_stance +\n        (1 | topic/group)\n      , data = d\n      , chains = 4\n      , cores = 4\n      , iter = 6000\n      , warmup = 2000\n      , family = zero_inflated_poisson()\n      , control = list(\n        adapt_delta = .95\n        , max_treedepth = 12\n        )\n      , save_pars = save_pars(all = TRUE)\n      , silent = 2\n      )\n  )\n\nWarning: There were 214 divergent transitions after warmup. See\nhttps://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup\nto find out why this is a problem and how to eliminate them.\n\n\nWarning: Examine the pairs() plot to diagnose sampling problems\n\n\nShows some convergence warnings. Let’s inspect model.\n\nplot(fit_fe_1, ask = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTrace-plots look alright.\nLet’s look at results.\n\nsummary(fit_fe_1)\n\nWarning: There were 214 divergent transitions after warmup. Increasing\nadapt_delta above 0.95 may help. See\nhttp://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup\n\n\n Family: zero_inflated_poisson \n  Links: mu = log; zi = identity \nFormula: op_expr ~ 1 + persistence_dev * anonymity_dev + age + female + pol_stance + (1 | topic/group) \n   Data: d (Number of observations: 960) \n  Draws: 4 chains, each with iter = 6000; warmup = 2000; thin = 1;\n         total post-warmup draws = 16000\n\nMultilevel Hyperparameters:\n~topic (Number of levels: 3) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.27      0.31     0.01     1.18 1.00     1935     4004\n\n~topic:group (Number of levels: 48) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.40      0.05     0.32     0.50 1.00     2863     4835\n\nRegression Coefficients:\n                                Estimate Est.Error l-95% CI u-95% CI Rhat\nIntercept                           1.99      0.20     1.56     2.43 1.00\npersistence_dev1                   -0.01      0.06    -0.12     0.11 1.00\nanonymity_dev1                     -0.01      0.06    -0.13     0.10 1.00\nage                                 0.01      0.00     0.01     0.01 1.00\nfemaleTRUE                         -0.00      0.02    -0.05     0.05 1.00\npol_stance                         -0.02      0.01    -0.03    -0.01 1.00\npersistence_dev1:anonymity_dev1     0.02      0.06    -0.09     0.14 1.00\n                                Bulk_ESS Tail_ESS\nIntercept                           3751     2124\npersistence_dev1                    2818     4655\nanonymity_dev1                      2685     5035\nage                                22907    13685\nfemaleTRUE                          9989    10431\npol_stance                         11560    10620\npersistence_dev1:anonymity_dev1     2773     4109\n\nFurther Distributional Parameters:\n   Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nzi     0.21      0.01     0.19     0.24 1.00    10401     9549\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nNo significant effect emerged.\nLet’s inspect ICC\n\nvar_ratio_fe &lt;- performance::variance_decomposition(\n  fit_fe_1\n  , by_group = TRUE)\nvar_ratio_fe\n\n# Random Effect Variances and ICC\n\nConditioned on: all random effects\n\n## Variance Ratio (comparable to ICC)\nRatio: 0.42  CI 95%: [-0.24 0.72]\n\n## Variances of Posterior Predicted Distribution\nConditioned on fixed effects: 31.94  CI 95%: [15.38 68.22]\nConditioned on rand. effects: 55.01  CI 95%: [49.75 60.91]\n\n## Difference in Variances\nDifference: 22.97  CI 95%: [-13.03 40.39]\n\n\n41.886 percent of variance in opinion expressions explained by both topics and groups.\nLet’s visualize results to see what they exactly mean.\n\np &lt;- plot(\n  conditional_effects(\n    fit_fe_1\n    ), \n  ask = FALSE,\n  plot = FALSE\n  )\n\np_anon &lt;- \n  p[[\"anonymity_dev\"]] +\n  xlab(\"Anonymity\") +\n  ylab(\"Opinion expression\") +\n  scale_x_discrete(\n    limits = rev\n     ) +\n  scale_y_continuous(\n    limits = c(5, 14)\n    , breaks = c(6, 8, 10, 12, 14)\n    )\n\np_pers &lt;- \n  p[[\"persistence_dev\"]] +\n  xlab(\"Persistence\") +\n  ylab(\"Opinion expression\") +\n  scale_x_discrete(\n    limits = rev\n   ) +\n  scale_y_continuous(\n    limits = c(5, 14)\n    , breaks = c(6, 8, 10, 12, 14)\n    ) +\n  theme(\n    axis.title.y = element_blank()\n    )\n\np_int &lt;- \n  p[[\"persistence_dev:anonymity_dev\"]] +\n  xlab(\"Persistence\") +\n  scale_x_discrete(\n    limits = rev\n     ) +\n  scale_color_discrete(\n    labels = c(\"low\", \"high\")\n    ) +\n  guides(\n    fill = \"none\",\n    color = guide_legend(\n      title = \"Anonymity\"\n      )\n    ) +\n  theme(\n    axis.title.y = element_blank()\n    ) +\n  scale_y_continuous(\n    limits = c(5, 14)\n    , breaks = c(6, 8, 10, 12, 14)\n    )\n\nplot &lt;- cowplot::plot_grid(\n  p_anon, p_pers, p_int, \n  labels = c('A', 'B', \"C\"), \n  nrow = 1,\n  rel_widths = c(2, 2, 3)\n  )\n\nplot\n\n\n\n\n\n\n\nggsave(\"figures/results.png\", plot, width = 8, height = 4)\n\nShows that there are no main effects. There seems to be a (nonsignificant) interaction effect. In low persistence environment, anonymity is conducive to communication; in high it’s the opposite.\nLet’s look at posteriors\n\np_1 &lt;- \n  pp_check(fit_fe_1) + \n  labs(title = \"Zero-inflated poisson\")\n\nUsing 10 posterior draws for ppc type 'dens_overlay' by default.\n\np_1\n\n\n\n\n\n\n\n\nThe actual distribution cannot be precisely reproduced, but it’s also not too far off."
  },
  {
    "objectID": "analyses.html#random-effects",
    "href": "analyses.html#random-effects",
    "title": "Analyses",
    "section": "Random effects",
    "text": "Random effects\nWe preregistered to explore and compare models with random effects. So let’s model how the experimental conditions affect the outcomes differently depending on topic.\n\nfit_re_1 &lt;- \n  hush(\n    brm(\n      op_expr ~ \n        1 + persistence_dev * anonymity_dev + age + female + pol_stance +\n        (1 + persistence_dev * anonymity_dev | topic) + \n        (1 | topic:group)\n      , data = d\n      , chains = 4\n      , cores = 4\n      , iter = 6000\n      , warmup = 2000\n      , family = zero_inflated_poisson()\n      , control = list(\n        adapt_delta = .95\n        , max_treedepth = 15\n        )\n      , save_pars = save_pars(all = TRUE)\n    )\n  )\n\nWarning: There were 757 divergent transitions after warmup. See\nhttps://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup\nto find out why this is a problem and how to eliminate them.\n\n\nWarning: Examine the pairs() plot to diagnose sampling problems\n\n\nWarning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable.\nRunning the chains for more iterations may help. See\nhttps://mc-stan.org/misc/warnings.html#tail-ess\n\n\nShows some convergence warnings.\nLet’s inspect model.\n\nplot(fit_re_1, ask = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTraceplots look alright.\nLet’s look at results.\n\nsummary(fit_re_1)\n\nWarning: There were 757 divergent transitions after warmup. Increasing\nadapt_delta above 0.95 may help. See\nhttp://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup\n\n\n Family: zero_inflated_poisson \n  Links: mu = log; zi = identity \nFormula: op_expr ~ 1 + persistence_dev * anonymity_dev + age + female + pol_stance + (1 + persistence_dev * anonymity_dev | topic) + (1 | topic:group) \n   Data: d (Number of observations: 960) \n  Draws: 4 chains, each with iter = 6000; warmup = 2000; thin = 1;\n         total post-warmup draws = 16000\n\nMultilevel Hyperparameters:\n~topic (Number of levels: 3) \n                                                      Estimate Est.Error\nsd(Intercept)                                             0.35      0.45\nsd(persistence_dev1)                                      0.25      0.38\nsd(anonymity_dev1)                                        0.25      0.40\nsd(persistence_dev1:anonymity_dev1)                       0.44      0.53\ncor(Intercept,persistence_dev1)                          -0.01      0.46\ncor(Intercept,anonymity_dev1)                            -0.01      0.46\ncor(persistence_dev1,anonymity_dev1)                     -0.01      0.46\ncor(Intercept,persistence_dev1:anonymity_dev1)            0.06      0.46\ncor(persistence_dev1,persistence_dev1:anonymity_dev1)     0.01      0.46\ncor(anonymity_dev1,persistence_dev1:anonymity_dev1)      -0.01      0.46\n                                                      l-95% CI u-95% CI Rhat\nsd(Intercept)                                             0.01     1.64 1.00\nsd(persistence_dev1)                                      0.00     1.34 1.00\nsd(anonymity_dev1)                                        0.00     1.36 1.00\nsd(persistence_dev1:anonymity_dev1)                       0.02     2.00 1.00\ncor(Intercept,persistence_dev1)                          -0.83     0.82 1.00\ncor(Intercept,anonymity_dev1)                            -0.83     0.82 1.00\ncor(persistence_dev1,anonymity_dev1)                     -0.83     0.84 1.00\ncor(Intercept,persistence_dev1:anonymity_dev1)           -0.79     0.86 1.00\ncor(persistence_dev1,persistence_dev1:anonymity_dev1)    -0.83     0.84 1.00\ncor(anonymity_dev1,persistence_dev1:anonymity_dev1)      -0.84     0.84 1.00\n                                                      Bulk_ESS Tail_ESS\nsd(Intercept)                                             3999     7589\nsd(persistence_dev1)                                      3022     1235\nsd(anonymity_dev1)                                        2973     4156\nsd(persistence_dev1:anonymity_dev1)                        812     1075\ncor(Intercept,persistence_dev1)                          18914    11709\ncor(Intercept,anonymity_dev1)                            11052    10770\ncor(persistence_dev1,anonymity_dev1)                     14598    12328\ncor(Intercept,persistence_dev1:anonymity_dev1)            4205     1403\ncor(persistence_dev1,persistence_dev1:anonymity_dev1)    13374    12801\ncor(anonymity_dev1,persistence_dev1:anonymity_dev1)       3222     1168\n\n~topic:group (Number of levels: 48) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.40      0.05     0.32     0.50 1.00     1232     2167\n\nRegression Coefficients:\n                                Estimate Est.Error l-95% CI u-95% CI Rhat\nIntercept                           2.00      0.29     1.36     2.59 1.00\npersistence_dev1                   -0.00      0.22    -0.43     0.47 1.00\nanonymity_dev1                     -0.01      0.25    -0.45     0.45 1.00\nage                                 0.01      0.00     0.01     0.01 1.00\nfemaleTRUE                         -0.00      0.02    -0.05     0.04 1.00\npol_stance                         -0.02      0.01    -0.03    -0.01 1.00\npersistence_dev1:anonymity_dev1     0.05      0.39    -0.69     1.38 1.01\n                                Bulk_ESS Tail_ESS\nIntercept                           5679     5933\npersistence_dev1                    7250     6100\nanonymity_dev1                      4316     4669\nage                                17356    12335\nfemaleTRUE                         25008     9823\npol_stance                         14780    10789\npersistence_dev1:anonymity_dev1      681      124\n\nFurther Distributional Parameters:\n   Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nzi     0.21      0.01     0.19     0.24 1.00    16420    10765\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nAgain, no main or interaction effects.\nLet’s see if the random effects model fits better\n\ncores &lt;- parallel::detectCores()\n\nfit_fe_1 &lt;- add_criterion(\n  fit_fe_1\n  , \"kfold\" \n  , K = 5\n  , cores = cores\n  )\n\nFitting model 1 out of 5\n\n\nFitting model 2 out of 5\n\n\nFitting model 3 out of 5\n\n\nFitting model 4 out of 5\n\n\nFitting model 5 out of 5\n\nfit_re_1 &lt;- add_criterion(\n  fit_re_1\n  , \"kfold\"\n  , K = 5\n  , cores = cores\n  )\n\nFitting model 1 out of 5\n\n\nStart sampling\n\n\nFitting model 2 out of 5\n\n\nStart sampling\n\n\nFitting model 3 out of 5\n\n\nStart sampling\n\n\nFitting model 4 out of 5\n\n\nStart sampling\n\n\nFitting model 5 out of 5\n\n\nStart sampling\n\ncomp_1 &lt;- loo_compare(fit_fe_1, fit_re_1, criterion = \"kfold\")\ncomp_1\n\n         elpd_diff se_diff\nfit_re_1    0.0       0.0 \nfit_fe_1 -149.4      69.3 \n\n\nAlthough model comparisons showed that the model with random effects fitted better, the difference was not significant (Δ ELPD = -149.36, 95% CI [-285.246, -13.467]. Hence, for reasons of parsimony the model with fixed effects is preferred."
  },
  {
    "objectID": "analyses.html#null-model",
    "href": "analyses.html#null-model",
    "title": "Analyses",
    "section": "Null-Model",
    "text": "Null-Model\nLet’s also inspect a model without random intercepts to see if including random intercepts is worthwhile.\n\nfit_nm_1 &lt;- \n  hush(\n    brm(\n      op_expr ~ \n        1 + persistence_dev * anonymity_dev + age + female + pol_stance\n      , data = d\n      , chains = 4\n      , cores = 4\n      , iter = 6000\n      , warmup = 2000\n      , family = zero_inflated_poisson()\n      , control = list(\n        adapt_delta = .95\n        , max_treedepth = 12\n        )\n      , save_pars = save_pars(all = TRUE)\n      , silent = 2\n      )\n  )\n\nsummary(fit_nm_1)\n\n Family: zero_inflated_poisson \n  Links: mu = log; zi = identity \nFormula: op_expr ~ 1 + persistence_dev * anonymity_dev + age + female + pol_stance \n   Data: d (Number of observations: 960) \n  Draws: 4 chains, each with iter = 6000; warmup = 2000; thin = 1;\n         total post-warmup draws = 16000\n\nRegression Coefficients:\n                                Estimate Est.Error l-95% CI u-95% CI Rhat\nIntercept                           1.96      0.06     1.85     2.06 1.00\npersistence_dev1                    0.00      0.01    -0.02     0.02 1.00\nanonymity_dev1                     -0.04      0.01    -0.06    -0.02 1.00\nage                                 0.01      0.00     0.01     0.01 1.00\nfemaleTRUE                          0.02      0.02    -0.02     0.07 1.00\npol_stance                         -0.01      0.01    -0.02     0.01 1.00\npersistence_dev1:anonymity_dev1     0.02      0.01    -0.00     0.04 1.00\n                                Bulk_ESS Tail_ESS\nIntercept                          20193    13428\npersistence_dev1                   20156    11001\nanonymity_dev1                     20783    10932\nage                                19306    11896\nfemaleTRUE                         20703    11806\npol_stance                         22715    12379\npersistence_dev1:anonymity_dev1    20156    12002\n\nFurther Distributional Parameters:\n   Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nzi     0.21      0.01     0.19     0.24 1.00    20932    11802\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nShows significant effect of anonymity on opinion expression.\nLet’s compare models.\n\nfit_nm_1 &lt;- add_criterion(\n  fit_nm_1\n  , \"kfold\"\n  , K = 5\n  , cores = cores\n  )\n\nFitting model 1 out of 5\n\n\nFitting model 2 out of 5\n\n\nFitting model 3 out of 5\n\n\nFitting model 4 out of 5\n\n\nFitting model 5 out of 5\n\ncomp_2 &lt;- loo_compare(fit_fe_1, fit_nm_1, criterion = \"kfold\")\ncomp_2\n\n         elpd_diff se_diff\nfit_fe_1    0.0       0.0 \nfit_nm_1 -364.9     134.0 \n\n\nThe model comparisons showed that the model with random intercepts fitted significantly better than the null model with fixed intercepts (Δ ELPD = -364.85, 95% CI [-627.549, -102.152]."
  },
  {
    "objectID": "analyses.html#hurdle",
    "href": "analyses.html#hurdle",
    "title": "Analyses",
    "section": "Hurdle",
    "text": "Hurdle\nLet’s now estimate a fixed effects model with hurdles.\n\nfit_hrdl_1 &lt;- \n  hush(\n    brm(\n      bf(\n        op_expr ~ \n          1 + persistence_dev * anonymity_dev + age + female + pol_stance +\n          (1 | topic) + \n          (1 | topic:group),\n        zi ~ \n          1 + persistence_dev * anonymity_dev + age + female + pol_stance +\n          (1 | topic) + \n          (1 | topic:group)\n      )\n    , data = d\n    , chains = 4\n    , cores = 4\n    , iter = 6000\n    , warmup = 2000\n    , family = zero_inflated_poisson()\n    , control = list(\n      adapt_delta = .95\n      , max_treedepth = 15\n      )\n    )\n  )\n\nWarning: There were 422 divergent transitions after warmup. See\nhttps://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup\nto find out why this is a problem and how to eliminate them.\n\n\nWarning: Examine the pairs() plot to diagnose sampling problems\n\n\nWarning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable.\nRunning the chains for more iterations may help. See\nhttps://mc-stan.org/misc/warnings.html#tail-ess\n\n\nAgain, some warnings.\nLet’s inspect model.\n\nplot(fit_hrdl_1, ask = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTrace-plots look alright.\n\nsummary(fit_hrdl_1)\n\nWarning: There were 422 divergent transitions after warmup. Increasing\nadapt_delta above 0.95 may help. See\nhttp://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup\n\n\n Family: zero_inflated_poisson \n  Links: mu = log; zi = logit \nFormula: op_expr ~ 1 + persistence_dev * anonymity_dev + age + female + pol_stance + (1 | topic) + (1 | topic:group) \n         zi ~ 1 + persistence_dev * anonymity_dev + age + female + pol_stance + (1 | topic) + (1 | topic:group)\n   Data: d (Number of observations: 960) \n  Draws: 4 chains, each with iter = 6000; warmup = 2000; thin = 1;\n         total post-warmup draws = 16000\n\nMultilevel Hyperparameters:\n~topic (Number of levels: 3) \n                 Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)        0.26      0.31     0.01     1.20 1.00     1220      292\nsd(zi_Intercept)     0.28      0.42     0.01     1.52 1.00     3380     4173\n\n~topic:group (Number of levels: 48) \n                 Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)        0.40      0.05     0.32     0.50 1.00     2278     1113\nsd(zi_Intercept)     0.24      0.14     0.02     0.52 1.00     3893     7197\n\nRegression Coefficients:\n                                   Estimate Est.Error l-95% CI u-95% CI Rhat\nIntercept                              2.00      0.18     1.60     2.39 1.01\nzi_Intercept                          -1.69      0.49    -2.61    -0.72 1.00\npersistence_dev1                      -0.01      0.06    -0.13     0.11 1.00\nanonymity_dev1                        -0.01      0.06    -0.13     0.11 1.00\nage                                    0.01      0.00     0.01     0.01 1.00\nfemaleTRUE                            -0.00      0.02    -0.05     0.05 1.00\npol_stance                            -0.02      0.01    -0.03    -0.01 1.00\npersistence_dev1:anonymity_dev1        0.02      0.06    -0.09     0.16 1.01\nzi_persistence_dev1                    0.03      0.09    -0.15     0.20 1.00\nzi_anonymity_dev1                      0.01      0.09    -0.17     0.18 1.00\nzi_age                                 0.01      0.01    -0.00     0.03 1.00\nzi_femaleTRUE                          0.19      0.17    -0.15     0.53 1.00\nzi_pol_stance                         -0.05      0.04    -0.12     0.04 1.00\nzi_persistence_dev1:anonymity_dev1    -0.01      0.09    -0.18     0.17 1.00\n                                   Bulk_ESS Tail_ESS\nIntercept                              4517     2523\nzi_Intercept                           8977     5131\npersistence_dev1                       3100     2940\nanonymity_dev1                         2296     5882\nage                                   17399    12354\nfemaleTRUE                            19167    11310\npol_stance                            21511    10355\npersistence_dev1:anonymity_dev1        1098      208\nzi_persistence_dev1                   12625     3777\nzi_anonymity_dev1                     15515    11855\nzi_age                                17492    11736\nzi_femaleTRUE                         19399    11393\nzi_pol_stance                         19998    11223\nzi_persistence_dev1:anonymity_dev1    15922    10687\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nSame results, no main effects, slightly larger but still non-significant interaction effect."
  },
  {
    "objectID": "analyses.html#frequentist",
    "href": "analyses.html#frequentist",
    "title": "Analyses",
    "section": "Frequentist",
    "text": "Frequentist\nLook at results from a frequentist perspective.\n\nFixed effects\nEstimate nested model.\n\nfit_fe_1_frq &lt;- \n  lmer(\n    op_expr ~ \n      1 + \n      (1 | topic/group) + \n      persistence_dev * anonymity_dev + age + female + pol_stance\n    , data = d\n    )\n\nsummary(fit_fe_1_frq)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: op_expr ~ 1 + (1 | topic/group) + persistence_dev * anonymity_dev +  \n    age + female + pol_stance\n   Data: d\n\nREML criterion at convergence: 7604\n\nScaled residuals: \n   Min     1Q Median     3Q    Max \n-1.484 -0.555 -0.196  0.264 13.549 \n\nRandom effects:\n Groups      Name        Variance Std.Dev.\n group:topic (Intercept) 1.08e+01 3.28e+00\n topic       (Intercept) 8.92e-08 2.99e-04\n Residual                1.55e+02 1.25e+01\nNumber of obs: 960, groups:  group:topic, 48; topic, 3\n\nFixed effects:\n                                Estimate Std. Error       df t value Pr(&gt;|t|)\n(Intercept)                       6.0450     2.1478 885.1185    2.81    0.005\npersistence_dev1                 -0.0197     0.6214  43.8644   -0.03    0.975\nanonymity_dev1                   -0.3437     0.6242  44.6401   -0.55    0.585\nage                               0.0860     0.0357 943.4320    2.41    0.016\nfemaleTRUE                       -0.2434     0.8783 939.5946   -0.28    0.782\npol_stance                       -0.0319     0.2058 942.6445   -0.16    0.877\npersistence_dev1:anonymity_dev1   0.1953     0.6226  44.1939    0.31    0.755\n                                  \n(Intercept)                     **\npersistence_dev1                  \nanonymity_dev1                    \nage                             * \nfemaleTRUE                        \npol_stance                        \npersistence_dev1:anonymity_dev1   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) prss_1 anny_1 age    fmTRUE pl_stn\nprsstnc_dv1  0.015                                   \nannymty_dv1  0.053  0.000                            \nage         -0.750 -0.010 -0.049                     \nfemaleTRUE  -0.463 -0.014  0.041  0.252              \npol_stance  -0.538 -0.009 -0.057 -0.003  0.062       \nprsstn_1:_1  0.019  0.000 -0.002 -0.045 -0.034  0.038\noptimizer (nloptwrap) convergence code: 0 (OK)\nboundary (singular) fit: see help('isSingular')\n\n\nQuite weird that topic doesn’t get any variance at all. Perhaps due to small cluster size? With Bayesian estimation, it worked alright. Also, again no significant effects.\nEstimate without nesting.\n\nfit_fe_2_frq &lt;- \n  lmer(\n    op_expr ~ \n      1 + \n      (1 | group) +\n      persistence_dev * anonymity_dev + age + female + pol_stance + topic\n    , data = d\n    )\n\nsummary(fit_fe_2_frq)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: op_expr ~ 1 + (1 | group) + persistence_dev * anonymity_dev +  \n    age + female + pol_stance + topic\n   Data: d\n\nREML criterion at convergence: 7598\n\nScaled residuals: \n   Min     1Q Median     3Q    Max \n-1.513 -0.548 -0.188  0.265 13.577 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n group    (Intercept)  11       3.32   \n Residual             155      12.46   \nNumber of obs: 960, groups:  group, 48\n\nFixed effects:\n                                Estimate Std. Error       df t value Pr(&gt;|t|)\n(Intercept)                       6.3760     2.3261 511.8117    2.74   0.0063\npersistence_dev1                 -0.0195     0.6257  41.8742   -0.03   0.9753\nanonymity_dev1                   -0.3439     0.6284  42.6053   -0.55   0.5871\nage                               0.0854     0.0357 942.0312    2.39   0.0169\nfemaleTRUE                       -0.2641     0.8788 938.1103   -0.30   0.7638\npol_stance                       -0.0324     0.2058 941.3972   -0.16   0.8751\ntopicgender                       0.4373     1.5334  41.9702    0.29   0.7769\ntopicmigration                   -1.3078     1.5329  41.9180   -0.85   0.3984\npersistence_dev1:anonymity_dev1   0.1960     0.6268  42.1850    0.31   0.7561\n                                  \n(Intercept)                     **\npersistence_dev1                  \nanonymity_dev1                    \nage                             * \nfemaleTRUE                        \npol_stance                        \ntopicgender                       \ntopicmigration                    \npersistence_dev1:anonymity_dev1   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) prss_1 anny_1 age    fmTRUE pl_stn tpcgnd tpcmgr\nprsstnc_dv1  0.014                                                 \nannymty_dv1  0.049  0.000                                          \nage         -0.701 -0.010 -0.049                                   \nfemaleTRUE  -0.423 -0.014  0.041  0.252                            \npol_stance  -0.489 -0.009 -0.057 -0.004  0.063                     \ntopicgender -0.325  0.000 -0.001  0.017 -0.024 -0.020              \ntopicmigrtn -0.337  0.000 -0.001  0.024  0.000 -0.016  0.500       \nprsstn_1:_1  0.018  0.000 -0.001 -0.045 -0.033  0.038 -0.001 -0.002\n\n\nAlso shows no significant effects.\nFor curiosity, estimate also without hierarchical structure.\n\nfit_fe_3_frq &lt;- \n  lm(\n    op_expr ~ \n      1 + \n      persistence_dev * anonymity_dev + topic + age + female + pol_stance\n    , data = d\n    )\n\nsummary(fit_fe_3_frq)\n\n\nCall:\nlm(formula = op_expr ~ 1 + persistence_dev * anonymity_dev + \n    topic + age + female + pol_stance, data = d)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-12.95  -7.46  -2.92   3.00 177.59 \n\nCoefficients:\n                                Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)                       5.7503     2.2095    2.60   0.0094 **\npersistence_dev1                 -0.0223     0.4148   -0.05   0.9571   \nanonymity_dev1                   -0.3598     0.4191   -0.86   0.3908   \ntopicgender                       0.4291     1.0174    0.42   0.6733   \ntopicmigration                   -1.3114     1.0166   -1.29   0.1974   \nage                               0.0901     0.0362    2.49   0.0129 * \nfemaleTRUE                       -0.2010     0.8932   -0.23   0.8220   \npol_stance                        0.0398     0.2087    0.19   0.8489   \npersistence_dev1:anonymity_dev1   0.2004     0.4166    0.48   0.6306   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.8 on 951 degrees of freedom\nMultiple R-squared:  0.0115,    Adjusted R-squared:  0.00315 \nF-statistic: 1.38 on 8 and 951 DF,  p-value: 0.202\n\n\nAlso here, no significant effects."
  },
  {
    "objectID": "analyses.html#gender",
    "href": "analyses.html#gender",
    "title": "Analyses",
    "section": "Gender",
    "text": "Gender\nAs preregistered, let’s see if effects differ across genders.\n\nfit_fe_gen &lt;- \n  hush(\n    brm(\n      op_expr ~ \n        1 + persistence_dev * anonymity_dev * gender + age + pol_stance +\n        (1 | topic/group)\n      , data = d\n      , chains = 4\n      , cores = 4\n      , iter = 8000\n      , warmup = 2000\n      , family = zero_inflated_poisson()\n      , control = list(\n        adapt_delta = .95\n        , max_treedepth = 12\n        )\n      )\n  )\n\nWarning: There were 603 divergent transitions after warmup. See\nhttps://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup\nto find out why this is a problem and how to eliminate them.\n\n\nWarning: Examine the pairs() plot to diagnose sampling problems\n\n\nAgain, some warnings.\nLet’s inspect model.\n\nplot(fit_fe_gen, ask = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTraceplots look alright.\nLet’s look at results.\n\nsummary(fit_fe_gen)\n\nWarning: There were 603 divergent transitions after warmup. Increasing\nadapt_delta above 0.95 may help. See\nhttp://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup\n\n\n Family: zero_inflated_poisson \n  Links: mu = log; zi = identity \nFormula: op_expr ~ 1 + persistence_dev * anonymity_dev * gender + age + pol_stance + (1 | topic/group) \n   Data: d (Number of observations: 960) \n  Draws: 4 chains, each with iter = 8000; warmup = 2000; thin = 1;\n         total post-warmup draws = 24000\n\nMultilevel Hyperparameters:\n~topic (Number of levels: 3) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.21      0.21     0.01     0.84 1.00     3091     4051\n\n~topic:group (Number of levels: 48) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.40      0.05     0.32     0.50 1.00     3874     8425\n\nRegression Coefficients:\n                                           Estimate Est.Error l-95% CI u-95% CI\nIntercept                                      1.99      0.15     1.67     2.32\npersistence_dev1                               0.02      0.06    -0.10     0.14\nanonymity_dev1                                -0.04      0.06    -0.16     0.08\ngendermale                                    -0.00      0.02    -0.05     0.04\nage                                            0.01      0.00     0.01     0.01\npol_stance                                    -0.02      0.01    -0.03    -0.01\npersistence_dev1:anonymity_dev1                0.01      0.06    -0.11     0.12\npersistence_dev1:gendermale                   -0.08      0.02    -0.12    -0.03\nanonymity_dev1:gendermale                      0.07      0.02     0.03     0.11\npersistence_dev1:anonymity_dev1:gendermale     0.05      0.02     0.00     0.09\n                                           Rhat Bulk_ESS Tail_ESS\nIntercept                                  1.00     5113     5226\npersistence_dev1                           1.00     3885     6451\nanonymity_dev1                             1.00     4466     6784\ngendermale                                 1.00    12495     8754\nage                                        1.00    16372     7194\npol_stance                                 1.00    15721    15008\npersistence_dev1:anonymity_dev1            1.00     4269     7151\npersistence_dev1:gendermale                1.00    13393    12807\nanonymity_dev1:gendermale                  1.00    15059    13599\npersistence_dev1:anonymity_dev1:gendermale 1.00    14762    13666\n\nFurther Distributional Parameters:\n   Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nzi     0.21      0.01     0.19     0.24 1.00    14835    13287\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nIndeed, several gender effects.\n\nFor females, the effect of persistence is larger, that is more positive.\nFor females, the effect of anonymity is smaller, that is more negative.\nFor females, the interaction effect is also a bit smaller, that is more negative.\n\nLet’s visualize results.\n\np_gen &lt;- plot(\n  conditional_effects(\n    fit_fe_gen\n    ), \n  ask = FALSE,\n  plot = FALSE\n  )\n\np_gen_pers &lt;- \n  p_gen[[\"persistence_dev:gender\"]] +\n  xlab(\"Persistence\") +\n  ylab(\"Opinion expression\") +\n  scale_y_continuous(\n    limits = c(4, 15),\n    breaks = c(5, 7.5, 10, 12.5, 15)\n  ) +\n  scale_x_discrete(\n    limits = rev\n  ) +\n  guides(\n    fill = \"none\"\n    , color = \"none\"\n    )\n\np_gen_anon &lt;- \n  p_gen[[\"anonymity_dev:gender\"]] +\n  xlab(\"Anonymity\") +\n  ylab(\"Opinion expression\") +\n  scale_y_continuous(\n    limits = c(3.5, 15),\n    breaks = c(5, 7.5, 10, 12.5, 15)\n  ) +\n  theme(\n    axis.title.y = element_blank()\n    ) +\n  guides(\n    fill = \"none\"\n    ) + \n  scale_x_discrete(\n    limits = rev\n  ) +\n  scale_color_discrete(\n    name = \"Gender\"\n    )\n\nplot_gen &lt;- cowplot::plot_grid(\n  p_gen_pers, p_gen_anon, \n  labels = c('A', 'B'), \n  nrow = 1,\n  rel_widths = c(4, 5)\n  )\n\nplot_gen\n\n\n\n\n\n\n\nggsave(\"figures/results_gen.png\", plot_gen, width = 8, height = 4)"
  },
  {
    "objectID": "analyses.html#benefits",
    "href": "analyses.html#benefits",
    "title": "Analyses",
    "section": "Benefits",
    "text": "Benefits\nLet’s see if benefits differ across experimental groups.\nWe first look at the experimental group’s descriptives\n\nd |&gt; \n  group_by(persistence) |&gt; \n  summarize(benefits_m = mean(benefits, na.rm = TRUE)) |&gt; \n  as.data.frame() |&gt; \n  kable()\n\n\n\n\npersistence\nbenefits_m\n\n\n\n\nhigh\n3.12\n\n\nlow\n3.23\n\n\n\n\n\nLooking at persistence, we see people with lower persistence reporting slightly higher benefits.\n\nd |&gt; \n  group_by(anonymity) |&gt; \n  summarize(benefits_m = mean(benefits, na.rm = TRUE)) |&gt; \n  as.data.frame() |&gt; \n  kable()\n\n\n\n\nanonymity\nbenefits_m\n\n\n\n\nhigh\n3.15\n\n\nlow\n3.20\n\n\n\n\n\nLooking at anonymity, we see people with low anonymity reporting marginally higher benefits.\n\nd |&gt; \n  group_by(persistence, anonymity) |&gt; \n  summarize(benefits_m = mean(benefits, na.rm = T)) |&gt; \n  as.data.frame() |&gt; \n  kable()\n\n`summarise()` has grouped output by 'persistence'. You can override using the\n`.groups` argument.\n\n\n\n\n\npersistence\nanonymity\nbenefits_m\n\n\n\n\nhigh\nhigh\n3.07\n\n\nhigh\nlow\n3.18\n\n\nlow\nhigh\n3.22\n\n\nlow\nlow\n3.23\n\n\n\n\n\nLooking at both groups combined, we see that low anonymity and low persistence yielded highest benefits.\nLet’s look if effects are significant.\n\nfit_fe_ben_1 &lt;- \n  hush(\n    brm(\n      benefits ~ \n        1 + persistence_dev * anonymity_dev  + age + female + pol_stance +\n        (1 | topic/group)\n      , data = d\n      , chains = 4\n      , cores = 4\n      , iter = 6000\n      , warmup = 2000\n      , control = list(\n        adapt_delta = .95\n        , max_treedepth = 12\n        )\n      )\n  )\n\nWarning: Rows containing NAs were excluded from the model.\n\n\nWarning: There were 160 divergent transitions after warmup. See\nhttps://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup\nto find out why this is a problem and how to eliminate them.\n\n\nWarning: Examine the pairs() plot to diagnose sampling problems\n\n\nLet’s inspect model.\n\nplot(fit_fe_ben_1, ask = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTraceplots look alright.\nLet’s look at results.\n\nsummary(fit_fe_ben_1)\n\nWarning: There were 160 divergent transitions after warmup. Increasing\nadapt_delta above 0.95 may help. See\nhttp://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup\n\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: benefits ~ 1 + persistence_dev * anonymity_dev + age + female + pol_stance + (1 | topic/group) \n   Data: d (Number of observations: 705) \n  Draws: 4 chains, each with iter = 6000; warmup = 2000; thin = 1;\n         total post-warmup draws = 16000\n\nMultilevel Hyperparameters:\n~topic (Number of levels: 3) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.13      0.17     0.00     0.63 1.00     2141     2071\n\n~topic:group (Number of levels: 48) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.08      0.05     0.00     0.17 1.00     3801     6162\n\nRegression Coefficients:\n                                Estimate Est.Error l-95% CI u-95% CI Rhat\nIntercept                           3.21      0.17     2.85     3.55 1.00\npersistence_dev1                   -0.05      0.03    -0.11     0.01 1.00\nanonymity_dev1                     -0.03      0.03    -0.09     0.03 1.00\nage                                -0.00      0.00    -0.01     0.00 1.00\nfemaleTRUE                         -0.07      0.06    -0.19     0.04 1.00\npol_stance                          0.02      0.01    -0.01     0.04 1.00\npersistence_dev1:anonymity_dev1    -0.02      0.03    -0.08     0.04 1.00\n                                Bulk_ESS Tail_ESS\nIntercept                           2614      903\npersistence_dev1                   10311     8192\nanonymity_dev1                      9308     9903\nage                                18813    12042\nfemaleTRUE                         13006     9174\npol_stance                         10421    10613\npersistence_dev1:anonymity_dev1    10541     7780\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     0.74      0.02     0.70     0.78 1.00    12561     9668\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nNo significant effects. But note that effect of persistence on perceived benefits only marginally not significant."
  },
  {
    "objectID": "analyses.html#costs",
    "href": "analyses.html#costs",
    "title": "Analyses",
    "section": "Costs",
    "text": "Costs\nLet’s see if perceived differed across experimental groups.\nWe first look at the experimental group’s descriptives\n\nd |&gt; \n  group_by(persistence) |&gt; \n  summarize(costs = mean(costs, na.rm = TRUE)) |&gt; \n  as.data.frame() |&gt; \n  kable()\n\n\n\n\npersistence\ncosts\n\n\n\n\nhigh\n1.99\n\n\nlow\n1.99\n\n\n\n\n\nLooking at persistence, we see both groups report equal costs.\n\nd |&gt; \n  group_by(anonymity) |&gt; \n  summarize(costs = mean(costs, na.rm = TRUE)) |&gt; \n  as.data.frame() |&gt; \n  kable()\n\n\n\n\nanonymity\ncosts\n\n\n\n\nhigh\n1.89\n\n\nlow\n2.09\n\n\n\n\n\nLooking at anonymity, we see people with low anonymity report slightly higher costs.\n\nd |&gt; \n  group_by(persistence, anonymity) |&gt; \n  summarize(costs = mean(costs, na.rm = TRUE)) |&gt; \n  as.data.frame() |&gt; \n  kable()\n\n`summarise()` has grouped output by 'persistence'. You can override using the\n`.groups` argument.\n\n\n\n\n\npersistence\nanonymity\ncosts\n\n\n\n\nhigh\nhigh\n1.90\n\n\nhigh\nlow\n2.07\n\n\nlow\nhigh\n1.87\n\n\nlow\nlow\n2.11\n\n\n\n\n\nLooking at both groups combined, we see that highest costs were reported by group with low anonymity and low persistence.\nLet’s look if effects are significant.\n\nfit_fe_costs_1 &lt;- \n  hush(\n    brm(\n      costs ~ \n        1 + persistence_dev * anonymity_dev + age + female + pol_stance +\n        (1 | topic/group)\n      , data = d\n      , chains = 4\n      , cores = 4\n      , iter = 8000\n      , warmup = 2000\n      , control = list(\n        adapt_delta = .95\n        , max_treedepth = 12\n        )\n      )\n  )\n\nWarning: Rows containing NAs were excluded from the model.\n\n\nWarning: There were 186 divergent transitions after warmup. See\nhttps://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup\nto find out why this is a problem and how to eliminate them.\n\n\nWarning: Examine the pairs() plot to diagnose sampling problems\n\n\nLet’s inspect model.\n\nplot(fit_fe_costs_1, ask = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTraceplots look alright.\nLet’s look at results.\n\nsummary(fit_fe_costs_1)\n\nWarning: There were 186 divergent transitions after warmup. Increasing\nadapt_delta above 0.95 may help. See\nhttp://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup\n\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: costs ~ 1 + persistence_dev * anonymity_dev + age + female + pol_stance + (1 | topic/group) \n   Data: d (Number of observations: 705) \n  Draws: 4 chains, each with iter = 8000; warmup = 2000; thin = 1;\n         total post-warmup draws = 24000\n\nMultilevel Hyperparameters:\n~topic (Number of levels: 3) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.13      0.19     0.00     0.66 1.00     3819     2147\n\n~topic:group (Number of levels: 48) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.07      0.05     0.00     0.17 1.00     7146     9973\n\nRegression Coefficients:\n                                Estimate Est.Error l-95% CI u-95% CI Rhat\nIntercept                           2.48      0.19     2.11     2.86 1.00\npersistence_dev1                    0.00      0.03    -0.07     0.07 1.00\nanonymity_dev1                     -0.08      0.03    -0.15    -0.02 1.00\nage                                -0.01      0.00    -0.02    -0.01 1.00\nfemaleTRUE                          0.01      0.07    -0.12     0.14 1.00\npol_stance                         -0.00      0.02    -0.04     0.03 1.00\npersistence_dev1:anonymity_dev1     0.02      0.03    -0.05     0.09 1.00\n                                Bulk_ESS Tail_ESS\nIntercept                           5196     2440\npersistence_dev1                   26569    16662\nanonymity_dev1                     25889    17303\nage                                34343    18126\nfemaleTRUE                         25883    16648\npol_stance                         34809    17089\npersistence_dev1:anonymity_dev1    24338    13993\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     0.84      0.02     0.80     0.89 1.00    30590    16079\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nWe find that anonymity does reduce costs."
  },
  {
    "objectID": "analyses.html#mediation",
    "href": "analyses.html#mediation",
    "title": "Analyses",
    "section": "Mediation",
    "text": "Mediation\nLet’s see if perceived benefits and costs were associated with increased opinion expressions.\n\nfit_fe_med &lt;- \n  hush(\n    brm(\n      op_expr ~ \n        1 + persistence_dev * anonymity_dev + benefits + costs  + age + female + pol_stance + \n        (1 | topic/group)\n      , data = d\n      , chains = 4\n      , cores = 4\n      , iter = 6000\n      , warmup = 2000\n      , family = zero_inflated_poisson()\n      , control = list(\n        adapt_delta = .95\n        , max_treedepth = 12\n        )\n      )\n  )\n\nWarning: Rows containing NAs were excluded from the model.\n\n\nWarning: There were 195 divergent transitions after warmup. See\nhttps://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup\nto find out why this is a problem and how to eliminate them.\n\n\nWarning: Examine the pairs() plot to diagnose sampling problems\n\n\nLet’s look at results.\n\nsummary(fit_fe_med)\n\nWarning: There were 195 divergent transitions after warmup. Increasing\nadapt_delta above 0.95 may help. See\nhttp://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup\n\n\n Family: zero_inflated_poisson \n  Links: mu = log; zi = identity \nFormula: op_expr ~ 1 + persistence_dev * anonymity_dev + benefits + costs + age + female + pol_stance + (1 | topic/group) \n   Data: d (Number of observations: 705) \n  Draws: 4 chains, each with iter = 6000; warmup = 2000; thin = 1;\n         total post-warmup draws = 16000\n\nMultilevel Hyperparameters:\n~topic (Number of levels: 3) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.19      0.23     0.01     0.86 1.00     2218     4466\n\n~topic:group (Number of levels: 48) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.41      0.05     0.32     0.51 1.00     3002     4917\n\nRegression Coefficients:\n                                Estimate Est.Error l-95% CI u-95% CI Rhat\nIntercept                           1.96      0.16     1.63     2.30 1.00\npersistence_dev1                   -0.03      0.06    -0.14     0.09 1.00\nanonymity_dev1                      0.00      0.06    -0.12     0.12 1.00\nbenefits                            0.11      0.02     0.08     0.14 1.00\ncosts                              -0.09      0.01    -0.12    -0.07 1.00\nage                                 0.01      0.00     0.01     0.01 1.00\nfemaleTRUE                          0.00      0.02    -0.05     0.05 1.00\npol_stance                         -0.02      0.01    -0.03    -0.00 1.00\npersistence_dev1:anonymity_dev1     0.02      0.06    -0.10     0.14 1.00\n                                Bulk_ESS Tail_ESS\nIntercept                           4690     4632\npersistence_dev1                    2325     3690\nanonymity_dev1                      2431     3821\nbenefits                           12168    11167\ncosts                              11977    10166\nage                                21747    12851\nfemaleTRUE                         12484    10183\npol_stance                         11991     9162\npersistence_dev1:anonymity_dev1     2662     4144\n\nFurther Distributional Parameters:\n   Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nzi     0.08      0.01     0.06     0.10 1.00    12415    10719\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nWe find that increased perceived costs are associated with decreased opinion expressions. Increased benefits are associated with increased opinion expressions. Let’s check if overall effect is significant.\n\nanon_costs_a_b &lt;- fixef(fit_fe_costs_1)[\"anonymity_dev1\", \"Estimate\"]\nanon_costs_a_se &lt;- fixef(fit_fe_costs_1)[\"anonymity_dev1\", \"Est.Error\"]\nanon_costs_a_dis &lt;- rnorm(10000, anon_costs_a_b, anon_costs_a_se)\n\nanon_costs_b_b &lt;- fixef(fit_fe_med)[\"benefits\", \"Estimate\"]\nanon_costs_b_se &lt;- fixef(fit_fe_med)[\"benefits\", \"Est.Error\"]\nanon_costs_b_dis &lt;- rnorm(10000, anon_costs_b_b, anon_costs_b_se)\n\nanon_costs_ab_dis &lt;- anon_costs_a_dis * anon_costs_b_dis\nanon_costs_ab_m &lt;- median(anon_costs_ab_dis)\nanon_costs_ab_ll &lt;- quantile(anon_costs_ab_dis, .025)\nanon_costs_ab_ul &lt;- quantile(anon_costs_ab_dis, .975)\n\nThe effect is significant (b = -0.01, 95% MC CI [-0.02, 0])."
  }
]