---
title: "Analyses with words as outcome"
format: 
  html:
    self-contained: true
    toc: true
    toc-float: true
execute:
  cache: true
---

# Set-up
## Packages

```{r}
#| message: false
#| result: hide
library(brms)
library(ggplot2)
library(lme4)
library(sjmisc)
library(tidyverse)
options(
  digits = 3
)
```

## Data

```{r}
# d <- read_csv("data/data.csv")
d <- read_csv("data/DataAggregated_T1T2_nwords.csv")
# load("data/image_words.RData")

d <- d %>% 
  mutate(
    persistence_dev = persistence - .5,
    anonymity_dev = anonymity - .5,
    group = QUESTNNR_T1,
    id = CASE_T1,
    n_Words = replace_na(n_Words, 0)
  )
```

# Descriptives

Let's inspect distribution of opinion expressions.

```{r}
ggplot(d, aes(n_Words)) +
  geom_histogram(binwidth = 50)
```

Looks like a zero-inflated poisson distribution. Confirms our preregistered approach to analyze data using zero-inflated Poisson approach.

```{r}
nrow(d[d$n_Words == 0, ]) / nrow(d)
```

Overall, 21% of participants without any opinion expressions.

Let's look at distribution of experimental groups.

```{r}
d %>% 
  select(persistence, anonymity) %>% 
  table
```

Distribution among groups perfect.

```{r}
d %>% 
  select(topic) %>% 
  table
```

Distribution of topics also perfect.

Let's check if groups are nested in topics:

```{r}
is_nested(d$topic, d$group)
```

Indeed the case. 

We first look at the experimental group's descriptives

```{r}
d %>% 
  group_by(persistence) %>% 
  summarize(n_Words_m = mean(n_Words))
```

Looking at persistence, we see there's virtually no difference among groups.

```{r}
d %>% 
  group_by(anonymity) %>% 
  summarize(n_Words_m = mean(n_Words))
```

People who with _less_ anonymity communicated _more_. But the difference isn't particularly large.

```{r}
d %>% 
  group_by(persistence, anonymity) %>% 
  summarize(n_Words_m = mean(n_Words))
```

Looking at both groups combined, we see that low anonymity and low persistence created highest participation. But differences among groups aren't large.

```{r}
d %>% 
  group_by(group) %>% 
  summarize(
    anonymity = anonymity[1],
    persistence = persistence[1],
    topic = topic[1],
    n_Words_m = mean(n_Words)
    ) %>% 
  rmarkdown::paged_table()
```

Looking at the various individual groups, we do see some difference. Generally, this shows that individually, communication varied. But not so much systematically across experimental groups.

```{r}
d %>% 
  group_by(topic) %>% 
  summarize(n_Words_m = mean(n_Words))
```

Looking at topics specifically, we also see that there's some variance.

# Bayesian mixed effects modeling

We analyze the data using Bayesian modelling. 

We use deviation contrast coding (-.5, .5). Meaning, contrasts measure main effects of independent variables.

## Fixed effects 

We preregistered to analyze fixed effects. However, we did not explicate if we were to model zero inflation separately. Below hence two options.

```{r fixed-effects-model-1}
#| message: false
fit_fe_1 <- 
  brm(
    n_Words ~ 
      1 + persistence_dev * anonymity_dev +
      (1 | topic/group)
    , data = d
    , chains = 4
    , cores = 4
    , iter = 8000
    , warmup = 2000
    , family = zero_inflated_poisson()
    , control = list(
      adapt_delta = .95
      , max_treedepth = 12
      )
    )
```

Only some convergence issues. Let's inspect model.

```{r fixed-effects-model-1-insp}
plot(fit_fe_1, ask = FALSE)
```

Looks quite good!

Let's look at results.

```{r fixed-effects-model-1-sum}
summary(fit_fe_1)
```

No significant effect emerged.

Let's look at exponentiated results for interpretation.

```{r fixed-effects-model-1-tab}
broom.mixed::tidy(fit_fe_1) |> 
  mutate(
    estimate_exp = exp(estimate),
    conf_low_exp = exp(conf.low),
    conf_high_exp = exp(conf.high)
    ) %>% 
  mutate(
    across(
      c(
        estimate
        , conf.low
        , conf.high
        , estimate_exp
        , conf_low_exp
        , conf_high_exp
        ),
      ~ round(.x, 2)
    )
  ) %>% 
  select(
    -effect, -component, -group, -std.error
  ) %>% 
  rmarkdown::paged_table()
```

Again, of course no significant effect. Main effects appear trivial. Interaction effect somewhat larger. Let's visualize results to see what this exactly means.

```{r fixed-effects-model-1-vis}
int_conditions <- list(
  anonymity_dev = setNames(c(-.5, .5), c("low", "high")),
  persistence_dev = setNames(c(-.5, .5), c("low", "high"))
)

plot(
  conditional_effects(
    fit_fe_1,
    int_conditions = int_conditions
    ), 
  ask = FALSE
  )
```

Shows that there are no main effects. There seems to be a (nonsignificant) interaction effect. In high persistence environment, anonymity is conducive to communication; in low it's the opposite.

Let's look at posteriors

```{r fixed-effects-model-1-pos}
p_1 <- 
  pp_check(fit_fe_1) + 
  labs(title = "Zero-inflated poisson")
p_1
```

The actual distribution cannot be precisely reproduced, but it's also not too far off.

## Random effects

We said we'd explorate random effects. Following the "keep it maximal" principle, it'd actually make sense to consider these analyses the best ones, as they can model how the experimental conditions affect the outcomes differentially depending on topic.

Let's now model random effects.

```{r random-effects-model-1}
#| message: false

fit_re_1 <- 
  brm(
    n_Words ~ 
      1 + persistence_dev * anonymity_dev +
      (1 + persistence_dev * anonymity_dev | topic) + 
      (1 | topic:group)
    , data = d
    , chains = 4
    , cores = 4
    , iter = 8000
    , warmup = 2000
    , family = zero_inflated_poisson()
    , control = list(
      adapt_delta = .95
      , max_treedepth = 15
      )
    )
```

Shows some problems, but not all that many.

Let's inspect model.

```{r random-effects-model-1-insp}
plot(fit_re_1, ask = FALSE)
```

Traceplots look alright.

Let's look at results.

```{r random-effects-model-1-sum}
summary(fit_re_1)
```

Again, virtually no main effect. Interaction effect larger, but also not even closely significant. 

Let's inspect coefficients individually.

```{r}
coefficients(fit_re_1)
```

Interestingly, we see that experimental manipulations are just very different across topics. It seems effects don't really generalize!

Let's look at exponentiated results for interpretation.

```{r random-effects-model-1-tab}
broom.mixed::tidy(fit_re_1) |> 
  mutate(
    estimate_exp = exp(estimate),
    conf_low_exp = exp(conf.low),
    conf_high_exp = exp(conf.high)
    ) %>% 
  mutate(
    across(
      c(
        estimate
        , conf.low
        , conf.high
        , estimate_exp
        , conf_low_exp
        , conf_high_exp
        ),
      ~ round(.x, 2)
    )
  ) %>% 
  select(
    -effect, -component, -group, -std.error
  ) %>% 
  rmarkdown::paged_table()
```

Let's visualize results.

```{r random-effects-model-1-vis}
plot(
  conditional_effects(
    fit_re_1,
    int_conditions = int_conditions
    ), 
  ask = FALSE
  )
```

Picture remains the same, though effects seem even less pronounced.

Let's look at posteriors

```{r random-effects-model-1-pos}
p_3 <- 
  pp_check(fit_re_1) + 
  labs(title = "Zero-inflated poisson")
p_3
```

Same result.

## Hurdle
### Fixed effects

Let's now run a hurdle-model where we model zeros and intensity of communication separately.

```{r fixed-effects-model-2}
#| message: false
fit_fe_2 <- 
  brm(
    bf(
      n_Words ~ 
        1 + persistence_dev * anonymity_dev +
        (1 | topic/group),
      zi ~ 
        1 + persistence_dev * anonymity_dev + 
        (1 | topic/group)
    )
    , data = d
    , chains = 4
    , cores = 4
    , iter = 8000
    , warmup = 2000
    , family = zero_inflated_poisson()
    , control = list(
      adapt_delta = .95
      , max_treedepth = 12
      )
    )
```

Some divergent transitions, but other than that no further problems.

Let's inspect model.

```{r fixed-effects-model-2-insp}
plot(fit_fe_2, ask = FALSE)
```

Estimation looks good!

```{r fixed-effects-model-2-sum}
summary(fit_fe_2)
```

Again, no significant effects.

Let's look at exponentiated results for interpretation. Effects for ZIs still need to be adapted.

```{r fixed-effects-model-2-tab}
broom.mixed::tidy(fit_fe_2) |> 
  mutate(
    estimate_exp = exp(estimate),
    conf_low_exp = exp(conf.low),
    conf_high_exp = exp(conf.high),
    estimate_zi = exp(estimate) / (1 + exp(estimate)),
    conf_low_zi = exp(conf.low) / (1 + exp(conf.low)),
    conf_high_zi = exp(conf.high) / (1 + exp(conf.high))
    ) %>% 
  mutate(
    across(
      c(
        estimate
        , conf.low
        , conf.high
        , estimate_exp
        , conf_low_exp
        , conf_high_exp
        , estimate_zi 
        , conf_low_zi 
        , conf_high_zi
        ),
      ~ round(.x, 2)
    )
  ) %>% 
  select(
    -effect, -group, -std.error  # , -component
  ) %>% 
  rmarkdown::paged_table()
```

Let's visualize results.

```{r fixed-effects-model-2-vis}
plot(
  conditional_effects(
    fit_fe_2,
    int_conditions = int_conditions
    ), 
  ask = FALSE
  )

```

Same as before, but interaction effect seems more pronounced. 

Let's look at posteriors

```{r fixed-effects-model-2-pos}
p_2 <- 
  pp_check(fit_fe_2) + 
  labs(title = "Zero-inflated poisson with predicted ZI probabilities")
p_2
```

Again, not really precise, but also not completely off.

### Random effects

Let's now estimate a mixed effects model with hurdles. 

```{r random-effects-model-2_fit}
#| message: false
fit_re_2 <- 
  brm(
    bf(
      n_Words ~ 
        1 + persistence_dev * anonymity_dev +
        (1 + persistence_dev * anonymity_dev | topic) + 
        (1 | topic:group),
      zi ~ 
        1 + persistence_dev * anonymity_dev +
        (1 + persistence_dev * anonymity_dev | topic) + 
        (1 | topic:group)
    )
    , data = d
    , chains = 4
    , cores = 4
    , iter = 20000
    , warmup = 2000
    , family = zero_inflated_poisson()
    , control = list(
      adapt_delta = .95
      , max_treedepth = 15
      )
    )
```

After increasing iterations to 20.000, estimation works quite well.

Let's inspect model.

```{r random-effects-model-2-insp}
plot(fit_re_2, ask = FALSE)
```

Trace-plots don't look perfect, but also not overly problematic.

```{r random-effects-model-2-sum}
summary(fit_re_2)
```

Same results, no main effects, slightly larger but still nonsignificant interaction effect.

Let's inspect coefficients individually.

```{r}
coefficients(fit_re_2)
```

Let's look at exponentiated results for interpretation.

```{r random-effects-model-2-tab}
broom.mixed::tidy(fit_re_2) |> 
  mutate(
    estimate_exp = exp(estimate),
    conf_low_exp = exp(conf.low),
    conf_high_exp = exp(conf.high),
    estimate_zi = exp(estimate) / (1 + exp(estimate)),
    conf_low_zi = exp(conf.low) / (1 + exp(conf.low)),
    conf_high_zi = exp(conf.high) / (1 + exp(conf.high))
    ) %>% 
  mutate(
    across(
      c(
        estimate
        , conf.low
        , conf.high
        , estimate_exp
        , conf_low_exp
        , conf_high_exp
        , estimate_zi 
        , conf_low_zi 
        , conf_high_zi
        ),
      ~ round(.x, 2)
    )
  ) %>% 
  select(
    -effect, -group, -std.error  # -component, 
  ) %>% 
  rmarkdown::paged_table()
```

Let's visualize results.

```{r random-effects-model-2-plot}
plot(
  conditional_effects(
    fit_re_2,
    int_conditions = int_conditions
    ), 
  ask = FALSE
  )
```

Similar picture. Effects appear even smaller.

Let's look at posteriors

```{r random-effects-model-2-pos}
p_4 <- 
  pp_check(fit_re_2) + 
  labs(title = "Zero-inflated poisson")
p_4
```

# Exploratory Analyses

Look at results from a frequentist perspective.

## Fixed effects

Estimate nested model.

```{r frq-fixed-effects-model-1}
#| message: false
fit_fe_1_frq <- 
  lmer(
    n_Words ~ 
      1 + 
      (1 | topic/group) + 
      persistence_dev * anonymity_dev
    , data = d
    )

summary(fit_fe_1_frq)
```

Quite weird that topic doesn't get any variance at all. Perhaps due to small cluster size? With Bayesian estimation, it worked alright.

Estimate without nesting.

```{r frq-fixed-effects-model-2}
#| message: false
fit_fe_2_frq <- 
  lmer(
    n_Words ~ 
      1 + 
      (1 | topic) +
      persistence_dev * anonymity_dev
    , data = d
    )

summary(fit_fe_2_frq)
```

Estimate without hierarchical structure.

```{r frq-fixed-effects-model-3}
#| message: false
fit_fe_3_frq <- 
  lm(
    n_Words ~ 
      1 + 
      persistence_dev * anonymity_dev + topic
    , data = d
    )

summary(fit_fe_3_frq)
```

## Random effects

Now do the same with random effects.

```{r frq-random-effects-model-1}
#| message: false
fit_re_1_frq <- 
  lmer(
    n_Words ~ 
      1 + 
      persistence_dev * anonymity_dev + 
      (1 + persistence_dev * anonymity_dev | topic) +
      (1 | topic:group),
    , data = d
    )

summary(fit_re_1_frq)
```

```{r frq-random-effects-model-2}
#| message: false
fit_re_2_frq <- 
  lmer(
    n_Words ~ 
      1 + 
      persistence_dev * anonymity_dev + 
      (1 + persistence_dev * anonymity_dev | topic),
    , data = d
    )

summary(fit_re_2_frq)
```

Let's inspect coefficients.

```{r}
coefficients(fit_re_2_frq)
```

Save output.

```{r}
save.image("data/image_words.RData")
```

