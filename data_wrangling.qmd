---
title: "Data preparation"
format:
  html:
    toc: true
    toc-depth: 3
execute:
  cache: true
---

This document contains the code to prepare the data of the study "The Effects of Technological Affordances on Political Opinion Expression in Social Media: A Field Experiment". 

Main output of this code is the dataset DataAggregated_T1T2.csv which contains all data from the first and second questionnaire, matched with aggregated content data from the field phase (e.g., number of contributions / words / opinion expressions per participant).

For reasons of privacy, the raw data cannot be included in the online supplement. However, we do include the final edited dataset, which is anonymous. 

```{r}
#| message: false
#| result: hide
library(lavaan)
library(ltm)
library(readxl)
library(tidyverse)
library(sjlabelled)
```

# Data Input

The working directory is set to the location of the data files. All files in this directory are read and merged into one dataset.

```{r}
files <- list.files("data/raw/")
length(files) # 48
 
# read in first dataset
dat_raw <- read_excel(paste0("data/raw/", files[1]))

# read in and merge remaining datasets
for(file in 2:length(files)){ 
  d <- read_excel(paste0("data/raw/", files[file]))
  dat_raw <- rbind(d, dat_raw)
}

nrow(dat_raw)
head(dat_raw)
```

# Remove and Mark Edited Messages

The following approach searches for identical timestamps across all tables. It is unlikely that two people would have written at the exact same time down to the millisecond.

generate new variable which indicates if messages have been edited

```{r}
dat_raw$edit <- 0 
```

Find all timestamps which occur more than once but excludes the last occurrence

```{r}
dat <- 
  dat_raw %>% 
  arrange(timestamp)

dat <-
  dat %>% 
  mutate(duplicat = duplicated(timestamp, fromLast = TRUE))

table(dat$duplicat)

duplicats <- which(duplicated(dat$timestamp, fromLast = TRUE))
```

Overall, there are 497 duplicates, which seems high. Let's inspect.

```{r}
dat[c(duplicats[1], duplicats[1] +1), ]
```

Shows that these are edited messages.

Mark all messages with timestamps which occur more than once as edited

```{r}
dat[dat$timestamp %in% dat$timestamp[duplicated(dat$timestamp)], ]$edit <- 1
```

Let's inspect

```{r}
dat[dat$edit == 1, ]$message %>% 
  head()
```

Seems correct.

```{r}
dat <- dat[-which(duplicated(dat$timestamp, fromLast = TRUE)), ]
```

Check for remaining duplicated timestamps

```{r}
which(duplicated(dat$timestamp))
```

```{r}
table(dat$edit)
```

401 edited messages

```{r}
nrow(dat)
```

13333 messages in total. 

Exclude all moderator/admin messages.

```{r}
dat <- dat[-grep("moderator", dat$role), ]
dat <- dat[-grep("admin", dat$role), ]

nrow(dat)
```

Without moderator / admin messages, there are 13252 messages left

Write dataset containing all discord data without duplicated messages and with variables indicating factor levels // topic

```{r}
write.csv(dat, file = "data/DiscordData_AllGroups.csv")
```

# Merge with Survey Datasets and Add Silent Participants

In the discord data set, participants who did not post any messages do not occur. 
Since we want to consider these participants as well, we need to add them to the dataset. We thus use extra datasets containing all participants which were in the 48 discord groups and add these to the discord dataset. 

```{r}
#### read in T1 data ####
dat_T1 <- read.csv("data/data_T1_Fragebogen.csv", header = TRUE, sep = ";")
nrow(dat_T1)
nrow(dat_T1[dat_T1$QUESTNNR != "radnom", ])

# indicate which variables are from T1 Questionnaire
colnames(dat_T1) <- paste(colnames(dat_T1), "T1", sep = "_") 

length(na.omit(dat_T1$DE08_T1)) # 7627 Participants completed the T1 questionnaire. 

# Only keep those T1 participants which are on discord -> I can find these via the
# discord lists
D_D <- read_excel("data/DISCORD_USER_Discord_Discuss_Liste_Final.xlsx")
D_D$nickname_neu <- ifelse(!is.na(D_D$nickname), D_D$nickname, D_D$username)
namesD_D <- D_D$nickname_neu # usernames which are on discord (anonymous). 
D_D$case <- as.numeric(gsub("_", "", str_extract(namesD_D, "\\d+"))) 

DD <- read_excel("data/DISCORD_USER_DiscordDiscuss_Liste_Final.xlsx")
namesDD <- DD$username # usernames which are on discord (non-anonymous). 
DD$nickname_neu <- DD$username
DD$case <- as.numeric(gsub("_", "", str_extract(namesDD, "\\d+"))) 


Discord_lists <- rbind(DD, D_D)
nrow(Discord_lists)

# Now, exclude all case numbers which were not in one of the 48 experimental groups
# or any moderator / admin roles: 
# exclude_roles <- c("admin", 
#                    "admin; Monitor_bot", "Discuss; admin", "Dyno", "Dyno Premium",
#                    "Gruppe1; Gruppe3; admin", "Gruppe3; admin", "moderator", 
#                    "moderator; admin", "Statbot")
# only to get descriptive infos

exclude_roles <- c("Atlantis1", "Atlantis2", "Atlantis3", "Atlantis4", "admin", 
                   "admin; Monitor_bot", "Discuss; admin", "Dyno", "Dyno Premium",
                   "Gruppe1; Gruppe3; admin", "Gruppe3; admin", "moderator", 
                   "moderator; admin", "Statbot")
Discord_lists <- Discord_lists[!(Discord_lists$roles %in% exclude_roles), ]
Discord_lists <- Discord_lists[!(is.na(Discord_lists$roles)), ]
nrow(Discord_lists) # 960 Personen; 1352 inkl. Atlantis. 
length(unique(Discord_lists$roles)) # 48 Gruppen
table(Discord_lists$roles) # 20 Personen je Gruppe
# Discord_lists now contains all 960 participants which were in the final 48 groups
# and their role (discussion group)


### Keep only those 960 participants in T1 dataset ###
dat_T1_discord <- dat_T1[dat_T1$CASE_T1 %in% Discord_lists$case, ]
nrow(dat_T1_discord) # 960


length(unique(dat$case)) # 773 participants appear in the discord dataset
# this means that 960 - 773 = 187 participants were on discord but did not write
# anything


# now perform right join to keep all case numbers in dat_T1_discord, also if they
# don't appear in the discord dataset (dat). If they did not write any messages
# they will receive NA in these columns
dat_merged_full_T1 <- right_join(
  dat, 
  dat_T1_discord, 
  by = c("case" = "CASE_T1"), 
  keep = TRUE
)

# this should result in 13252 + 187 = 13439 rows
nrow(dat_merged_full_T1) # 13439. This is correct.

length(unique(dat_merged_full_T1$CASE_T1))
length(unique(dat_merged_full_T1$case)) 
# also seems correct!


dat_merged_full_T1$case <- dat_merged_full_T1$CASE_T1
dat_full_T1 <- merge(x = dat_merged_full_T1, y = Discord_lists[, c("case", "roles")], by = "case")
# add the roles column from the discord lists. This contains information in which group the
# participants were. 

dat_full_T1 %>%
  group_by(roles) %>% 
  summarise(n = length(unique(case)))
# In this dataset, there are 20 unique case numbers in each discussion group -> this is correct. 

nrow(dat_full_T1)
```


## Merge T2 Data to Discord / T1 Dataset

```{r}
#### read T2 data ####
dat_T2 <- read.csv("data/data_T2_Fragebogen.csv", header = TRUE, sep = ";")
nrow(dat_T2)

# indicate which variables are from T2 Questionnaire
colnames(dat_T2) <- paste(colnames(dat_T2), "T2", sep = "_") 
dat_T2 <- dat_T2[dat_T2$FINISHED_T2 == 1, ]
nrow(dat_T2)
length(which(table(dat_T2$IV01_RV1_T2) >= 2))
```

25 people have multiple complete datasets in the T2 survey.
Keep the first version

```{r}
dat_T2$IV01_RV1_T2 <- as.integer(dat_T2$IV01_RV1_T2)
dat_merged_T1T2 <- left_join(dat_full_T1, dat_T2, by = c("case" = "IV01_RV1_T2"), 
                             relationship = "many-to-one", multiple = "first", 
                             keep = TRUE)

nrow(dat_merged_T1T2)
```

IV01_RV1_T2 contains the case numbers in the T2 dataset. 
Individuals not in T2 receive NA. 

```{r}
nrow(dat)
nrow(dat_merged_T1T2) 

ncol(dat_merged_T1T2) # + 1 (roles)
ncol(dat) + ncol(dat_T1) + ncol(dat_T2)

write.csv(dat_merged_T1T2, "data/Data_Discord_AllVP_T1T2.csv", row.names = FALSE)

length(unique(dat_merged_T1T2$case))

length(unique(dat_merged_T1T2$CASE_T1))

length(unique(dat_merged_T1T2$IV01_RV1_T2))
```

706 Discord users filled out T2
 
### Add Experimental Condition based on "roles" variable

```{r}
table(dat_merged_T1T2$roles)

#### Anonymity ####
dat_merged_T1T2$anonymity <- NA

dat_merged_T1T2$anonymity <- ifelse(
  grepl(
    "rom|london|madrid|prag|berlin|paris", 
    dat_merged_T1T2$roles, 
    ignore.case = TRUE
    ), 
  "low", 
  ifelse(
    grepl(
      "tokio|dubai|oslo|rio|florenz|sydney", 
      dat_merged_T1T2$roles, 
      ignore.case = TRUE
      ), 
    "high", 
    "other"
    )
  )

table(dat_merged_T1T2$anonymity)

#### Persistence ####
dat_merged_T1T2$persistence <- NA

dat_merged_T1T2$persistence <- ifelse(
  grepl(
    "london|dubai|prag|rio|paris|sydney", 
    dat_merged_T1T2$roles, 
    ignore.case = TRUE)
  , "low",
  ifelse(
    grepl(
      "rom|tokio|madrid|oslo|berlin|florenz", 
      dat_merged_T1T2$roles, 
      ignore.case = TRUE
      ), 
    "high", 
    "other"
    )
  )

table(dat_merged_T1T2$persistence)

#### Topic ####
dat_merged_T1T2$topic <- NA 

dat_merged_T1T2$topic <- ifelse(
  grepl(
    "rom|london|tokio|dubai", 
    dat_merged_T1T2$roles, 
    ignore.case = TRUE
    ), 
  "gender", 
  ifelse(
    grepl(
      "madrid|prag|oslo|rio", 
      dat_merged_T1T2$roles, 
      ignore.case = TRUE
      ), 
    "climate", 
    ifelse(
      grepl(
        "berlin|paris|florenz|sydney", 
        dat_merged_T1T2$roles, 
        ignore.case = TRUE
        ), 
      "migration", 
      "other"
      )
    )
  )

table(dat_merged_T1T2$topic)
```

Note: The numbers above cannot be interpreted as the exact numbers of messages per participant, since the rows in the dat_merged_T1T2 dataset also contain rows for participants which did not write anything (with message then being NA).

# Create Aggregated Dataset

Now count opinion expressions for each participants. Maintain information on experimental settings.

```{r}
# combine implicit and explicit opinion expressions
table(dat_merged_T1T2$EM, useNA = "always")
dat_merged_T1T2$EM1 <- NA
dat_merged_T1T2[(!is.na(dat_merged_T1T2$EM) & dat_merged_T1T2$EM == 2), ]$EM1 <- 1
dat_merged_T1T2[(!is.na(dat_merged_T1T2$EM) & dat_merged_T1T2$EM == 1), ]$EM1 <- 1
dat_merged_T1T2[(!is.na(dat_merged_T1T2$EM) & dat_merged_T1T2$EM == 0), ]$EM1 <- 0
dat_merged_T1T2[is.na(dat_merged_T1T2$EM), ]$EM1 <- 0
table(dat_merged_T1T2$EM1, useNA = "always")
```

Now count number of words per message. We then want to add the mean and summed number of words per participant to the aggregated dataset. 

```{r}
strsplit(dat_merged_T1T2$message[1], ':[A-Za-z]|\\s+| :[A-Za-z]')
strsplit(dat_merged_T1T2$message[2], ':[A-Za-z]|\\s+| :[A-Za-z]')
strsplit(dat_merged_T1T2$message[3], ':[A-Za-z]|\\s+| :[A-Za-z]')

strsplit(dat_merged_T1T2$message[4], ':[A-Za-z]|\\s+| :[A-Za-z]') 

# The first delimiter ensures that emojis are counted correctly, regardless of whether they are separated by a space or not, or whether there is a period/space following them or not.
# The last delimiter ensures that a space before an emoji is not counted as an extra.
# Example:
  
strsplit("Das ist ein Test:grinning_face:", ':[A-Za-z]|\\s+| :[A-Za-z]') 
strsplit("Das ist ein Test:grinning_face:.", ':[A-Za-z]|\\s+| :[A-Za-z]') 
strsplit("Das ist ein Test :grinning_face:.", ':[A-Za-z]|\\s+| :[A-Za-z]') 

dat_merged_T1T2$nwords <- ifelse(is.na(dat_merged_T1T2$message), NA, 
                                 lengths(strsplit(dat_merged_T1T2$message, ':[A-Za-z]|\\s+| :[A-Za-z]')))
# lengths(gregexpr("\\W+", dat$message))
```

Create aggregated dataset. 

```{r}
d <- dat_merged_T1T2 %>% 
      group_by(case) %>%
      summarize(n_OE = sum(EM1 == 1)
                , persistence = persistence[1]
                , anonymity = anonymity[1]
                , topic = topic[1])


# test for some case numbers if this worked correctly:
# first 5: 
sum(dat_merged_T1T2[dat_merged_T1T2$case == 4075, ]$EM1)
sum(dat_merged_T1T2[dat_merged_T1T2$case == 4087, ]$EM1)
sum(dat_merged_T1T2[dat_merged_T1T2$case == 4118, ]$EM1)
sum(dat_merged_T1T2[dat_merged_T1T2$case == 4135, ]$EM1)
sum(dat_merged_T1T2[dat_merged_T1T2$case == 4145, ]$EM1)

head(d, n = 5)

# last 5: 
sum(dat_merged_T1T2[dat_merged_T1T2$case == 56557, ]$EM1)
sum(dat_merged_T1T2[dat_merged_T1T2$case == 56569, ]$EM1)
sum(dat_merged_T1T2[dat_merged_T1T2$case == 56611, ]$EM1)
sum(dat_merged_T1T2[dat_merged_T1T2$case == 56659, ]$EM1)
sum(dat_merged_T1T2[dat_merged_T1T2$case == 56778, ]$EM1)

tail(d, n = 5)

# these are all correct. 

### Ad summed number of words per participant ###
d_w <- dat_merged_T1T2 %>% 
      group_by(case) %>%
      summarize(n_Words = sum(nwords))

head(d_w)
sum(dat_merged_T1T2[dat_merged_T1T2$case == 4075, ]$nwords) 
sum(dat_merged_T1T2[dat_merged_T1T2$case == 4087, ]$nwords) 
sum(dat_merged_T1T2[dat_merged_T1T2$case == 4118, ]$nwords) 
sum(dat_merged_T1T2[dat_merged_T1T2$case == 4135, ]$nwords) 
sum(dat_merged_T1T2[dat_merged_T1T2$case == 4145, ]$nwords) 
sum(dat_merged_T1T2[dat_merged_T1T2$case == 4327, ]$nwords) 

# this all worked fine. 

d$n_Words <- d_w$n_Words
identical(d$case, d_w$case) # check whether the case numbers work fine

### Ad mean number of words per participant ###
d_wm <- dat_merged_T1T2 %>% 
      group_by(case) %>%
      summarize(mean_Words = mean(nwords))
mean(dat_merged_T1T2[dat_merged_T1T2$case == 4075, ]$nwords) # check

d$mean_Words <- d_wm$mean_Words

### Ad number of messages (not number of opinion expressions)
d_nm <- dat_merged_T1T2 %>% 
      group_by(case) %>%
      summarize(number_messages = sum(!is.na(message)))

sum(!is.na(dat_merged_T1T2[dat_merged_T1T2$case == 4075, ]$message))
sum(!is.na(dat_merged_T1T2[dat_merged_T1T2$case == 4118, ]$message))

# the second participant has 0.

table(d_nm$number_messages)

d$number_messages <- d_nm$number_messages
identical(d$case, d_nm$case)
```

```{r}
save(d, file = "data/data_aggregated_nwords.csv")

aggregate(n_OE ~ persistence + anonymity, d, mean)
aggregate(n_OE ~ persistence, d, mean)
aggregate(n_OE ~ anonymity, d, mean)
```

To this aggregated dataset, we now again add the T1 and T2 variables. 

```{r}
d_final_T1 <- left_join(d, dat_T1, by = c("case" = "CASE_T1"), keep = TRUE)
d_final <- left_join(d_final_T1, dat_T2, by = c("case" = "IV01_RV1_T2"), keep = TRUE, 
                     multiple = "first",)
d_final <- merge(x = d_final, y = Discord_lists[, c("case", "roles")], by = "case")
# add roles variable (contains the individual discussion groups)

write.csv(d_final, "data/DataAggregated_T1T2_nwords.csv", row.names = FALSE)
# head(read.csv("data/DataAggregated_T1T2_nwords.csv", header = TRUE))
```

# Factorial validity

We now add means of relevant T2-scales and perform a confirmatory factor analysis for the cost / benefit items. 

```{r}
### Aggregate Salience Check Items ###
# Add mean score perceived anonymity: Items ZD05_01, ZD_05_02, ZD05_03
# high value means low perceived anonymity!

anon <- c("ZD05_01_T2", "ZD05_01_T2", "ZD05_01_T2")
d_final$per_anonymity <- apply(d_final[, anon], 1, mean)
head(d_final$per_anonymity)

aggregate(per_anonymity ~ anonymity, d_final, mean)

# Add mean score perceived persistence: Items ZD05_04, ZD05_05, ZD05_06
# high value means low perceived persistence

pers <- c("ZD05_04_T2", "ZD05_05_T2", "ZD05_06_T2")
d_final$per_persistence <- apply(d_final[, pers], 1, mean)
head(d_final$per_persistence)

aggregate(per_persistence ~ persistence, d_final, mean)

### Confirmatory Factor Analysis for Costs / Benefits ###

# Perceived Benefits: KN01-Items
# Subscales: Persuasion (01, 02, 03, 18, 19, 20), Corrective Action (04, 05, 06), 
# Self-presentation (07, 08, 09, 10), civic contribution (11, 12, 13, 16, 17), 
# Relational Maintenance (14, 15)

benefits <- grep("KN01", names(d_final), value = TRUE) # all benefit items
d_final$benefits <- apply(d_final[, benefits], 1, mean)
head(d_final$benefits)
mean(na.omit(d_final$benefits))
sd(na.omit(d_final$benefits))

benefit.model <- ' 
persuasion  =~ KN01_01_T2 + KN01_02_T2 + KN01_03_T2 + KN01_18_T2 + KN01_19_T2 + KN01_20_T2 
corrective =~ KN01_04_T2 + KN01_05_T2 + KN01_06_T2
selfpresentation =~ KN01_07_T2 + KN01_08_T2 + KN01_09_T2 + KN01_10_T2
civicmotivation =~ KN01_11_T2 + KN01_12_T2 + KN01_13_T2 + KN01_16_T2 + KN01_17_T2
Relationalmotivation =~ KN01_14_T2 + KN01_15_T2
'
fit.benefits <- cfa(benefit.model, data=d_final, estimator = "MLM")
summary(fit.benefits, fit.measures=TRUE, standardized = TRUE)

# Add subscales to data: 
d_final$b_persuasion <- apply(d_final[, c("KN01_01_T2", "KN01_02_T2", "KN01_03_T2", "KN01_18_T2", "KN01_19_T2", "KN01_20_T2")], 1, mean)
d_final$b_corrective <- apply(d_final[, c("KN01_04_T2", "KN01_05_T2", "KN01_06_T2")], 1, mean)
d_final$b_selfpresentation <- apply(d_final[, c("KN01_07_T2", "KN01_08_T2", "KN01_09_T2", "KN01_10_T2")], 1, mean)
d_final$b_civicmotivation <- apply(d_final[, c("KN01_11_T2", "KN01_12_T2", "KN01_13_T2", "KN01_16_T2", "KN01_17_T2")], 1, mean)
d_final$b_relationalmotivation <- apply(d_final[, c("KN01_14_T2", "KN01_15_T2")], 1, mean)

# perceived costs: KN03-Items
# Subscales: Negative Judgment (01, 02, 03, 04), Dissolution of Relationships (05, 06, 07, 08), 
# Personal Attacks (09, 10, 11, 12), Zero Effect (13, 14, 15)

costs <- grep("KN03", names(d_final), value = TRUE) # all costs items
d_final$costs <- apply(d_final[, costs], 1, mean)
head(d_final$costs)
mean(na.omit(d_final$costs))
sd(na.omit(d_final$costs))

costs.model <- ' 
negativejudgment  =~ KN03_01_T2 + KN03_02_T2 + KN03_03_T2 + KN03_04_T2
dissolution =~ KN03_05_T2 + KN03_06_T2 + KN03_07_T2 + KN03_08_T2
attacks =~ KN03_09_T2 + KN03_10_T2 + KN03_11_T2 + KN03_12_T2
zeroeffects =~ KN03_13_T2 + KN03_14_T2 + KN03_15_T2 
'
fit.costs <- cfa(costs.model, data=d_final, estimator = "MLM")
summary(fit.costs, fit.measures=TRUE, standardized = TRUE)

d_final$c_negativejudgment <- apply(d_final[, c("KN03_01_T2", "KN03_02_T2", "KN03_03_T2", "KN03_04_T2")], 1, mean)
d_final$c_dissolution <- apply(d_final[, c("KN03_05_T2", "KN03_06_T2", "KN03_07_T2", "KN03_08_T2")], 1, mean)
d_final$c_attacks <- apply(d_final[, c("KN03_09_T2", "KN03_10_T2", "KN03_11_T2", "KN03_12_T2")], 1, mean)
d_final$c_zeroeffects <- apply(d_final[, c("KN03_13_T2", "KN03_14_T2", "KN03_15_T2")], 1, mean)

d_final_T2 <- d_final[!is.na(d_final$CASE_T2), ]
cronbach.alpha(d_final_T2[, benefits])
cronbach.alpha(d_final_T2[, costs])

# persuasion
mean(na.omit(d_final_T2$b_persuasion))
sd(na.omit(d_final_T2$b_persuasion))
cronbach.alpha(d_final_T2[, c("KN01_01_T2", "KN01_02_T2", "KN01_03_T2", "KN01_18_T2", "KN01_19_T2", "KN01_20_T2")])

# corrective action
mean(na.omit(d_final_T2$b_corrective))
sd(na.omit(d_final$b_corrective))
cronbach.alpha(d_final_T2[, c("KN01_04_T2", "KN01_05_T2", "KN01_06_T2")])

# self-presentation
mean(na.omit(d_final_T2$b_selfpresentation))
sd(na.omit(d_final$b_selfpresentation))
cronbach.alpha(d_final_T2[, c("KN01_07_T2", "KN01_08_T2", "KN01_09_T2", "KN01_10_T2")])

# civic contribution
mean(na.omit(d_final_T2$b_civicmotivation))
sd(na.omit(d_final$b_civicmotivation))
cronbach.alpha(d_final_T2[, c("KN01_11_T2", "KN01_12_T2", "KN01_13_T2", "KN01_16_T2", "KN01_17_T2")])

# relational maintenance
mean(na.omit(d_final_T2$b_relationalmotivation))
sd(na.omit(d_final$b_relationalmotivation))
cronbach.alpha(d_final_T2[, c("KN01_14_T2", "KN01_15_T2")])

# negative judgment
mean(na.omit(d_final_T2$c_negativejudgment))
sd(na.omit(d_final$c_negativejudgment))
cronbach.alpha(d_final_T2[, c("KN03_01_T2", "KN03_02_T2", "KN03_03_T2", "KN03_04_T2")])

# dissolution of relationships
mean(na.omit(d_final_T2$c_dissolution))
sd(na.omit(d_final$c_dissolution))
cronbach.alpha(d_final_T2[, c("KN03_05_T2", "KN03_06_T2", "KN03_07_T2", "KN03_08_T2")])

# personal attacks
mean(na.omit(d_final_T2$c_attacks))
sd(na.omit(d_final$c_attacks))
cronbach.alpha(d_final_T2[, c("KN03_09_T2", "KN03_10_T2", "KN03_11_T2", "KN03_12_T2")])

# zero effects
mean(na.omit(d_final_T2$c_zeroeffects))
sd(na.omit(d_final$c_zeroeffects))
cronbach.alpha(d_final_T2[, c("KN03_13_T2", "KN03_14_T2", "KN03_15_T2")])

# anonymity 
mean(na.omit(d_final$per_anonymity))
sd(na.omit(d_final$per_anonymity))
cronbach.alpha(d_final_T2[, c("ZD05_01_T2", "ZD05_01_T2", "ZD05_01_T2")])

# persistence 
mean(na.omit(d_final$per_persistence))
sd(na.omit(d_final$per_persistence))
cronbach.alpha(d_final_T2[, c("ZD05_04_T2", "ZD05_05_T2", "ZD05_06_T2")])
```

```{r}
# Demographic Data: 

table(d_final$DE01_T1)
mean(d_final$DE02_01_T1)
sd(d_final$DE02_01_T1)
range(d_final$DE02_01_T1)
table(d_final$DE03_T1)

mean(d_final$DE06_01_T1)
table(d_final$DE06_01_T1)
sd(d_final$DE06_01_T1)

table(d_final$DE08_T1)

d_T2 <- d_final[!is.na(d_final$CASE_T2), ]
nrow(d_T2)
table(d_T2$DE01_T1)
```

# Save dataset

```{r}
d_final <- d_final |> 
  dplyr::select(
    DE01_T1, # gender
    DE02_01_T1, # age
    DE03_T1, # education
    DE08_T1, # party preference
    roles,
    topic,
    anonymity,
    per_anonymity,
    persistence,
    per_persistence,
    n_OE, # opinion expressions
    n_Words,
    benefits,
    costs,
    DE06_01_T1, # political stance
    c_zeroeffects,
    c_attacks,
    c_dissolution,
    c_negativejudgment,
    b_relationalmotivation,
    b_civicmotivation,
    b_selfpresentation,
    b_corrective,
    b_persuasion
  )
write.csv(d_final, "data/data.csv", row.names = FALSE)
# head(read.csv("data/DataAggregated_T1T2_costsbenefits.csv", header = TRUE))
```













